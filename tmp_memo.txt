-------------------------------------

### git 更新は以下のコマンドで出来た
```bash
$ git add --all
$ git commit -m "hogehoge"
$ git push origin HEAD:master
```
-------------------------------------

■20201030 共有会
cvの過学習あるので、LBに効くcvの値を把握していけばいいんでない。上位はcv=0.015-0.016台でいけてるので OTさん

RANK ガウスはMLPと相性いいらしい OTさん

nonscored で学習→予測値を特徴に追加→scored を学習でやりたい OHさん

nonscoredも予測ラベルに入れてMLP作ればマルチタスクでうまくいくかも OTさん

nonscored targetのclass_weightを減らして学習させる方がいいと思う Aさん

画像化がうまくできるならCNNはいいと思う。今のところそんなのないが OTさん

DeepInsightより、Auto encoderで2次元化した画像でやる方がいいと思う OTさん

ラベルは阻害剤とほかのなんかの種類が多い Nさん

ラベルの種類でMLPの出力層2股にわけるとか、阻害剤とそれ以外とか OTさん

ラベルの間の相関得るため、RNNやClassifierChain がいいでは OHさん

RNN よりLSTMのがいいだろう。LSTMよりTransfomerのがいいだろ。じゃあTabNetじゃん OTさん

最終のサブは
①1サブは推論のみでアンサンブルしまくるサブ
?train+推論のサブ
でいく


■20201106聞くこと
to OH
クラスごとのブレンドの重みはどうやって決めている？
ネルダーミードだと非常に遅いためクラスごとにやるのはきびしい
→ scipy.optimize.minimize_scalar なら早くできる

to N
CatBoost＋add target
⇒scored target を分類し、そのラベルのOOF予測値を追加
はどういうこと？
→阻害剤とかのクラス追加してモデル作成したってこと

to A
DeepGBM ってなに？↓これ？
http://yh0sh.hateblo.jp/

to OT
tabnetのpretrainingって何してるの？論文読めという話かもですが。。。

チーム参加しました。コードとか

仕事を分担したい（CV を変更した MLP の再実験、チューニング）

---------------------------------------------------------------

20201023時点
◆来週試したいこと
・LightGBMのコード修正（マルチラベルのone modelではなくクラスごとに206個モデル作る方法）
　→
・notebook, discussion確認して気になったの試す
    - https://www.kaggle.com/c/lish-moa/discussion/191545 で書いてるようにデータ不均衡の対策をしたい
　→
・TGAN(テーブルデータのGAN)で学習データ水増し（noiseが増えるだけで失敗しそうだが）
　→1epoch3000時間もかかるといわれたためあきらめる
　　改良版のCTGANもうまくいかないらしいので
　　https://www.kaggle.com/c/lish-moa/discussion/193358
・加重平均のモデルブレンディングの重みをネルダーミードで最適化
　→ネルダーミードした方がoof下がるが、LBは悪くなった

20201028
・PCAが有効だと言ってるディスカッション探す
　→
　→
　　https://www.kaggle.com/c/lish-moa/discussion/193532

・LightGBMを1モデルでマルチラベル学習。他のsklearnのモデルでも試せるようにする

・
自分で試したのだと、
PCAはsklearn.preprocessingのRobustScalerやStandardScalerと組み合わせでcv 0.00007ぐらい下がってました 

train setだけでPCAしたらshakeup する可能性あるとディスカッション出てますね
https://www.kaggle.com/c/lish-moa/discussion/193532
----------------------------------------------------------------------------

20201030
◆今週試したこと
・LightGBMのコード修正

・3層のMLPでfeature engineering
　- CV下がったの
　　- 列の統計値
　　- PCA+RobustScaler
　　- c-列の2乗
　　- c-列の絶対値
　- 公開notebookでは効果出てるが、自分のCV効果なかったの
　　- RankGauss
　　- VarianceThreshold（分散がしきい値以下の特徴削除）
　　- KMeansで特徴量作成
　　- cp_type列削除
　- 効果なし
　　- g-列の2乗
　　- g-列の二値化
　　- g-列の絶対値
　　- cp_type=ctl_vehicle 行の平均値との差、比率

・モデルブレンディングの重みをネルダーミードで最適化
CV下がるが、LB悪化

・TGANあきらめた

◆現在のスコア
・LightGBM + feature engineering
CV 0.01548 / LB  0.01987

・MLPブレンディング + feature engineering
CV 0.01519 / LB  0.01858

◆疑問（困ってること）
スコア良いpytorchの公開notebook(https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846)
のMLPをtensorflowで作り直したがうまくいかない

◆来週試したいこと
・MLPでスコア上げる
	- パラメータチューニング
		- https://www.kaggle.com/fchollet/moa-keras-kerastuner-best-practices/?utm_campaign=piqcy&utm_medium=email&utm_source=Revue+newsletter
・LightGBM + ClassifierChain

・TabNetの論文確認（https://arxiv.org/pdf/1908.07442.pdf）
・TabNetでスコア上げる
	- https://www.kaggle.com/hiramcho/moa-tabnet-with-pca-rank-gauss

・sklernでほかのモデル作成してアンサンブル

・RNN (https://www.kaggle.com/c/lish-moa/discussion/193583)

・異常検知
	- https://www.kaggle.com/rahulsd91/moa-anomaly-detection

・不均衡対策
	- バッチ内でラベルのバランス保つように学習
		- https://devblog.thebase.in/entry/2020/02/29/110000
	- MLSMOTE
		- https://www.kaggle.com/anonamename/upsampling-multilabel-data-with-mlsmote/edit

・同種の薬のレコード見つける
	- 統制群に対する値や散布図かく？
	
・マルチラベルコンペの上位解法参考にする
	-https://www.kaggle.com/c/lish-moa/discussion/180092

----------------------------------------------------------------------------

20201106
◆今週試した上手くいったこと
* feature engineering
　g-,c-毎に5%,95%の値でクリップしたらCV 0.000001改善

* nonscored target もクラスに追加した MLP
　resnet構造のMLPでCV改善

* adabelief-tf=0.1.0
　CV改善。Lookaheadと組み合わせたらCV悪化（大堀さんが言った通り）

◆今週試した上手くいかなかったこと
* nonscored target もクラスに追加した MLP + scored targetのclass_weight大きくして学習
　CV、LB 悪化

* LightGBM + MultiOutputClassifier 
　LightGBM206個作る方法よりCV、LB 悪化
　
* LightGBM + ClassifierChain
　LightGBM206個作る方法よりCV、LB 悪化
　LightGBM + MultiOutputClassifier よりはCV改善

* nonscored target もクラスに追加した LightGBM + ClassifierChain 
　LightGBM206個作る方法よりCV悪化
　LightGBM + ClassifierChain よりはCV改善

* tf版TabNet
　MLPよりCV悪化

◆来週試したいこと
* drug_id利用したMultilabelStratifiedKFoldでモデル再作成
* feature engineering
　同じ用量時間だがg-,c-列の値が全然違うデータ削除など
　https://www.kaggle.com/c/lish-moa/discussion/195245
* tf版TabNetのパラメチューニング
* 作成したモデルブレンディング

◆現状の CV/LB スコア
* tf版TabNet
　CV: 0.01667 / LB: 出してない
* MLPとLightGBM は前回から改善なし

◆注目の notebook, discussion
* https://www.kaggle.com/c/lish-moa/discussion/195378
　余裕あればCNN試したい

◆疑問（と困ってること）
* クラス毎に blendingはどうやっている？
　scipy.optimize.minimizeでやると時間かかりすぎて困ってる
* tf版TabNetのCV上がらない
* LB上がらない

◆議題
* drug_id利用したMultilabelStratifiedKFold 使うか？
　https://www.kaggle.com/c/lish-moa/discussion/195195
　CVとLBの差は狭まるがLB 悪化
　わずかにCV 下げた(0.00002下げた)場合ではLB 改善しなかったので、このCVを完全に信じるのは危なそう

----------------------------------------------------------------------------

20201113
◆今週試した上手くいったこと
- MultilabelGroupStratifiedKFold でMLPClassifier.fit 再試
　activation, bn, dropout の順序
　→cv変更前と同様bn-act-dropの順序がcv一番良い

　gaussian noise, cutout, mixup, cutmix
　→cv変更前と同様mixup, cutmixがcv良い

　weight normalization の有無
　→cv変更前と同様有る方がcv良い

　cp_type と cp_dose の有無
　→cv変更前と同様無い方がcv良い

　ClippedFeatures, QuantileTransformer 等の前処理
　→cv変更前と同様
　　Clipped 有る方が良い
　　QuantileTransformer 無い方が良い。https://www.kaggle.com/c/lish-moa/discussion/195788 で書いてるようにパラメータ n_quantiles=100, 1000 試したがどちらも効果なし

　PCA features, RowStatistics 等の特徴エンジニアリング
　→cv変更前と同様
　　PCA 無い方が良い
　　RowStatistics 有る方が良い
　→5シードアベレージで一番cv下がったのは、特徴量の遺伝子発現列の絶対値が2以上かのフラグ列を追加した特長量エンジニアリングを組み合わせたもの(cv: 0.01549)
　https://www.kaggle.com/anonamename/mlpclassifier-edit-fe-fit

　ctl_vehicle 行の削除
　→vanilla の状態に ctl_vehicle 行の削除 のみ実行すると効くが、mixupやcutmixと組み合わせると無い方がcv良くなる

　non score target で転移学習
　→深いMLPやresnetだと効くみたい( https://www.kaggle.com/c/lish-moa/discussion/195932 )だが効果なし

◆今週試した上手くいかなかったこと
- パラメータチューニングが終わらない

◆来週試したいこと
- パラメータチューニング
- 作成したモデルブレンディング

◆注目の notebook, discussion
- MLP + ClassifierChain みたいな方法のGrowNet
　https://www.kaggle.com/c/lish-moa/discussion/196436
- drug_idを特徴量に使う
　https://www.kaggle.com/c/lish-moa/discussion/195380

----------------------------------------------------------------------------

20201120
◆今週試した上手くいったこと
- RapidsのSVM
　cv: 0.01513 / LB: 出してない (StratifiedKFold。1クラスごとに1つモデル作る方法なので)
　https://www.kaggle.com/anonamename/moa-rapids-svm

◆今週試した上手くいかなかったこと
- 在原さんのVotingClassifier.fit, VotingClassifier.predict にLightGBMとMLPを追加してアンサンブル
　cv下がるがLB悪化
　cv: 0.01521 / LB: 0.02074 (MultilabelGroupStratifiedKFold)
　https://www.kaggle.com/anonamename/votingclassifier-fit
　https://www.kaggle.com/anonamename/votingclassifier-predict

- validation 分割修正してnonscored targets 連結したMLP再試
　変わらずcv悪化。自分の修正間違ってる？orパラメータの問題？
　連結前 cv score: 0.01768
　連結後 cv score: 0.01803

◆来週試したいこと
- GrowNet
- マルチラベルでLightGBM学習
　https://www.kaggle.com/c/lish-moa/discussion/197650

◆疑問（と困ってること）
- 最終サブどうするか？
- cvどうするか?
- アンサンブルするinput揃えるか?
- 出力ファイルが20GB超えてkaggleカーネルがエラーになる。回避する方法はないか？


離散した特徴量だとGBM強い
連続値の特徴量だとNNに向いてる。今回はこれだからうまくいくみたい(by 大堀さん)

GBMは、データが個別の選択肢を持つ人々の行動に関するものである場合に最適に機能します
https://twitter.com/JFPuget/status/1233431595455041537


---------------------------------------------------------------

MLP + ClassifierChain みたいな方法のGrowNetっていうのあるんですね
https://www.kaggle.com/c/lish-moa/discussion/196436

クラスのバランスが取れていないことの難しさみんな感じているんすね
https://www.kaggle.com/c/lish-moa/discussion/196463

チューニング（ハイパーパラメータチューニング、混合重みの最適化など）に新しいCVを使用してから、モデルのトレーニングに古いCVメソッドを使用するのを猫の人も言ってる
https://www.kaggle.com/c/lish-moa/discussion/195660

層重ねたMLPやresnetでno scored targetの転移学習するとスコア上がるらしいが実現せず。。。
（TabNetではno scored targetの転移学習効かないらしい）
https://www.kaggle.com/c/lish-moa/discussion/195932
https://www.kaggle.com/c/lish-moa/discussion/195859

rankgaussパラメータ100, 1000でやったが効かず。。。
https://www.kaggle.com/c/lish-moa/discussion/195788

同じ用量と時間の同じ薬が遺伝子と細胞のデータが大きく異なるのはサンプルの個人差のせい
→私たちの日常生活では、ある個人に効く「薬」が別の人にはうまく効かないことがよくあります
https://www.kaggle.com/c/lish-moa/discussion/195170

drug_idを特徴量に使う
https://www.kaggle.com/c/lish-moa/discussion/195380

cvとLBの関係性plot。コントロールなしのMultilabelGroupStratifiedKFoldでの結果
cv下がればLBも下がってることがわかる
1位の人のコメント「0.01530前後の新しいCVを持つLB0.01809提出物があります（コントロールグループを含む）」
→cv下げるの頑張るべき？
https://www.kaggle.com/c/lish-moa/discussion/197108

public LBにover fitする
最適化したモデルブレンディングでLB下がらなかったのでCVとLB相関してないと言ってる人もいる
https://www.kaggle.com/c/lish-moa/discussion/196874

データの増強もおすすめしてる
https://www.kaggle.com/c/lish-moa/discussion/197654

表形式のデータなのに、
ニューラルネットワークの方がブースティングモデルよりもパフォーマンスが優れているため、
この競争は非常に興味深く特別です。
→理由1
　データの構造は、ブースティングアルゴリズムに適合していない可能性があります
　（セルの機能間で順序はそれほど重要ではないようです。
　　つまり、結果を変更せずに一部のsig_idのcx、cyを並べ替えることができます）
→理由2
　1度に206すべてのラベルを使用していない
　(ニューラルネットは206クラスのマルチラベルで学習できる)
https://www.kaggle.com/c/lish-moa/discussion/197650

self-stacking + lgbm
ポジティブサンプル(=1)を多く含むターゲットを最初に学習させる
oofを保存し、oofの予測値を特徴量として追加することで、ポジティブなサンプル数が少ない学習対象の特徴量を得る
https://www.kaggle.com/underwearfitting/partial-self-stacking-lightgbm

nonscored入れた方が良くなったらしい
MultilabelGroupStratifiedKFoldの切り方をsoredを基準にするのしてなかったため
自分のMLPはnonscored入れた方がcv悪化する

GrowNetはニューラルネットワークでブースティングするモデル（弱学習器として浅いニューラルネットを用いた勾配ブースティングフレームワーク）
Xgboostより高精度
このコンペティションでは、ほとんどの人がNNがCVとLBの両方で最高の性能を発揮すると言っていますが、
他のアルゴリズムはNNほどの性能を発揮しません。
そのため、勾配ブーストとNNの混合がこのタスクに適しているかもしれません
https://www.kaggle.com/tmhrkt/grownet-gradient-boosting-neural-networks

マイナークラスは oof 予測があてにならない（訓練データにないときある）からアンサンブルの重み求めるときに過学習しそう
薬品の違いを区別（あるいは解消）できるような特徴を追加しないとダメみたい
(by OHさん)

moaの日本語解説
https://www.kaggle.com/takiyu/japanese-moa

PCAについて議論されてる
https://www.kaggle.com/c/lish-moa/discussion/198898

少量データ対策の手法で聞いたことまとめておくこと（by Iさん 20201117）

