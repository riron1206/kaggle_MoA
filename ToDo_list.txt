20201023時点
◆来週試したいこと
・LightGBMのコード修正（マルチラベルのone modelではなくクラスごとに206個モデル作る方法）
　→
・notebook, discussion確認して気になったの試す
    - https://www.kaggle.com/c/lish-moa/discussion/191545 で書いてるようにデータ不均衡の対策をしたい
　→
・TGAN(テーブルデータのGAN)で学習データ水増し（noiseが増えるだけで失敗しそうだが）
　→1epoch3000時間もかかるといわれたためあきらめる
　　改良版のCTGANもうまくいかないらしいので
　　https://www.kaggle.com/c/lish-moa/discussion/193358
・加重平均のモデルブレンディングの重みをネルダーミードで最適化
　→ネルダーミードした方がoof下がるが、LBは悪くなった

20201028
・PCAが有効だと言ってるディスカッション探す
　→
　→
　　https://www.kaggle.com/c/lish-moa/discussion/193532

・LightGBMを1モデルでマルチラベル学習。他のsklearnのモデルでも試せるようにする

・
自分で試したのだと、
PCAはsklearn.preprocessingのRobustScalerやStandardScalerと組み合わせでcv 0.00007ぐらい下がってました 

train setだけでPCAしたらshakeup する可能性あるとディスカッション出てますね
https://www.kaggle.com/c/lish-moa/discussion/193532
----------------------------------------------------------------------------

20201030
◆今週試したこと
・LightGBMのコード修正

・3層のMLPでfeature engineering
　- CV下がったの
　　- 列の統計値
　　- PCA+RobustScaler
　　- c-列の2乗
　　- c-列の絶対値
　- 公開notebookでは効果出てるが、自分のCV効果なかったの
　　- RankGauss
　　- VarianceThreshold（分散がしきい値以下の特徴削除）
　　- KMeansで特徴量作成
　　- cp_type列削除
　- 効果なし
　　- g-列の2乗
　　- g-列の二値化
　　- g-列の絶対値
　　- cp_type=ctl_vehicle 行の平均値との差、比率

・モデルブレンディングの重みをネルダーミードで最適化
CV下がるが、LB悪化

・TGANあきらめた

◆現在のスコア
・LightGBM + feature engineering
CV 0.01548 / LB  0.01987

・MLPブレンディング + feature engineering
CV 0.01519 / LB  0.01858

◆疑問（困ってること）
スコア良いpytorchの公開notebook(https://www.kaggle.com/kushal1506/moa-pytorch-feature-engineering-0-01846)
のMLPをtensorflowで作り直したがうまくいかない

◆来週試したいこと
・MLPでスコア上げる
	- パラメータチューニング
		- https://www.kaggle.com/fchollet/moa-keras-kerastuner-best-practices/?utm_campaign=piqcy&utm_medium=email&utm_source=Revue+newsletter
・LightGBM + ClassifierChain

・TabNetの論文確認（https://arxiv.org/pdf/1908.07442.pdf）
・TabNetでスコア上げる
	- https://www.kaggle.com/hiramcho/moa-tabnet-with-pca-rank-gauss

・sklernでほかのモデル作成してアンサンブル

・RNN (https://www.kaggle.com/c/lish-moa/discussion/193583)

・異常検知
	- https://www.kaggle.com/rahulsd91/moa-anomaly-detection

・不均衡対策
	- バッチ内でラベルのバランス保つように学習
		- https://devblog.thebase.in/entry/2020/02/29/110000
	- MLSMOTE
		- https://www.kaggle.com/anonamename/upsampling-multilabel-data-with-mlsmote/edit

・同種の薬のレコード見つける
	- 統制群に対する値や散布図かく？
	
・マルチラベルコンペの上位解法参考にする
	-https://www.kaggle.com/c/lish-moa/discussion/180092

----------------------------------------------------------------------------

20201106
◆今週試した上手くいったこと
* feature engineering
　g-,c-毎に5%,95%の値でクリップしたらCV 0.000001改善

* nonscored target もクラスに追加した MLP
　resnet構造のMLPでCV改善

* adabelief-tf=0.1.0
　CV改善。Lookaheadと組み合わせたらCV悪化（大堀さんが言った通り）

◆今週試した上手くいかなかったこと
* nonscored target もクラスに追加した MLP + scored targetのclass_weight大きくして学習
　CV、LB 悪化

* LightGBM + MultiOutputClassifier 
　LightGBM206個作る方法よりCV、LB 悪化
　
* LightGBM + ClassifierChain
　LightGBM206個作る方法よりCV、LB 悪化
　LightGBM + MultiOutputClassifier よりはCV改善

* nonscored target もクラスに追加した LightGBM + ClassifierChain 
　LightGBM206個作る方法よりCV悪化
　LightGBM + ClassifierChain よりはCV改善

* tf版TabNet
　MLPよりCV悪化

◆来週試したいこと
* drug_id利用したMultilabelStratifiedKFoldでモデル再作成
* feature engineering
　同じ用量時間だがg-,c-列の値が全然違うデータ削除など
　https://www.kaggle.com/c/lish-moa/discussion/195245
* tf版TabNetのパラメチューニング
* 作成したモデルブレンディング

◆現状の CV/LB スコア
* tf版TabNet
　CV: 0.01667 / LB: 出してない
* MLPとLightGBM は前回から改善なし

◆注目の notebook, discussion
* https://www.kaggle.com/c/lish-moa/discussion/195378
　余裕あればCNN試したい

◆疑問（と困ってること）
* クラス毎に blendingはどうやっている？
　scipy.optimize.minimizeでやると時間かかりすぎて困ってる
* tf版TabNetのCV上がらない
* LB上がらない

◆議題
* drug_id利用したMultilabelStratifiedKFold 使うか？
　https://www.kaggle.com/c/lish-moa/discussion/195195
　CVとLBの差は狭まるがLB 悪化
　わずかにCV 下げた(0.00002下げた)場合ではLB 改善しなかったので、このCVを完全に信じるのは危なそう

----------------------------------------------------------------------------

20201113
◆今週試した上手くいったこと
- MultilabelGroupStratifiedKFold でMLPClassifier.fit 再試
　activation, bn, dropout の順序
　→cv変更前と同様bn-act-dropの順序がcv一番良い

　gaussian noise, cutout, mixup, cutmix
　→cv変更前と同様mixup, cutmixがcv良い

　weight normalization の有無
　→cv変更前と同様有る方がcv良い

　cp_type と cp_dose の有無
　→cv変更前と同様無い方がcv良い

　ClippedFeatures, QuantileTransformer 等の前処理
　→cv変更前と同様
　　Clipped 有る方が良い
　　QuantileTransformer 無い方が良い。https://www.kaggle.com/c/lish-moa/discussion/195788 で書いてるようにパラメータ n_quantiles=100, 1000 試したがどちらも効果なし

　PCA features, RowStatistics 等の特徴エンジニアリング
　→cv変更前と同様
　　PCA 無い方が良い
　　RowStatistics 有る方が良い
　→5シードアベレージで一番cv下がったのは、特徴量の遺伝子発現列の絶対値が2以上かのフラグ列を追加した特長量エンジニアリングを組み合わせたもの(cv: 0.01549)
　https://www.kaggle.com/anonamename/mlpclassifier-edit-fe-fit

　ctl_vehicle 行の削除
　→vanilla の状態に ctl_vehicle 行の削除 のみ実行すると効くが、mixupやcutmixと組み合わせると無い方がcv良くなる

　non score target で転移学習
　→深いMLPやresnetだと効くみたい( https://www.kaggle.com/c/lish-moa/discussion/195932 )だが効果なし

◆今週試した上手くいかなかったこと
- パラメータチューニングが終わらない

◆来週試したいこと
- パラメータチューニング
- 作成したモデルブレンディング

◆注目の notebook, discussion
- MLP + ClassifierChain みたいな方法のGrowNet
　https://www.kaggle.com/c/lish-moa/discussion/196436
- drug_idを特徴量に使う
　https://www.kaggle.com/c/lish-moa/discussion/195380

