20201023時点
◆来週試したいこと
・LightGBMのコード修正（マルチラベルのone modelではなくクラスごとに206個モデル作る方法）
　→
・notebook, discussion確認して気になったの試す
    - https://www.kaggle.com/c/lish-moa/discussion/191545 で書いてるようにデータ不均衡の対策をしたい
　→
・TGAN(テーブルデータのGAN)で学習データ水増し（noiseが増えるだけで失敗しそうだが）
　→1epoch3000時間もかかるといわれたためあきらめる
　　改良版のCTGANもうまくいかないらしいので
　　https://www.kaggle.com/c/lish-moa/discussion/193358
・加重平均のモデルブレンディングの重みをネルダーミードで最適化
　→ネルダーミードした方がoof下がるが、LBは悪くなった

20201028
・PCAが有効だと言ってるディスカッション探す
　→
　→
　　https://www.kaggle.com/c/lish-moa/discussion/193532

・LightGBMを1モデルでマルチラベル学習。他のsklearnのモデルでも試せるようにする

・
自分で試したのだと、
PCAはsklearn.preprocessingのRobustScalerやStandardScalerと組み合わせでcv 0.00007ぐらい下がってました 

train setだけでPCAしたらshakeup する可能性あるとディスカッション出てますね
https://www.kaggle.com/c/lish-moa/discussion/193532
----------------------------------------------------------------------------

20201030
◆来週試したいこと
・MLPでスコア上げる
	- パラメータチューニング
		- https://www.kaggle.com/fchollet/moa-keras-kerastuner-best-practices/?utm_campaign=piqcy&utm_medium=email&utm_source=Revue+newsletter
・LightGBM + ClassifierChain

・TabNetの論文確認（https://arxiv.org/pdf/1908.07442.pdf）
・TabNetでスコア上げる
	- https://www.kaggle.com/hiramcho/moa-tabnet-with-pca-rank-gauss

・sklernでほかのモデル作成してアンサンブル

・RNN (https://www.kaggle.com/c/lish-moa/discussion/193583)

・異常検知
	- https://www.kaggle.com/rahulsd91/moa-anomaly-detection

・不均衡対策
	- バッチ内でラベルのバランス保つように学習
		- https://devblog.thebase.in/entry/2020/02/29/110000
	- MLSMOTE
		- https://www.kaggle.com/anonamename/upsampling-multilabel-data-with-mlsmote/edit

・同種の薬のレコード見つける
	- 統制群に対する値や散布図かく？
	
・マルチラベルコンペの上位解法参考にする
	-https://www.kaggle.com/c/lish-moa/discussion/180092
