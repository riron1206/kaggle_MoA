＜MoAコンペで得られた使える技術など振り返り＞

- コンペの前提条件
	- マルチラベル分類(targetは206クラス)
	- テーブルデータ
	- 特徴量はほぼ連続値。カテゴリ型の列3つだけ
	- ラベルは非常に不均衡（0のラベルが大半で1のラベルが非常に少ない）
	- cvとLBが完全には相関してない（おみくじコンペ）

- 特に有効だった技術
	- TabNet
	- mixup, cutmixによるデータ増強
	- label smoothing
	- 複数モデルのアンサンブル。クラスごとにブレンドする重み最適化
	- adabeliefのオプティマイザ
	- WeightNormalizationを入れたMLP
	- Skip Connectionを使ったMLP
	- 1,2層程度の浅いMLPを弱モデルとしてブースティングするGrowNet

- やや有効だった技術
	- 特徴量の値クリッピング（上位99%, 下位1%の値までにする）
	- 特徴量の行統計(mean, std, kurtosis, skew)
	- Self-Stacking（第1段階の予測値を第2段階の学習の追加特徴量とし、クラス間の関係性を学習させる） + 2クラス分類のGBMT
	- 予測対象ではないnon-targetのクラスもマルチラベルで学習してnon-targetの誤差もモデルに取り込むことで精度向上狙う

- うまくいかなかった技術
	- LB上位者は使ってるが全体的に特徴量エンジニアリングはうまくいかず（cutmixと相性悪かった）
	- PCAで圧縮した特徴量
	- RankGaussで特徴量規格化
	- kmeansでグルーピングした特徴量
	- VarianceThresholdで分散低い特徴量削除
	
- その他
	- 同じ条件なのにpytorch版の方がtensorflow版よりも性能良いケースが多かった
	→pytorch使いになるべきなんだなあ…
	
	

- 結論
■モデル
　連続値のテーブルデータでマルチラベルを扱う場合はDNNでGBMTを模倣するTabNetが最適
　2位がMLPやGrowNet(※GrowNetはきれいなパッケージになってないので汎用的には使いにくいが)
　3位がLightGBMなどのGBMT
　4位以降がSVM、KNN
　（検証してないが）マルチクラスでも同じだと思う。2クラス分類はわからないが
　
　これまでの経験上、カテゴリデータを多く含むテーブルデータを扱う場合は
　LightGBMなどのGBMT が最適と思われる
　（検証してないので）この場合もTabNet が勝つかもしれないが

■テーブルデータでもcutmix有効
　label smoothing と同じような効果なのでlabel smoothingがうまくいく場合はcutmixもうまくいくはず

■（不均衡ラベルのマルチラベルで？）アンサンブルする場合
　クラスごとに予測値ブレンドする重みを最適化することで精度グッと上がる
　ただし、最適化のチューニングが難しい

■DNNのオプティマイザはadabeliefが良い
　少なくともAdamよりもloss下げてくれた

■マルチラベルでは予測対象ではないnon-targetのクラスも学習クラスに含めるのが有効な場合あり
　今回はあまり効かず最終サブでは使わなかったが

■クラス間の関係性を学習させるSelf-Stacking の考え方はおもしろかった
　処理煩雑なので実案件で使うかというと微妙だが

■LBよりcvを信じてサブミットするのが大事
　shake up/downがめちゃめちゃ起きた
