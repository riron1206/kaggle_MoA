{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:37.337821Z",
     "start_time": "2020-11-16T12:25:37.333804Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import re\n",
    "import math\n",
    "import pickle\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:38.141342Z",
     "start_time": "2020-11-16T12:25:38.137352Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    rn.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:38.820504Z",
     "start_time": "2020-11-16T12:25:38.816509Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def score(Y, Y_pred):\n",
    "    _, n_classes = Y.shape\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for j in range(n_classes):\n",
    "        loss = log_loss(Y.iloc[:, j], Y_pred.iloc[:, j], labels=[0, 1])\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:39.719074Z",
     "start_time": "2020-11-16T12:25:39.695137Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('../input/iterativestratification')\n",
    "\n",
    "import numpy as np\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "\n",
    "\n",
    "class MultilabelGroupStratifiedKFold(_BaseKFold):\n",
    "    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n",
    "        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "\n",
    "    def _iter_test_indices(self, X=None, y=None, groups=None):\n",
    "        cv = MultilabelStratifiedKFold(\n",
    "            n_splits=self.n_splits,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=self.shuffle,\n",
    "        )\n",
    "\n",
    "        value_counts = groups.value_counts()\n",
    "        regular_index = value_counts.loc[\n",
    "            (value_counts == 6) | (value_counts == 12) | (value_counts == 18)\n",
    "        ].index.sort_values()\n",
    "        irregular_index = value_counts.loc[\n",
    "            (value_counts != 6) & (value_counts != 12) & (value_counts != 18)\n",
    "        ].index.sort_values()\n",
    "\n",
    "        group_to_fold = {}\n",
    "        tmp = Y.groupby(groups).mean().loc[regular_index]\n",
    "\n",
    "        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n",
    "            group_to_fold.update({group: fold for group in tmp.index[test]})\n",
    "\n",
    "        sample_to_fold = {}\n",
    "        tmp = Y.loc[groups.isin(irregular_index)]\n",
    "\n",
    "        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n",
    "            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n",
    "\n",
    "        folds = groups.map(group_to_fold)\n",
    "        is_na = folds.isna()\n",
    "        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            yield np.where(folds == i)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:40.715349Z",
     "start_time": "2020-11-16T12:25:40.710362Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class ClippedFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, copy=True, high=0.99, low=0.01):\n",
    "        self.copy = copy\n",
    "        self.high = high\n",
    "        self.low = low\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.data_max_ = X.quantile(q=self.high)\n",
    "        self.data_min_ = X.quantile(q=self.low)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.copy:\n",
    "            X = X.copy()\n",
    "\n",
    "        X.clip(self.data_min_, self.data_max_, axis=1, inplace=True)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:41.695728Z",
     "start_time": "2020-11-16T12:25:41.692736Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def compute_row_statistics(X, prefix=\"\"):\n",
    "    Xt = pd.DataFrame()\n",
    "\n",
    "    for agg_func in [\n",
    "        # \"min\",\n",
    "        # \"max\",\n",
    "        \"mean\",\n",
    "        \"std\",\n",
    "        \"kurtosis\",\n",
    "        \"skew\",\n",
    "    ]:\n",
    "        Xt[f\"{prefix}{agg_func}\"] = X.agg(agg_func, axis=1)\n",
    "\n",
    "    return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:43.193941Z",
     "start_time": "2020-11-16T12:25:42.413836Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_importances(\n",
    "    importance_df, png_path=f\"feature_importance.png\",\n",
    "):\n",
    "    \"\"\"feature_importance plot\"\"\"\n",
    "    importance_df.sort_values(by=\"importance\", ascending=False).to_csv(f\"feature_importance.csv\")\n",
    "    cols = (\n",
    "        importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:100]\n",
    "        .index\n",
    "    )\n",
    "    best_features = importance_df.loc[importance_df.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 15))\n",
    "    sns.barplot(\n",
    "        x=\"importance\",\n",
    "        y=\"feature\",\n",
    "        data=best_features.sort_values(by=\"importance\", ascending=False),\n",
    "    )\n",
    "    plt.title(\"LightGBM (avg over folds)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(png_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:43.603139Z",
     "start_time": "2020-11-16T12:25:43.599937Z"
    }
   },
   "outputs": [],
   "source": [
    "# dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\n",
    "# index_col = \"sig_id\"\n",
    "#\n",
    "# train_features = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_features.csv\", dtype=dtype, index_col=index_col\n",
    "# )\n",
    "# X = train_features.select_dtypes(\"number\")\n",
    "# Y_nonscored = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_targets_nonscored.csv\", index_col=index_col\n",
    "# )\n",
    "# Y = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\n",
    "# groups = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n",
    "# )\n",
    "#\n",
    "# columns = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:47.748492Z",
     "start_time": "2020-11-16T12:25:44.800508Z"
    }
   },
   "outputs": [],
   "source": [
    "DATADIR = (\n",
    "    r\"C:\\Users\\81908\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\input\\lish-moa\"\n",
    ")\n",
    "\n",
    "dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\n",
    "index_col = \"sig_id\"\n",
    "\n",
    "train_features = pd.read_csv(\n",
    "    f\"{DATADIR}/train_features.csv\", dtype=dtype, index_col=index_col\n",
    ")\n",
    "X = train_features.select_dtypes(\"number\")\n",
    "Y_nonscored = pd.read_csv(\n",
    "    f\"{DATADIR}/train_targets_nonscored.csv\", index_col=index_col\n",
    ")\n",
    "Y = pd.read_csv(f\"{DATADIR}/train_targets_scored.csv\", index_col=index_col)\n",
    "groups = pd.read_csv(\n",
    "    f\"{DATADIR}/train_drug.csv\", index_col=index_col, squeeze=True\n",
    ")\n",
    "\n",
    "columns = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:49.731910Z",
     "start_time": "2020-11-16T12:25:47.749489Z"
    }
   },
   "outputs": [],
   "source": [
    "clipped_features = ClippedFeatures()\n",
    "X = clipped_features.fit_transform(X)\n",
    "\n",
    "with open(\"clipped_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clipped_features, f)\n",
    "# アンサンブルのために統計値, nonscoredは入れない \n",
    "#c_prefix = \"c-\"\n",
    "#g_prefix = \"g-\"\n",
    "#c_columns = X.columns.str.startswith(c_prefix)\n",
    "#g_columns = X.columns.str.startswith(g_prefix)\n",
    "#X_c = compute_row_statistics(X.loc[:, c_columns], prefix=c_prefix)\n",
    "#X_g = compute_row_statistics(X.loc[:, g_columns], prefix=g_prefix)\n",
    "#X = pd.concat([X, X_c, X_g], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:33:30.156752Z",
     "start_time": "2020-11-16T12:33:30.148773Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(params):\n",
    "\n",
    "    _count = 0\n",
    "    counts = np.empty((n_seeds * len(columns) * n_splits))\n",
    "\n",
    "    f_importance = np.zeros((n_features,))\n",
    "    Y_pred = np.zeros((train_size, n_classes))\n",
    "    Y_pred = pd.DataFrame(Y_pred, columns=Y.columns, index=Y.index)\n",
    "\n",
    "    for i in range(n_seeds):\n",
    "        set_seed(seed=i)\n",
    "\n",
    "        for tar_i, tar_col in tqdm(enumerate(Y.columns)):\n",
    "            Y_target = Y[[tar_col]]\n",
    "\n",
    "            if is_drug_cv:\n",
    "                cv = MultilabelGroupStratifiedKFold(\n",
    "                    n_splits=n_splits, random_state=i, shuffle=True\n",
    "                )\n",
    "                cv_split = cv.split(X, Y_target, groups)\n",
    "            else:\n",
    "                StratifiedKFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "                cv_split = cv.split(X, Y_target)\n",
    "\n",
    "            for j, (trn_idx, val_idx) in enumerate(cv_split):\n",
    "                print(f\"\\n------------ fold:{j} ------------\")\n",
    "                counts[_count] = Y_target.iloc[trn_idx].sum()\n",
    "\n",
    "                X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "                Y_train, Y_val = Y_target.iloc[trn_idx], Y_target.iloc[val_idx]\n",
    "\n",
    "                # Label Smoothing. https://www.kaggle.com/gogo827jz/self-stacking-groupcv-xgboost\n",
    "                Y_train = Y_train * (1 - LBS) + 0.5 * LBS\n",
    "\n",
    "                lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "                lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    "\n",
    "                model = lgb.train(\n",
    "                    params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_eval],\n",
    "                    verbose_eval=verbose_eval,\n",
    "                    num_boost_round=num_boost_round,\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                )\n",
    "                Y_pred[tar_col][val_idx] += (\n",
    "                    model.predict(X_val, num_iteration=model.best_iteration) / n_seeds\n",
    "                )\n",
    "\n",
    "                # f_importance += np.array(model.feature_importance(importance_type=\"gain\")) / (n_seeds * n_splits)\n",
    "\n",
    "                joblib.dump(\n",
    "                    model,\n",
    "                    f\"model_seed_{i}_fold_{j}_{Y.columns[tar_i]}.jlb\",\n",
    "                    compress=True,\n",
    "                )\n",
    "                _count += 1\n",
    "\n",
    "    # importance_df = pd.DataFrame({\"feature\": model.feature_name(), \"importance\": f_importance})\n",
    "\n",
    "    Y_pred[train_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n",
    "\n",
    "    with open(\"counts.pkl\", \"wb\") as f:\n",
    "        pickle.dump(counts, f)\n",
    "\n",
    "    with open(\"Y_pred.pkl\", \"wb\") as f:\n",
    "        pickle.dump(Y_pred[columns], f)\n",
    "\n",
    "    oof = score(Y[columns], Y_pred[columns])\n",
    "\n",
    "    return oof, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:25:59.924195Z",
     "start_time": "2020-11-16T12:25:59.266422Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"learning_rate\": 0.1,\n",
    "    }\n",
    "    params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 3)\n",
    "    params[\"num_leaves\"] = trial.suggest_int(\"num_leaves\", 2, 4)\n",
    "    params[\"min_data_in_leaf\"] = trial.suggest_int(\n",
    "        \"min_data_in_leaf\", \n",
    "        1, \n",
    "        max(1, int(X.shape[0] * ((n_splits - 1) / n_splits) / params[\"num_leaves\"])),\n",
    "    )\n",
    "    params[\"feature_fraction\"] = trial.suggest_discrete_uniform(\"feature_fraction\", 0.1, 1.0, 0.05)\n",
    "    params[\"lambda_l1\"] = trial.suggest_loguniform(\"lambda_l1\", 1e-09, 10.0)\n",
    "    params[\"lambda_l2\"] = trial.suggest_loguniform(\"lambda_l2\", 1e-09, 10.0)\n",
    "\n",
    "    if DEBUG:\n",
    "        params[\"n_estimators\"] = 2\n",
    "    #else:\n",
    "    #    params[\"n_estimators\"] = 1000\n",
    "    \n",
    "    oof, _ = train_and_evaluate(params)\n",
    "    \n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:30:12.963948Z",
     "start_time": "2020-11-16T12:30:12.957964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: True\n"
     ]
    }
   ],
   "source": [
    "is_drug_cv = True\n",
    "n_splits = 5\n",
    "n_seeds = 1\n",
    "#LBS = 0.0008  # ラベルスムージングは全然効かないからやめる\n",
    "LBS = 0.0\n",
    "\n",
    "n_trials = 50\n",
    "#params = {\n",
    "#    \"num_leaves\": 2,\n",
    "#    \"max_depth\": 1,\n",
    "#    \"min_data_in_leaf\": 969,\n",
    "#    \"objective\": \"binary\",\n",
    "#    \"learning_rate\": 0.01,\n",
    "#}\n",
    "num_boost_round = 2000\n",
    "verbose_eval = 100\n",
    "# verbose_eval = 0  # 0なら学習履歴出さないが、warningは出るので意味なし\n",
    "#num_boost_round = 50000\n",
    "#verbose_eval = 1000\n",
    "early_stopping_rounds = 100\n",
    "\n",
    "DEBUG = True\n",
    "#DEBUG = False\n",
    "if DEBUG:\n",
    "    columns = [\n",
    "        \"atp-sensitive_potassium_channel_antagonist\",  # 陽性ラベル1個だけ\n",
    "        \"erbb2_inhibitor\",  # 陽性ラベル1個だけ\n",
    "        \"antiarrhythmic\",  # 陽性ラベル6個だけ\n",
    "#        \"aldehyde_dehydrogenase_inhibitor\",  # 陽性ラベル7個だけ\n",
    "#        \"lipase_inhibitor\",  # 陽性ラベル12個だけ\n",
    "#        \"sphingosine_receptor_agonist\",  # 陽性ラベル25個だけ\n",
    "#        \"igf-1_inhibitor\",  # 陽性ラベル37個だけ\n",
    "#        \"potassium_channel_activator\",  # 陽性ラベル55個だけ\n",
    "#        \"potassium_channel_antagonist\",  # 陽性ラベル98個だけ\n",
    "#        \"dopamine_receptor_agonist\",  # 陽性ラベル121個だけ\n",
    "#        \"nfkb_inhibitor\",  # 陽性ラベル832個\n",
    "#        \"cyclooxygenase_inhibitor\",  # 陽性ラベル435個\n",
    "#        \"dna_inhibitor\",  # 陽性ラベル402個\n",
    "#        \"glutamate_receptor_antagonist\",  # 陽性ラベル367個\n",
    "#        \"tubulin_inhibitor\",  # 陽性ラベル316個\n",
    "#        \"pdgfr_inhibitor\",  # 陽性ラベル297個\n",
    "#        \"calcium_channel_blocker\",  # 陽性ラベル281個\n",
    "#        \"flt3_inhibitor\",  # 陽性ラベル279個\n",
    "#        \"progesterone_receptor_agonist\",  # 陽性ラベル119個\n",
    "#        \"hdac_inhibitor\",  # 陽性ラベル106個\n",
    "    ]\n",
    "    Y = Y[columns]\n",
    "    \n",
    "    n_trials = 3\n",
    "    #params[\"n_estimators\"] = 2\n",
    "    n_splits = 2\n",
    "    num_boost_round = 100\n",
    "    verbose_eval = num_boost_round\n",
    "    early_stopping_rounds = verbose_eval\n",
    "    print(f\"DEBUG: {DEBUG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:30:16.108846Z",
     "start_time": "2020-11-16T12:30:16.105854Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size, n_features = X.shape\n",
    "_, n_classes_nonscored = Y_nonscored.shape\n",
    "_, n_classes = Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T06:27:14.560588Z",
     "start_time": "2020-11-16T03:52:51.192677Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"study\",\n",
    "    storage=f\"sqlite:///study.db\",\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=1),\n",
    ")\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "study.trials_dataframe().to_csv(f\"objective_history.csv\", index=False)\n",
    "with open(f\"objective_best_params.txt\", mode=\"w\") as f:\n",
    "    f.write(str(study.best_params))\n",
    "print(f\"\\nstudy.best_params:\\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:33:56.902641Z",
     "start_time": "2020-11-16T12:33:35.541195Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ fold:0 ------------\n",
      "[LightGBM] [Warning] Contains only one class\n",
      "[LightGBM] [Info] Number of positive: 0, number of negative: 11922\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222364\n",
      "[LightGBM] [Info] Number of data points in the train set: 11922, number of used features: 873\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.00290437\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.00290437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ fold:1 ------------\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 11891\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222364\n",
      "[LightGBM] [Info] Number of data points in the train set: 11892, number of used features: 873\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000084 -> initscore=-9.383537\n",
      "[LightGBM] [Info] Start training from score -9.383537\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's binary_logloss: 9.09422e-05\tvalid_1's binary_logloss: 7.16843e-05\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 9.09422e-05\tvalid_1's binary_logloss: 7.16843e-05\n",
      "\n",
      "------------ fold:0 ------------\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 11921\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222364\n",
      "[LightGBM] [Info] Number of data points in the train set: 11922, number of used features: 873\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000084 -> initscore=-9.386057\n",
      "[LightGBM] [Info] Start training from score -9.386057\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's binary_logloss: 8.90764e-05\tvalid_1's binary_logloss: 5.19944e-05\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 8.90764e-05\tvalid_1's binary_logloss: 5.19944e-05\n",
      "\n",
      "------------ fold:1 ------------\n",
      "[LightGBM] [Warning] Contains only one class\n",
      "[LightGBM] [Info] Number of positive: 0, number of negative: 11892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222364\n",
      "[LightGBM] [Info] Number of data points in the train set: 11892, number of used features: 873\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.00289706\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.00289706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:13,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ fold:0 ------------\n",
      "[LightGBM] [Warning] Contains only one class\n",
      "[LightGBM] [Info] Number of positive: 0, number of negative: 11922\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222364\n",
      "[LightGBM] [Info] Number of data points in the train set: 11922, number of used features: 873\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776\n",
      "[LightGBM] [Info] Start training from score -34.538776\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.0174262\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0\tvalid_1's binary_logloss: 0.0174262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ fold:1 ------------\n",
      "[LightGBM] [Info] Number of positive: 6, number of negative: 11886\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222364\n",
      "[LightGBM] [Info] Number of data points in the train set: 11892, number of used features: 873\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000505 -> initscore=-7.591357\n",
      "[LightGBM] [Info] Start training from score -7.591357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's binary_logloss: 0.000442303\tvalid_1's binary_logloss: 0.00020471\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.000442303\tvalid_1's binary_logloss: 0.00020471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:21,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0039183931579720435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#params = study.best_params\n",
    "params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"learning_rate\": 0.01,\n",
    "    }\n",
    "# params[\"n_estimators\"] = 100  # default param\n",
    "\n",
    "oof, Y_pred = train_and_evaluate(params)\n",
    "print(oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Platt Scaling\n",
    "Train a Logistic Regression model to calibrate the results\n",
    "- https://www.kaggle.com/gogo827jz/kernel-logistic-regression-one-for-206-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:00:00.079093Z",
     "start_time": "2020-11-16T03:52:44.885Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict_probaでだしたY_predをロジスティク回帰で確率に補正する\n",
    "# （Sigmoid関数にフィットさせ、そのSigmoid関数に通した値をCalibrationした値とする）\n",
    "\n",
    "counts = np.empty((n_classes))\n",
    "\n",
    "X_new = Y_pred.values\n",
    "Y_cali = Y_pred.copy()\n",
    "\n",
    "for tar in tqdm(range(Y.shape[1])):\n",
    "    \n",
    "    targets = Y.values[:, tar]\n",
    "    X_targets = X_new[:, tar]\n",
    "    counts[tar] = targets.sum()\n",
    "\n",
    "    if targets.sum() >= n_splits:\n",
    "\n",
    "        Y_cali[Y.columns[tar]] = np.zeros((Y_cali.shape[0], ))\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "\n",
    "        for n, (tr, te) in enumerate(skf.split(targets, targets)):\n",
    "            x_tr, x_val = X_targets[tr].reshape(-1, 1), X_targets[te].reshape(-1, 1)\n",
    "            y_tr, y_val = targets[tr], targets[te]\n",
    "\n",
    "            model = LogisticRegression(penalty=\"none\", max_iter=1000)\n",
    "            model.fit(x_tr, y_tr)\n",
    "            Y_cali[Y.columns[tar]].iloc[te] += model.predict_proba(x_val)[:, 1]\n",
    "            \n",
    "            joblib.dump(model, f\"calibrate_model_target_{Y.columns[tar]}.jlb\", compress=True)\n",
    "\n",
    "with open(\"counts_calibrate.pkl\", \"wb\") as f:\n",
    "    pickle.dump(counts, f)\n",
    "\n",
    "with open(\"Y_pred_calibrate.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Y_cali[columns], f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:00:00.080091Z",
     "start_time": "2020-11-16T03:52:44.886Z"
    }
   },
   "outputs": [],
   "source": [
    "score(Y[columns], Y_cali[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pkl check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T12:34:02.855744Z",
     "start_time": "2020-11-16T12:34:02.851755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 0., 6.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"counts.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    counts = pickle.load(f)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:00:00.081088Z",
     "start_time": "2020-11-16T03:52:44.888Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"counts_calibrate.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    counts = pickle.load(f)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:00:00.082085Z",
     "start_time": "2020-11-16T03:52:44.890Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"Y_pred.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    Y_pred = pickle.load(f)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:00:00.083083Z",
     "start_time": "2020-11-16T03:52:44.892Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"Y_pred_calibrate.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    Y_pred = pickle.load(f)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T08:00:00.083083Z",
     "start_time": "2020-11-16T03:52:44.894Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pathlib\n",
    "\n",
    "test_features = pd.read_csv(\n",
    "    #\"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n",
    "    f\"{DATADIR}/test_features.csv\",\n",
    "    dtype=dtype,\n",
    "    index_col=index_col,\n",
    ")\n",
    "X_test = test_features.select_dtypes(\"number\")\n",
    "\n",
    "\n",
    "with open(\"./clipped_features.pkl\", \"rb\") as f:\n",
    "    clipped_features = pickle.load(f)\n",
    "X_test = clipped_features.transform(X_test)\n",
    "# アンサンブルのため統計値, nonscoredは入れない \n",
    "#X_c = compute_row_statistics(X_test.loc[:, c_columns], prefix=c_prefix)\n",
    "#X_g = compute_row_statistics(X_test.loc[:, g_columns], prefix=g_prefix)\n",
    "#X_test = pd.concat([X_test, X_c, X_g], axis=1)\n",
    "\n",
    "\n",
    "# lgbで予測\n",
    "Y_test_pred = np.zeros((X_test.shape[0], len(columns)))\n",
    "Y_test_pred = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\n",
    "for target in columns:\n",
    "    model_paths = glob.glob(f\"./model_seed_*_{target}.jlb\")\n",
    "    for model_path in model_paths:\n",
    "        model = joblib.load(model_path)\n",
    "        Y_test_pred[target] += model.predict(X_test) / len(model_paths)\n",
    "print(Y_test_pred.shape)\n",
    "display(Y_test_pred)\n",
    "\n",
    "\n",
    "# lgbの予測値補正\n",
    "model_paths = glob.glob(f\"./calibrate_model_target_*.jlb\")\n",
    "for model_path in model_paths:\n",
    "    target = str(pathlib.Path(model_path).stem).replace(\"calibrate_model_target_\", \"\")\n",
    "\n",
    "    if target in columns:\n",
    "        # print(target)\n",
    "        model = joblib.load(model_path)\n",
    "        X_targets = Y_test_pred.loc[:, target].values.reshape(-1, 1)\n",
    "        Y_test_pred.loc[:, target] = model.predict_proba(X_targets)[:, 1]\n",
    "\n",
    "print(Y_test_pred.shape)\n",
    "display(Y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
