{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tmhrkt/grownet-gradient-boosting-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:34:01.311202Z",
     "start_time": "2020-11-20T07:34:01.030580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/81908/jupyter_notebook/pytorch_work/grownet_pytorch/20201119_objective\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\81908\\\\Anaconda3\\\\envs\\\\pytorch\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pwd\n",
    "import sys\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:34:02.074284Z",
     "start_time": "2020-11-20T07:34:01.757700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# GPU使えてるか確認\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:34:09.416771Z",
     "start_time": "2020-11-20T07:34:02.433537Z"
    }
   },
   "outputs": [],
   "source": [
    "import grownet_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test run\n",
    "- Kernel restart しないと前の結果が残るので注意！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T08:42:22.876629Z",
     "start_time": "2020-11-20T08:40:41.682086Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dda4df843940bab65a14ebb960d230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  1.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01938\n",
      "Stage - 1, training time:  3.1 sec, boost rate:  1.0226, Training Loss:  0.02073, Val Loss:  0.01698\n",
      "Stage - 2, training time:  3.7 sec, boost rate:  1.0404, Training Loss:  0.01937, Val Loss:  0.01670\n",
      "Stage - 3, training time:  4.4 sec, boost rate:  1.0555, Training Loss:  0.01843, Val Loss:  0.01651\n",
      "Stage - 4, training time:  4.9 sec, boost rate:  1.0713, Training Loss:  0.01793, Val Loss:  0.01636\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01896\n",
      "Stage - 1, training time:  3.2 sec, boost rate:  1.0258, Training Loss:  0.02069, Val Loss:  0.01691\n",
      "Stage - 2, training time:  3.8 sec, boost rate:  1.0447, Training Loss:  0.01937, Val Loss:  0.01652\n",
      "Stage - 3, training time:  4.3 sec, boost rate:  1.0602, Training Loss:  0.01844, Val Loss:  0.01638\n",
      "Stage - 4, training time:  5.0 sec, boost rate:  1.0761, Training Loss:  0.01790, Val Loss:  0.01631\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01956\n",
      "Stage - 1, training time:  3.2 sec, boost rate:  1.0180, Training Loss:  0.02068, Val Loss:  0.01709\n",
      "Stage - 2, training time:  3.8 sec, boost rate:  1.0371, Training Loss:  0.01932, Val Loss:  0.01682\n",
      "Stage - 3, training time:  4.3 sec, boost rate:  1.0528, Training Loss:  0.01838, Val Loss:  0.01654\n",
      "Stage - 4, training time:  4.9 sec, boost rate:  1.0689, Training Loss:  0.01787, Val Loss:  0.01661\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01979\n",
      "Stage - 1, training time:  3.2 sec, boost rate:  1.0187, Training Loss:  0.02065, Val Loss:  0.01713\n",
      "Stage - 2, training time:  3.7 sec, boost rate:  1.0399, Training Loss:  0.01933, Val Loss:  0.01680\n",
      "Stage - 3, training time:  4.3 sec, boost rate:  1.0559, Training Loss:  0.01837, Val Loss:  0.01652\n",
      "Stage - 4, training time:  4.8 sec, boost rate:  1.0720, Training Loss:  0.01787, Val Loss:  0.01654\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01931\n",
      "Stage - 1, training time:  3.2 sec, boost rate:  1.0179, Training Loss:  0.02076, Val Loss:  0.01690\n",
      "Stage - 2, training time:  3.7 sec, boost rate:  1.0361, Training Loss:  0.01950, Val Loss:  0.01636\n",
      "Stage - 3, training time:  4.4 sec, boost rate:  1.0519, Training Loss:  0.01852, Val Loss:  0.01613\n",
      "Stage - 4, training time:  4.8 sec, boost rate:  1.0668, Training Loss:  0.01801, Val Loss:  0.01611\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.016219369914021786\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T08:45:00.680817Z",
     "start_time": "2020-11-20T08:42:33.439653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 16, 'model': 'MLP_2HL', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3293ca13c94e19918a479c42e91384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  9.6 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02392\n",
      "Stage - 1, training time:  29.8 sec, boost rate:  1.0426, Training Loss:  0.02405, Val Loss:  0.02110\n",
      "Stage - 2, training time:  38.1 sec, boost rate:  1.1782, Training Loss:  0.02364, Val Loss:  0.02098\n",
      "Stage - 3, training time:  47.7 sec, boost rate:  1.2672, Training Loss:  0.02349, Val Loss:  0.02080\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-60283244fcbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_nets\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\jupyter_notebook\\pytorch_work\\grownet_pytorch\\20201119_objective\\grownet_funcs.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[1;34m(n_seeds)\u001b[0m\n\u001b[0;32m    672\u001b[0m                             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_f2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m                             \u001b[0mstage_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 16\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:31:06.941882Z",
     "start_time": "2020-11-20T09:30:02.419476Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 1024, 'model': 'MLP_2HL', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ea3b1a9fb346d9bd19703527d88ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  2.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01995\n",
      "Stage - 1, training time:  1.9 sec, boost rate:  1.0060, Training Loss:  0.02165, Val Loss:  0.01787\n",
      "Stage - 2, training time:  2.0 sec, boost rate:  1.0144, Training Loss:  0.02020, Val Loss:  0.01715\n",
      "Stage - 3, training time:  2.2 sec, boost rate:  1.0190, Training Loss:  0.01931, Val Loss:  0.01691\n",
      "Stage - 4, training time:  2.4 sec, boost rate:  1.0237, Training Loss:  0.01885, Val Loss:  0.01674\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  0.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01948\n",
      "Stage - 1, training time:  1.9 sec, boost rate:  1.0070, Training Loss:  0.02156, Val Loss:  0.01779\n",
      "Stage - 2, training time:  2.0 sec, boost rate:  1.0155, Training Loss:  0.02019, Val Loss:  0.01699\n",
      "Stage - 3, training time:  2.2 sec, boost rate:  1.0201, Training Loss:  0.01929, Val Loss:  0.01675\n",
      "Stage - 4, training time:  2.4 sec, boost rate:  1.0247, Training Loss:  0.01884, Val Loss:  0.01658\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  0.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02000\n",
      "Stage - 1, training time:  1.9 sec, boost rate:  1.0038, Training Loss:  0.02165, Val Loss:  0.01803\n",
      "Stage - 2, training time:  2.0 sec, boost rate:  1.0122, Training Loss:  0.02018, Val Loss:  0.01715\n",
      "Stage - 3, training time:  2.2 sec, boost rate:  1.0169, Training Loss:  0.01931, Val Loss:  0.01696\n",
      "Stage - 4, training time:  2.4 sec, boost rate:  1.0216, Training Loss:  0.01884, Val Loss:  0.01678\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  0.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01983\n",
      "Stage - 1, training time:  1.9 sec, boost rate:  1.0091, Training Loss:  0.02149, Val Loss:  0.01818\n",
      "Stage - 2, training time:  2.1 sec, boost rate:  1.0169, Training Loss:  0.02019, Val Loss:  0.01733\n",
      "Stage - 3, training time:  2.2 sec, boost rate:  1.0214, Training Loss:  0.01925, Val Loss:  0.01702\n",
      "Stage - 4, training time:  2.4 sec, boost rate:  1.0260, Training Loss:  0.01882, Val Loss:  0.01695\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  0.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01988\n",
      "Stage - 1, training time:  1.9 sec, boost rate:  1.0039, Training Loss:  0.02168, Val Loss:  0.01775\n",
      "Stage - 2, training time:  2.1 sec, boost rate:  1.0122, Training Loss:  0.02020, Val Loss:  0.01696\n",
      "Stage - 3, training time:  2.2 sec, boost rate:  1.0168, Training Loss:  0.01933, Val Loss:  0.01662\n",
      "Stage - 4, training time:  2.3 sec, boost rate:  1.0213, Training Loss:  0.01889, Val Loss:  0.01646\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.016516694629806216\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 1024\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:33:13.337574Z",
     "start_time": "2020-11-20T09:31:16.227715Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9480bdc5a42644dbaeb563dd4940de2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  3.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01942\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0234, Training Loss:  0.02082, Val Loss:  0.01705\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0398, Training Loss:  0.01938, Val Loss:  0.01671\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0548, Training Loss:  0.01837, Val Loss:  0.01657\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0705, Training Loss:  0.01782, Val Loss:  0.01643\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01901\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0280, Training Loss:  0.02077, Val Loss:  0.01694\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0445, Training Loss:  0.01937, Val Loss:  0.01650\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0597, Training Loss:  0.01836, Val Loss:  0.01641\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0756, Training Loss:  0.01777, Val Loss:  0.01628\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01956\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0195, Training Loss:  0.02074, Val Loss:  0.01711\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0366, Training Loss:  0.01930, Val Loss:  0.01683\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0525, Training Loss:  0.01831, Val Loss:  0.01654\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.0688, Training Loss:  0.01772, Val Loss:  0.01665\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01979\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0206, Training Loss:  0.02073, Val Loss:  0.01716\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0399, Training Loss:  0.01930, Val Loss:  0.01682\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0556, Training Loss:  0.01828, Val Loss:  0.01657\n",
      "Stage - 4, training time:  5.3 sec, boost rate:  1.0720, Training Loss:  0.01772, Val Loss:  0.01654\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01944\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0124, Training Loss:  0.02086, Val Loss:  0.01693\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0304, Training Loss:  0.01944, Val Loss:  0.01646\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0471, Training Loss:  0.01844, Val Loss:  0.01620\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0627, Training Loss:  0.01785, Val Loss:  0.01614\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.016213490552680582\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:39:57.019186Z",
     "start_time": "2020-11-20T09:37:59.013401Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.01, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6f50515dbf404ba89acfc30d42c0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  3.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01982\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0592, Training Loss:  0.02105, Val Loss:  0.01735\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.1701, Training Loss:  0.02016, Val Loss:  0.01722\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.2520, Training Loss:  0.01968, Val Loss:  0.01694\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.3262, Training Loss:  0.01950, Val Loss:  0.01681\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01969\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0353, Training Loss:  0.02107, Val Loss:  0.01748\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.1425, Training Loss:  0.02021, Val Loss:  0.01703\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.2219, Training Loss:  0.01971, Val Loss:  0.01667\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.3123, Training Loss:  0.01950, Val Loss:  0.01677\n",
      "Best validation stage: 3\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02018\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0209, Training Loss:  0.02099, Val Loss:  0.01752\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.1450, Training Loss:  0.02014, Val Loss:  0.01735\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.2292, Training Loss:  0.01957, Val Loss:  0.01697\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.3069, Training Loss:  0.01942, Val Loss:  0.01692\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02028\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0093, Training Loss:  0.02102, Val Loss:  0.01759\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.1467, Training Loss:  0.02020, Val Loss:  0.01731\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.2365, Training Loss:  0.01963, Val Loss:  0.01703\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.3253, Training Loss:  0.01949, Val Loss:  0.01680\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02049\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  0.9961, Training Loss:  0.02114, Val Loss:  0.01722\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.1169, Training Loss:  0.02024, Val Loss:  0.01704\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.2236, Training Loss:  0.01970, Val Loss:  0.01662\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.3091, Training Loss:  0.01956, Val Loss:  0.01657\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.01656429156419679\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.01\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:25:26.948743Z",
     "start_time": "2020-11-20T09:23:30.300539Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.005, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31c036bda8a4fe387e64b4fca4ac369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  3.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01933\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  0.9661, Training Loss:  0.02069, Val Loss:  0.01705\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  0.9817, Training Loss:  0.01970, Val Loss:  0.01713\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0207, Training Loss:  0.01905, Val Loss:  0.01664\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.0589, Training Loss:  0.01883, Val Loss:  0.01665\n",
      "Best validation stage: 3\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01935\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  0.9694, Training Loss:  0.02065, Val Loss:  0.01710\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  0.9799, Training Loss:  0.01970, Val Loss:  0.01681\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0249, Training Loss:  0.01905, Val Loss:  0.01648\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0628, Training Loss:  0.01881, Val Loss:  0.01648\n",
      "Best validation stage: 3\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01940\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  0.9588, Training Loss:  0.02060, Val Loss:  0.01715\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  0.9741, Training Loss:  0.01967, Val Loss:  0.01717\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0168, Training Loss:  0.01896, Val Loss:  0.01669\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0573, Training Loss:  0.01872, Val Loss:  0.01668\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01970\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  0.9713, Training Loss:  0.02050, Val Loss:  0.01710\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  0.9963, Training Loss:  0.01960, Val Loss:  0.01693\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0459, Training Loss:  0.01889, Val Loss:  0.01660\n",
      "Stage - 4, training time:  5.5 sec, boost rate:  1.0835, Training Loss:  0.01866, Val Loss:  0.01669\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01928\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  0.9661, Training Loss:  0.02066, Val Loss:  0.01692\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  0.9801, Training Loss:  0.01980, Val Loss:  0.01667\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0234, Training Loss:  0.01910, Val Loss:  0.01623\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0640, Training Loss:  0.01881, Val Loss:  0.01621\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.01630781779814729\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.005\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:19:02.842823Z",
     "start_time": "2020-11-20T09:17:04.753938Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.0001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74577bcc217e413da854865a59dccd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  3.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01985\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0026, Training Loss:  0.02243, Val Loss:  0.01895\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0062, Training Loss:  0.02161, Val Loss:  0.01833\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0080, Training Loss:  0.02105, Val Loss:  0.01808\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0098, Training Loss:  0.02078, Val Loss:  0.01782\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01964\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0027, Training Loss:  0.02247, Val Loss:  0.01885\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0063, Training Loss:  0.02166, Val Loss:  0.01827\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0081, Training Loss:  0.02111, Val Loss:  0.01802\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0099, Training Loss:  0.02082, Val Loss:  0.01780\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01992\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0025, Training Loss:  0.02240, Val Loss:  0.01908\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0061, Training Loss:  0.02158, Val Loss:  0.01846\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0078, Training Loss:  0.02101, Val Loss:  0.01820\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0096, Training Loss:  0.02075, Val Loss:  0.01807\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01993\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0029, Training Loss:  0.02237, Val Loss:  0.01908\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0065, Training Loss:  0.02158, Val Loss:  0.01848\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0082, Training Loss:  0.02099, Val Loss:  0.01822\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0100, Training Loss:  0.02070, Val Loss:  0.01805\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01969\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0025, Training Loss:  0.02247, Val Loss:  0.01879\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0059, Training Loss:  0.02161, Val Loss:  0.01817\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0075, Training Loss:  0.02108, Val Loss:  0.01792\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.0092, Training Loss:  0.02077, Val Loss:  0.01772\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.017687059592309214\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.0001\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:49:54.877161Z",
     "start_time": "2020-11-20T09:46:38.977958Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2ff85997d14edca71f45e495198ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  5.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01852\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0079, Training Loss:  0.02023, Val Loss:  0.01701\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0270, Training Loss:  0.01909, Val Loss:  0.01661\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0418, Training Loss:  0.01824, Val Loss:  0.01649\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0570, Training Loss:  0.01766, Val Loss:  0.01651\n",
      "Best validation stage: 3\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01858\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0048, Training Loss:  0.02020, Val Loss:  0.01687\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0205, Training Loss:  0.01919, Val Loss:  0.01650\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0342, Training Loss:  0.01824, Val Loss:  0.01639\n",
      "Stage - 4, training time:  9.3 sec, boost rate:  1.0480, Training Loss:  0.01770, Val Loss:  0.01643\n",
      "Best validation stage: 3\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01848\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0172, Training Loss:  0.02001, Val Loss:  0.01701\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0327, Training Loss:  0.01903, Val Loss:  0.01678\n",
      "Stage - 3, training time:  8.5 sec, boost rate:  1.0473, Training Loss:  0.01810, Val Loss:  0.01658\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0626, Training Loss:  0.01759, Val Loss:  0.01648\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  4.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01888\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0047, Training Loss:  0.02013, Val Loss:  0.01708\n",
      "Stage - 2, training time:  7.6 sec, boost rate:  1.0193, Training Loss:  0.01911, Val Loss:  0.01668\n",
      "Stage - 3, training time:  8.2 sec, boost rate:  1.0337, Training Loss:  0.01816, Val Loss:  0.01644\n",
      "Stage - 4, training time:  9.3 sec, boost rate:  1.0499, Training Loss:  0.01761, Val Loss:  0.01650\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01849\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0008, Training Loss:  0.02027, Val Loss:  0.01667\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0125, Training Loss:  0.01927, Val Loss:  0.01635\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0267, Training Loss:  0.01831, Val Loss:  0.01614\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0427, Training Loss:  0.01775, Val Loss:  0.01607\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.01615019058844965\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.001\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:14:20.403737Z",
     "start_time": "2020-11-20T09:12:22.671436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 10.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c742828c34884f6bb4464bfb1b24e319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  3.0 sec, boost rate:  10.0000, Training Loss:  0.00000, Val Loss:  0.02100\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  9.9703, Training Loss:  0.02425, Val Loss:  0.01922\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  9.9420, Training Loss:  0.02298, Val Loss:  0.01912\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  9.9238, Training Loss:  0.02080, Val Loss:  0.01870\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  9.9066, Training Loss:  0.02056, Val Loss:  0.01908\n",
      "Best validation stage: 3\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  10.0000, Training Loss:  0.00000, Val Loss:  0.02087\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  9.9723, Training Loss:  0.02462, Val Loss:  0.01896\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  9.9488, Training Loss:  0.02366, Val Loss:  0.01879\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  9.9313, Training Loss:  0.02106, Val Loss:  0.01843\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  9.9131, Training Loss:  0.02067, Val Loss:  0.01893\n",
      "Best validation stage: 3\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  10.0000, Training Loss:  0.00000, Val Loss:  0.02112\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  9.9743, Training Loss:  0.02440, Val Loss:  0.01914\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  9.9443, Training Loss:  0.02298, Val Loss:  0.01911\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  9.9268, Training Loss:  0.02079, Val Loss:  0.01873\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  9.9089, Training Loss:  0.02041, Val Loss:  0.01903\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  10.0000, Training Loss:  0.00000, Val Loss:  0.02106\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  9.9724, Training Loss:  0.02436, Val Loss:  0.01921\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  9.9408, Training Loss:  0.02266, Val Loss:  0.01888\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  9.9230, Training Loss:  0.02059, Val Loss:  0.01861\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  9.9054, Training Loss:  0.02036, Val Loss:  0.01930\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  10.0000, Training Loss:  0.00000, Val Loss:  0.02082\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  9.9703, Training Loss:  0.02430, Val Loss:  0.01922\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  9.9440, Training Loss:  0.02326, Val Loss:  0.01858\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  9.9261, Training Loss:  0.02086, Val Loss:  0.01835\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  9.9087, Training Loss:  0.02046, Val Loss:  0.01847\n",
      "Best validation stage: 3\n",
      "\n",
      "CV log_loss  0.01726696899859218\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.001\n",
    "params[\"epochs_per_stage\"] = 1\n",
    "params[\"boost_rate\"] = 10.0\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:12:10.938778Z",
     "start_time": "2020-11-20T09:10:15.517438Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 128, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612bdccd4791428d83236f30a51d1550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  2.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02000\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0275, Training Loss:  0.02199, Val Loss:  0.01796\n",
      "Stage - 2, training time:  4.1 sec, boost rate:  1.0621, Training Loss:  0.02038, Val Loss:  0.01712\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0793, Training Loss:  0.01958, Val Loss:  0.01688\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0957, Training Loss:  0.01918, Val Loss:  0.01678\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01973\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0303, Training Loss:  0.02202, Val Loss:  0.01794\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0630, Training Loss:  0.02051, Val Loss:  0.01708\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0791, Training Loss:  0.01960, Val Loss:  0.01678\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.0961, Training Loss:  0.01921, Val Loss:  0.01662\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02009\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0240, Training Loss:  0.02196, Val Loss:  0.01812\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0540, Training Loss:  0.02036, Val Loss:  0.01724\n",
      "Stage - 3, training time:  4.8 sec, boost rate:  1.0705, Training Loss:  0.01952, Val Loss:  0.01700\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0869, Training Loss:  0.01914, Val Loss:  0.01685\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02006\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0344, Training Loss:  0.02195, Val Loss:  0.01815\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0667, Training Loss:  0.02038, Val Loss:  0.01730\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0833, Training Loss:  0.01955, Val Loss:  0.01698\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.1001, Training Loss:  0.01912, Val Loss:  0.01676\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01972\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0292, Training Loss:  0.02195, Val Loss:  0.01779\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0597, Training Loss:  0.02041, Val Loss:  0.01706\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0764, Training Loss:  0.01967, Val Loss:  0.01671\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0928, Training Loss:  0.01925, Val Loss:  0.01650\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.016509438700766082\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.001\n",
    "params[\"epochs_per_stage\"] = 1\n",
    "params[\"boost_rate\"] = 1.0\n",
    "params[\"hidden_size\"] = 128\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:09:37.107906Z",
     "start_time": "2020-11-20T09:07:42.093079Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2900d8f679c04b8ea70968c660ee7d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  2.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01942\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0234, Training Loss:  0.02082, Val Loss:  0.01705\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0398, Training Loss:  0.01938, Val Loss:  0.01671\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0548, Training Loss:  0.01837, Val Loss:  0.01657\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0705, Training Loss:  0.01782, Val Loss:  0.01643\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01901\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0280, Training Loss:  0.02077, Val Loss:  0.01694\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0445, Training Loss:  0.01937, Val Loss:  0.01650\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0597, Training Loss:  0.01836, Val Loss:  0.01641\n",
      "Stage - 4, training time:  5.5 sec, boost rate:  1.0756, Training Loss:  0.01777, Val Loss:  0.01628\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01956\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0195, Training Loss:  0.02074, Val Loss:  0.01711\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0366, Training Loss:  0.01930, Val Loss:  0.01683\n",
      "Stage - 3, training time:  4.9 sec, boost rate:  1.0525, Training Loss:  0.01831, Val Loss:  0.01654\n",
      "Stage - 4, training time:  5.6 sec, boost rate:  1.0688, Training Loss:  0.01772, Val Loss:  0.01665\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  1.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01979\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0206, Training Loss:  0.02073, Val Loss:  0.01716\n",
      "Stage - 2, training time:  4.2 sec, boost rate:  1.0399, Training Loss:  0.01930, Val Loss:  0.01682\n",
      "Stage - 3, training time:  4.8 sec, boost rate:  1.0556, Training Loss:  0.01828, Val Loss:  0.01657\n",
      "Stage - 4, training time:  5.5 sec, boost rate:  1.0720, Training Loss:  0.01772, Val Loss:  0.01654\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  1.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01944\n",
      "Stage - 1, training time:  3.5 sec, boost rate:  1.0124, Training Loss:  0.02086, Val Loss:  0.01693\n",
      "Stage - 2, training time:  4.1 sec, boost rate:  1.0304, Training Loss:  0.01944, Val Loss:  0.01646\n",
      "Stage - 3, training time:  4.8 sec, boost rate:  1.0471, Training Loss:  0.01844, Val Loss:  0.01620\n",
      "Stage - 4, training time:  5.5 sec, boost rate:  1.0627, Training Loss:  0.01785, Val Loss:  0.01614\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.016213490552680582\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.001\n",
    "params[\"epochs_per_stage\"] = 1\n",
    "params[\"boost_rate\"] = 1.0\n",
    "params[\"hidden_size\"] = 512\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:43:28.398726Z",
     "start_time": "2020-11-20T09:41:28.350622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adabelief', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaf68e4b1b94cedbae8d641b54f9f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  3.1 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01942\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0253, Training Loss:  0.02083, Val Loss:  0.01705\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0436, Training Loss:  0.01941, Val Loss:  0.01670\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0585, Training Loss:  0.01841, Val Loss:  0.01656\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0744, Training Loss:  0.01789, Val Loss:  0.01642\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01900\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0277, Training Loss:  0.02080, Val Loss:  0.01698\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0463, Training Loss:  0.01942, Val Loss:  0.01652\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0613, Training Loss:  0.01842, Val Loss:  0.01638\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0775, Training Loss:  0.01784, Val Loss:  0.01633\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01951\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0195, Training Loss:  0.02075, Val Loss:  0.01715\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0375, Training Loss:  0.01935, Val Loss:  0.01686\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0527, Training Loss:  0.01839, Val Loss:  0.01655\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.9 sec, boost rate:  1.0691, Training Loss:  0.01784, Val Loss:  0.01664\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01976\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0219, Training Loss:  0.02077, Val Loss:  0.01720\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0442, Training Loss:  0.01935, Val Loss:  0.01682\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0603, Training Loss:  0.01833, Val Loss:  0.01653\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0764, Training Loss:  0.01780, Val Loss:  0.01655\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01931\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0191, Training Loss:  0.02086, Val Loss:  0.01699\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0374, Training Loss:  0.01953, Val Loss:  0.01644\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0528, Training Loss:  0.01850, Val Loss:  0.01616\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.9 sec, boost rate:  1.0676, Training Loss:  0.01795, Val Loss:  0.01613\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.0162398690643124\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"batch_size\"] = 256\n",
    "params[\"optimizer\"] = \"adabelief\"\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.001\n",
    "params[\"epochs_per_stage\"] = 1\n",
    "params[\"boost_rate\"] = 1.0\n",
    "params[\"hidden_size\"] = 512\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:45:41.742504Z",
     "start_time": "2020-11-20T09:43:42.437760Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adabelief', 'lr': 0.03, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecdae3fe0db4636a3de2a6c05b45e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  3.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02066\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.4868, Training Loss:  0.02232, Val Loss:  0.01864\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.8111, Training Loss:  0.02112, Val Loss:  0.01783\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.9907, Training Loss:  0.02031, Val Loss:  0.01730\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  2.0617, Training Loss:  0.02020, Val Loss:  0.01718\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02003\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.4392, Training Loss:  0.02213, Val Loss:  0.01808\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.7426, Training Loss:  0.02100, Val Loss:  0.01765\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.8931, Training Loss:  0.02038, Val Loss:  0.01729\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.9916, Training Loss:  0.02018, Val Loss:  0.01716\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02079\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.3751, Training Loss:  0.02234, Val Loss:  0.01968\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.7316, Training Loss:  0.02112, Val Loss:  0.01795\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.8907, Training Loss:  0.02033, Val Loss:  0.01749\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  2.0206, Training Loss:  0.02016, Val Loss:  0.01748\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02070\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.5156, Training Loss:  0.02218, Val Loss:  0.01853\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.8924, Training Loss:  0.02087, Val Loss:  0.01793\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.9993, Training Loss:  0.02033, Val Loss:  0.01734\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  2.0515, Training Loss:  0.02009, Val Loss:  0.01732\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01993\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.3841, Training Loss:  0.02222, Val Loss:  0.01845\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.6844, Training Loss:  0.02108, Val Loss:  0.01768\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.8656, Training Loss:  0.02043, Val Loss:  0.01720\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.9618, Training Loss:  0.02021, Val Loss:  0.01695\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.01696396988587084\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"optimizer\"] = \"adabelief\"\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"lr\"] = 0.03\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:56:21.389390Z",
     "start_time": "2020-11-20T09:51:12.900753Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 3, 'correct_epoch': 3, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b85650f9c914bf89741f9fa3f269b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  5.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01852\n",
      "Stage - 1, training time:  10.4 sec, boost rate:  1.0689, Training Loss:  0.01923, Val Loss:  0.01664\n",
      "Stage - 2, training time:  12.5 sec, boost rate:  1.1668, Training Loss:  0.01725, Val Loss:  0.01650\n",
      "Stage - 3, training time:  14.6 sec, boost rate:  1.2215, Training Loss:  0.01534, Val Loss:  0.01708\n",
      "Stage - 4, training time:  16.8 sec, boost rate:  1.2752, Training Loss:  0.01404, Val Loss:  0.01763\n",
      "Best validation stage: 2\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01850\n",
      "Stage - 1, training time:  10.5 sec, boost rate:  1.0683, Training Loss:  0.01925, Val Loss:  0.01655\n",
      "Stage - 2, training time:  12.6 sec, boost rate:  1.1656, Training Loss:  0.01729, Val Loss:  0.01652\n",
      "Stage - 3, training time:  14.7 sec, boost rate:  1.2190, Training Loss:  0.01537, Val Loss:  0.01697\n",
      "Stage - 4, training time:  16.8 sec, boost rate:  1.2723, Training Loss:  0.01405, Val Loss:  0.01760\n",
      "Best validation stage: 2\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01855\n",
      "Stage - 1, training time:  10.5 sec, boost rate:  1.0676, Training Loss:  0.01915, Val Loss:  0.01659\n",
      "Stage - 2, training time:  12.6 sec, boost rate:  1.1637, Training Loss:  0.01719, Val Loss:  0.01674\n",
      "Stage - 3, training time:  14.5 sec, boost rate:  1.2180, Training Loss:  0.01522, Val Loss:  0.01724\n",
      "Stage - 4, training time:  16.6 sec, boost rate:  1.2721, Training Loss:  0.01390, Val Loss:  0.01782\n",
      "Best validation stage: 1\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01873\n",
      "Stage - 1, training time:  10.6 sec, boost rate:  1.0620, Training Loss:  0.01918, Val Loss:  0.01666\n",
      "Stage - 2, training time:  12.5 sec, boost rate:  1.1616, Training Loss:  0.01717, Val Loss:  0.01688\n",
      "Stage - 3, training time:  14.7 sec, boost rate:  1.2165, Training Loss:  0.01525, Val Loss:  0.01727\n",
      "Stage - 4, training time:  16.7 sec, boost rate:  1.2698, Training Loss:  0.01391, Val Loss:  0.01784\n",
      "Best validation stage: 1\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01847\n",
      "Stage - 1, training time:  10.4 sec, boost rate:  1.0638, Training Loss:  0.01926, Val Loss:  0.01612\n",
      "Stage - 2, training time:  12.4 sec, boost rate:  1.1654, Training Loss:  0.01736, Val Loss:  0.01637\n",
      "Stage - 3, training time:  14.6 sec, boost rate:  1.2207, Training Loss:  0.01543, Val Loss:  0.01670\n",
      "Stage - 4, training time:  16.7 sec, boost rate:  1.2749, Training Loss:  0.01408, Val Loss:  0.01721\n",
      "Best validation stage: 1\n",
      "\n",
      "CV log_loss  0.01617293412628241\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "params[\"correct_epoch\"] = 3\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:59:16.662550Z",
     "start_time": "2020-11-20T09:56:39.832615Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 2, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e19cd107a34091b724104c98b0c159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  4.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01875\n",
      "Stage - 1, training time:  5.1 sec, boost rate:  1.0151, Training Loss:  0.02037, Val Loss:  0.01692\n",
      "Stage - 2, training time:  5.9 sec, boost rate:  1.0324, Training Loss:  0.01925, Val Loss:  0.01657\n",
      "Stage - 3, training time:  6.6 sec, boost rate:  1.0473, Training Loss:  0.01826, Val Loss:  0.01649\n",
      "Stage - 4, training time:  7.3 sec, boost rate:  1.0627, Training Loss:  0.01775, Val Loss:  0.01646\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  2.7 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01858\n",
      "Stage - 1, training time:  5.1 sec, boost rate:  1.0184, Training Loss:  0.02038, Val Loss:  0.01688\n",
      "Stage - 2, training time:  5.9 sec, boost rate:  1.0378, Training Loss:  0.01924, Val Loss:  0.01653\n",
      "Stage - 3, training time:  6.6 sec, boost rate:  1.0530, Training Loss:  0.01827, Val Loss:  0.01635\n",
      "Stage - 4, training time:  7.5 sec, boost rate:  1.0686, Training Loss:  0.01769, Val Loss:  0.01642\n",
      "Best validation stage: 3\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  2.7 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01888\n",
      "Stage - 1, training time:  5.1 sec, boost rate:  1.0199, Training Loss:  0.02034, Val Loss:  0.01690\n",
      "Stage - 2, training time:  5.9 sec, boost rate:  1.0370, Training Loss:  0.01918, Val Loss:  0.01672\n",
      "Stage - 3, training time:  6.7 sec, boost rate:  1.0519, Training Loss:  0.01822, Val Loss:  0.01650\n",
      "Stage - 4, training time:  7.5 sec, boost rate:  1.0668, Training Loss:  0.01771, Val Loss:  0.01652\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  2.7 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01916\n",
      "Stage - 1, training time:  5.1 sec, boost rate:  1.0168, Training Loss:  0.02034, Val Loss:  0.01714\n",
      "Stage - 2, training time:  5.9 sec, boost rate:  1.0300, Training Loss:  0.01923, Val Loss:  0.01664\n",
      "Stage - 3, training time:  6.7 sec, boost rate:  1.0448, Training Loss:  0.01826, Val Loss:  0.01646\n",
      "Stage - 4, training time:  7.5 sec, boost rate:  1.0603, Training Loss:  0.01766, Val Loss:  0.01653\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  2.7 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01874\n",
      "Stage - 1, training time:  5.1 sec, boost rate:  1.0196, Training Loss:  0.02041, Val Loss:  0.01683\n",
      "Stage - 2, training time:  5.9 sec, boost rate:  1.0358, Training Loss:  0.01934, Val Loss:  0.01636\n",
      "Stage - 3, training time:  6.6 sec, boost rate:  1.0497, Training Loss:  0.01837, Val Loss:  0.01615\n",
      "Stage - 4, training time:  7.5 sec, boost rate:  1.0653, Training Loss:  0.01785, Val Loss:  0.01610\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.0161624603388244\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"epochs_per_stage\"] = 2\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:02:44.502498Z",
     "start_time": "2020-11-20T09:59:29.196031Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 436, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba5b212369d4d62ad807496b47449f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  5.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01861\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0158, Training Loss:  0.02021, Val Loss:  0.01700\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0388, Training Loss:  0.01914, Val Loss:  0.01662\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0543, Training Loss:  0.01828, Val Loss:  0.01648\n",
      "Stage - 4, training time:  9.3 sec, boost rate:  1.0695, Training Loss:  0.01780, Val Loss:  0.01640\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01845\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0123, Training Loss:  0.02030, Val Loss:  0.01688\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0285, Training Loss:  0.01925, Val Loss:  0.01662\n",
      "Stage - 3, training time:  8.4 sec, boost rate:  1.0437, Training Loss:  0.01842, Val Loss:  0.01652\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0584, Training Loss:  0.01786, Val Loss:  0.01646\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01881\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0045, Training Loss:  0.02021, Val Loss:  0.01713\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0207, Training Loss:  0.01926, Val Loss:  0.01701\n",
      "Stage - 3, training time:  8.4 sec, boost rate:  1.0339, Training Loss:  0.01837, Val Loss:  0.01662\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0490, Training Loss:  0.01782, Val Loss:  0.01658\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01903\n",
      "Stage - 1, training time:  6.7 sec, boost rate:  1.0080, Training Loss:  0.02023, Val Loss:  0.01710\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0318, Training Loss:  0.01920, Val Loss:  0.01675\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0467, Training Loss:  0.01832, Val Loss:  0.01650\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0609, Training Loss:  0.01781, Val Loss:  0.01652\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01855\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0147, Training Loss:  0.02027, Val Loss:  0.01676\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0320, Training Loss:  0.01934, Val Loss:  0.01636\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0469, Training Loss:  0.01839, Val Loss:  0.01615\n",
      "Stage - 4, training time:  9.1 sec, boost rate:  1.0620, Training Loss:  0.01789, Val Loss:  0.01616\n",
      "Best validation stage: 3\n",
      "\n",
      "CV log_loss  0.016175361740576495\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "params[\"hidden_size\"] = params[\"feat_d\"] // 2\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:06:08.653173Z",
     "start_time": "2020-11-20T10:02:55.460573Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 291, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d78b6343e634339817419bae37ad9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  5.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01897\n",
      "Stage - 1, training time:  6.5 sec, boost rate:  1.0146, Training Loss:  0.02064, Val Loss:  0.01708\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0392, Training Loss:  0.01954, Val Loss:  0.01673\n",
      "Stage - 3, training time:  8.1 sec, boost rate:  1.0539, Training Loss:  0.01879, Val Loss:  0.01651\n",
      "Stage - 4, training time:  8.8 sec, boost rate:  1.0696, Training Loss:  0.01837, Val Loss:  0.01644\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  3.8 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01882\n",
      "Stage - 1, training time:  6.4 sec, boost rate:  1.0171, Training Loss:  0.02054, Val Loss:  0.01699\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0396, Training Loss:  0.01955, Val Loss:  0.01658\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0554, Training Loss:  0.01877, Val Loss:  0.01638\n",
      "Stage - 4, training time:  9.1 sec, boost rate:  1.0708, Training Loss:  0.01836, Val Loss:  0.01639\n",
      "Best validation stage: 3\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01859\n",
      "Stage - 1, training time:  6.5 sec, boost rate:  1.0207, Training Loss:  0.02048, Val Loss:  0.01718\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0477, Training Loss:  0.01942, Val Loss:  0.01679\n",
      "Stage - 3, training time:  8.2 sec, boost rate:  1.0636, Training Loss:  0.01863, Val Loss:  0.01669\n",
      "Stage - 4, training time:  9.1 sec, boost rate:  1.0796, Training Loss:  0.01820, Val Loss:  0.01657\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01898\n",
      "Stage - 1, training time:  6.5 sec, boost rate:  1.0174, Training Loss:  0.02059, Val Loss:  0.01728\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0415, Training Loss:  0.01951, Val Loss:  0.01680\n",
      "Stage - 3, training time:  8.2 sec, boost rate:  1.0575, Training Loss:  0.01873, Val Loss:  0.01657\n",
      "Stage - 4, training time:  9.1 sec, boost rate:  1.0742, Training Loss:  0.01828, Val Loss:  0.01653\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01865\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0245, Training Loss:  0.02056, Val Loss:  0.01685\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0462, Training Loss:  0.01955, Val Loss:  0.01649\n",
      "Stage - 3, training time:  8.2 sec, boost rate:  1.0617, Training Loss:  0.01885, Val Loss:  0.01622\n",
      "Stage - 4, training time:  9.1 sec, boost rate:  1.0765, Training Loss:  0.01845, Val Loss:  0.01620\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.01623172511972385\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "params[\"hidden_size\"] = params[\"feat_d\"] // 3\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:13:14.789866Z",
     "start_time": "2020-11-20T10:09:53.040017Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 873, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb4321b407b42bd8e195055288b2edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  5.6 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01825\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  0.9984, Training Loss:  0.01996, Val Loss:  0.01684\n",
      "Stage - 2, training time:  7.7 sec, boost rate:  0.9981, Training Loss:  0.01898, Val Loss:  0.01663\n",
      "Stage - 3, training time:  8.7 sec, boost rate:  1.0113, Training Loss:  0.01789, Val Loss:  0.01637\n",
      "Stage - 4, training time:  9.6 sec, boost rate:  1.0242, Training Loss:  0.01727, Val Loss:  0.01656\n",
      "Best validation stage: 3\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  4.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01839\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  0.9938, Training Loss:  0.01995, Val Loss:  0.01675\n",
      "Stage - 2, training time:  7.6 sec, boost rate:  0.9953, Training Loss:  0.01895, Val Loss:  0.01654\n",
      "Stage - 3, training time:  8.7 sec, boost rate:  1.0095, Training Loss:  0.01777, Val Loss:  0.01657\n",
      "Stage - 4, training time:  9.6 sec, boost rate:  1.0228, Training Loss:  0.01711, Val Loss:  0.01670\n",
      "Best validation stage: 2\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  4.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01861\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  0.9939, Training Loss:  0.01989, Val Loss:  0.01693\n",
      "Stage - 2, training time:  7.7 sec, boost rate:  0.9944, Training Loss:  0.01899, Val Loss:  0.01673\n",
      "Stage - 3, training time:  8.6 sec, boost rate:  1.0061, Training Loss:  0.01786, Val Loss:  0.01657\n",
      "Stage - 4, training time:  9.6 sec, boost rate:  1.0204, Training Loss:  0.01722, Val Loss:  0.01674\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  4.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01869\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  0.9941, Training Loss:  0.01987, Val Loss:  0.01701\n",
      "Stage - 2, training time:  7.8 sec, boost rate:  0.9977, Training Loss:  0.01889, Val Loss:  0.01675\n",
      "Stage - 3, training time:  8.5 sec, boost rate:  1.0111, Training Loss:  0.01773, Val Loss:  0.01666\n",
      "Stage - 4, training time:  9.6 sec, boost rate:  1.0239, Training Loss:  0.01711, Val Loss:  0.01666\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  4.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01834\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  0.9922, Training Loss:  0.02002, Val Loss:  0.01653\n",
      "Stage - 2, training time:  7.7 sec, boost rate:  0.9939, Training Loss:  0.01901, Val Loss:  0.01628\n",
      "Stage - 3, training time:  8.7 sec, boost rate:  1.0075, Training Loss:  0.01784, Val Loss:  0.01614\n",
      "Stage - 4, training time:  9.6 sec, boost rate:  1.0204, Training Loss:  0.01721, Val Loss:  0.01613\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.01621878053385272\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "params[\"hidden_size\"] = params[\"feat_d\"]\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:09:37.956412Z",
     "start_time": "2020-11-20T10:06:26.767294Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 0.0, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ad81a8faa147d18937ddfc787a6eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  5.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01850\n",
      "Stage - 1, training time:  6.4 sec, boost rate:  1.0097, Training Loss:  0.02033, Val Loss:  0.01707\n",
      "Stage - 2, training time:  7.2 sec, boost rate:  1.0281, Training Loss:  0.01921, Val Loss:  0.01665\n",
      "Stage - 3, training time:  8.1 sec, boost rate:  1.0424, Training Loss:  0.01847, Val Loss:  0.01657\n",
      "Stage - 4, training time:  8.9 sec, boost rate:  1.0574, Training Loss:  0.01797, Val Loss:  0.01654\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  3.8 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01831\n",
      "Stage - 1, training time:  6.4 sec, boost rate:  1.0148, Training Loss:  0.02026, Val Loss:  0.01684\n",
      "Stage - 2, training time:  7.2 sec, boost rate:  1.0333, Training Loss:  0.01927, Val Loss:  0.01660\n",
      "Stage - 3, training time:  8.1 sec, boost rate:  1.0490, Training Loss:  0.01838, Val Loss:  0.01648\n",
      "Stage - 4, training time:  8.9 sec, boost rate:  1.0649, Training Loss:  0.01789, Val Loss:  0.01650\n",
      "Best validation stage: 3\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  3.8 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01869\n",
      "Stage - 1, training time:  6.4 sec, boost rate:  1.0053, Training Loss:  0.02022, Val Loss:  0.01701\n",
      "Stage - 2, training time:  7.2 sec, boost rate:  1.0190, Training Loss:  0.01930, Val Loss:  0.01672\n",
      "Stage - 3, training time:  8.0 sec, boost rate:  1.0331, Training Loss:  0.01841, Val Loss:  0.01660\n",
      "Stage - 4, training time:  8.9 sec, boost rate:  1.0475, Training Loss:  0.01793, Val Loss:  0.01657\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  3.8 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01897\n",
      "Stage - 1, training time:  6.4 sec, boost rate:  1.0055, Training Loss:  0.02023, Val Loss:  0.01717\n",
      "Stage - 2, training time:  7.2 sec, boost rate:  1.0268, Training Loss:  0.01926, Val Loss:  0.01675\n",
      "Stage - 3, training time:  8.0 sec, boost rate:  1.0418, Training Loss:  0.01844, Val Loss:  0.01656\n",
      "Stage - 4, training time:  8.9 sec, boost rate:  1.0566, Training Loss:  0.01789, Val Loss:  0.01655\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  3.8 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01883\n",
      "Stage - 1, training time:  6.4 sec, boost rate:  1.0028, Training Loss:  0.02024, Val Loss:  0.01678\n",
      "Stage - 2, training time:  7.2 sec, boost rate:  1.0164, Training Loss:  0.01930, Val Loss:  0.01644\n",
      "Stage - 3, training time:  8.1 sec, boost rate:  1.0298, Training Loss:  0.01854, Val Loss:  0.01620\n",
      "Stage - 4, training time:  9.0 sec, boost rate:  1.0445, Training Loss:  0.01802, Val Loss:  0.01618\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.016252274488984572\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "params[\"weight_decay\"] = 0.0\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:23:41.951781Z",
     "start_time": "2020-11-20T10:13:28.416703Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 15, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6037a3a87cbb4200a7ff9428576bb0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  5.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01852\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0079, Training Loss:  0.02023, Val Loss:  0.01701\n",
      "Stage - 2, training time:  7.4 sec, boost rate:  1.0270, Training Loss:  0.01909, Val Loss:  0.01661\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0418, Training Loss:  0.01824, Val Loss:  0.01649\n",
      "Stage - 4, training time:  9.3 sec, boost rate:  1.0570, Training Loss:  0.01766, Val Loss:  0.01651\n",
      "Stage - 5, training time:  10.1 sec, boost rate:  1.0720, Training Loss:  0.01712, Val Loss:  0.01648\n",
      "Stage - 6, training time:  10.9 sec, boost rate:  1.0806, Training Loss:  0.01634, Val Loss:  0.01653\n",
      "Stage - 7, training time:  11.8 sec, boost rate:  1.0890, Training Loss:  0.01591, Val Loss:  0.01662\n",
      "Stage - 8, training time:  12.8 sec, boost rate:  1.0974, Training Loss:  0.01550, Val Loss:  0.01676\n",
      "Stage - 9, training time:  13.6 sec, boost rate:  1.1019, Training Loss:  0.01483, Val Loss:  0.01672\n",
      "Stage - 10, training time:  14.6 sec, boost rate:  1.1062, Training Loss:  0.01456, Val Loss:  0.01685\n",
      "Stage - 11, training time:  15.4 sec, boost rate:  1.1106, Training Loss:  0.01425, Val Loss:  0.01691\n",
      "early stopped!\n",
      "Best validation stage: 5\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01859\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0077, Training Loss:  0.02019, Val Loss:  0.01686\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0221, Training Loss:  0.01916, Val Loss:  0.01653\n",
      "Stage - 3, training time:  8.4 sec, boost rate:  1.0367, Training Loss:  0.01822, Val Loss:  0.01645\n",
      "Stage - 4, training time:  9.3 sec, boost rate:  1.0515, Training Loss:  0.01767, Val Loss:  0.01644\n",
      "Stage - 5, training time:  10.1 sec, boost rate:  1.0663, Training Loss:  0.01715, Val Loss:  0.01658\n",
      "Stage - 6, training time:  11.1 sec, boost rate:  1.0748, Training Loss:  0.01630, Val Loss:  0.01653\n",
      "Stage - 7, training time:  11.9 sec, boost rate:  1.0834, Training Loss:  0.01594, Val Loss:  0.01669\n",
      "Stage - 8, training time:  12.8 sec, boost rate:  1.0922, Training Loss:  0.01552, Val Loss:  0.01676\n",
      "Stage - 9, training time:  13.7 sec, boost rate:  1.0966, Training Loss:  0.01485, Val Loss:  0.01675\n",
      "Stage - 10, training time:  14.3 sec, boost rate:  1.1011, Training Loss:  0.01457, Val Loss:  0.01698\n",
      "early stopped!\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01856\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0075, Training Loss:  0.02011, Val Loss:  0.01696\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0268, Training Loss:  0.01909, Val Loss:  0.01677\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0423, Training Loss:  0.01814, Val Loss:  0.01651\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0575, Training Loss:  0.01760, Val Loss:  0.01650\n",
      "Stage - 5, training time:  10.1 sec, boost rate:  1.0733, Training Loss:  0.01709, Val Loss:  0.01655\n",
      "Stage - 6, training time:  11.1 sec, boost rate:  1.0816, Training Loss:  0.01623, Val Loss:  0.01663\n",
      "Stage - 7, training time:  12.0 sec, boost rate:  1.0903, Training Loss:  0.01582, Val Loss:  0.01679\n",
      "Stage - 8, training time:  12.8 sec, boost rate:  1.0988, Training Loss:  0.01543, Val Loss:  0.01678\n",
      "Stage - 9, training time:  13.6 sec, boost rate:  1.1032, Training Loss:  0.01475, Val Loss:  0.01681\n",
      "Stage - 10, training time:  14.5 sec, boost rate:  1.1076, Training Loss:  0.01439, Val Loss:  0.01697\n",
      "early stopped!\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  3.9 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01885\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0059, Training Loss:  0.02019, Val Loss:  0.01708\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0178, Training Loss:  0.01918, Val Loss:  0.01672\n",
      "Stage - 3, training time:  8.4 sec, boost rate:  1.0333, Training Loss:  0.01817, Val Loss:  0.01662\n",
      "Stage - 4, training time:  9.3 sec, boost rate:  1.0484, Training Loss:  0.01760, Val Loss:  0.01655\n",
      "Stage - 5, training time:  10.1 sec, boost rate:  1.0633, Training Loss:  0.01709, Val Loss:  0.01662\n",
      "Stage - 6, training time:  11.0 sec, boost rate:  1.0715, Training Loss:  0.01626, Val Loss:  0.01660\n",
      "Stage - 7, training time:  11.8 sec, boost rate:  1.0797, Training Loss:  0.01576, Val Loss:  0.01670\n",
      "Stage - 8, training time:  12.8 sec, boost rate:  1.0880, Training Loss:  0.01538, Val Loss:  0.01680\n",
      "Stage - 9, training time:  13.6 sec, boost rate:  1.0923, Training Loss:  0.01471, Val Loss:  0.01682\n",
      "Stage - 10, training time:  14.5 sec, boost rate:  1.0967, Training Loss:  0.01439, Val Loss:  0.01701\n",
      "early stopped!\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  4.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01848\n",
      "Stage - 1, training time:  6.6 sec, boost rate:  1.0055, Training Loss:  0.02025, Val Loss:  0.01678\n",
      "Stage - 2, training time:  7.5 sec, boost rate:  1.0226, Training Loss:  0.01922, Val Loss:  0.01628\n",
      "Stage - 3, training time:  8.3 sec, boost rate:  1.0368, Training Loss:  0.01829, Val Loss:  0.01617\n",
      "Stage - 4, training time:  9.2 sec, boost rate:  1.0521, Training Loss:  0.01771, Val Loss:  0.01614\n",
      "Stage - 5, training time:  10.1 sec, boost rate:  1.0681, Training Loss:  0.01720, Val Loss:  0.01615\n",
      "Stage - 6, training time:  10.9 sec, boost rate:  1.0766, Training Loss:  0.01637, Val Loss:  0.01614\n",
      "Stage - 7, training time:  11.9 sec, boost rate:  1.0852, Training Loss:  0.01600, Val Loss:  0.01620\n",
      "Stage - 8, training time:  12.8 sec, boost rate:  1.0938, Training Loss:  0.01554, Val Loss:  0.01635\n",
      "Stage - 9, training time:  13.7 sec, boost rate:  1.0982, Training Loss:  0.01491, Val Loss:  0.01639\n",
      "Stage - 10, training time:  14.6 sec, boost rate:  1.1026, Training Loss:  0.01457, Val Loss:  0.01647\n",
      "Stage - 11, training time:  15.6 sec, boost rate:  1.1071, Training Loss:  0.01426, Val Loss:  0.01659\n",
      "Stage - 12, training time:  16.5 sec, boost rate:  1.1094, Training Loss:  0.01380, Val Loss:  0.01659\n",
      "early stopped!\n",
      "Best validation stage: 6\n",
      "\n",
      "CV log_loss  0.016182657405617\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 15\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:40:46.075775Z",
     "start_time": "2020-11-20T10:30:52.682812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adabelief', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 15, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b0bd8e44084c02ac41e9a21c8b9ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  5.7 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01847\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  1.0091, Training Loss:  0.02038, Val Loss:  0.01708\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  7.8 sec, boost rate:  1.0247, Training Loss:  0.01924, Val Loss:  0.01672\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  8.7 sec, boost rate:  1.0396, Training Loss:  0.01837, Val Loss:  0.01653\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  9.5 sec, boost rate:  1.0548, Training Loss:  0.01785, Val Loss:  0.01651\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  10.4 sec, boost rate:  1.0693, Training Loss:  0.01733, Val Loss:  0.01641\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  11.1 sec, boost rate:  1.0780, Training Loss:  0.01658, Val Loss:  0.01646\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  12.1 sec, boost rate:  1.0864, Training Loss:  0.01616, Val Loss:  0.01654\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  13.0 sec, boost rate:  1.0947, Training Loss:  0.01579, Val Loss:  0.01668\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  13.8 sec, boost rate:  1.0992, Training Loss:  0.01517, Val Loss:  0.01667\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  14.8 sec, boost rate:  1.1035, Training Loss:  0.01491, Val Loss:  0.01677\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  15.7 sec, boost rate:  1.1079, Training Loss:  0.01463, Val Loss:  0.01684\n",
      "early stopped!\n",
      "Best validation stage: 5\n",
      "========================= fold: 1 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  4.2 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01861\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  6.9 sec, boost rate:  1.0082, Training Loss:  0.02030, Val Loss:  0.01692\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  7.8 sec, boost rate:  1.0198, Training Loss:  0.01929, Val Loss:  0.01659\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  8.6 sec, boost rate:  1.0336, Training Loss:  0.01840, Val Loss:  0.01652\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  9.5 sec, boost rate:  1.0476, Training Loss:  0.01785, Val Loss:  0.01641\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  10.4 sec, boost rate:  1.0618, Training Loss:  0.01738, Val Loss:  0.01648\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  11.1 sec, boost rate:  1.0703, Training Loss:  0.01658, Val Loss:  0.01644\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  12.0 sec, boost rate:  1.0787, Training Loss:  0.01624, Val Loss:  0.01660\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  13.0 sec, boost rate:  1.0874, Training Loss:  0.01583, Val Loss:  0.01664\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  13.9 sec, boost rate:  1.0918, Training Loss:  0.01520, Val Loss:  0.01671\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  15.0 sec, boost rate:  1.0963, Training Loss:  0.01493, Val Loss:  0.01682\n",
      "early stopped!\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  4.2 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01869\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  1.0083, Training Loss:  0.02026, Val Loss:  0.01703\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  7.8 sec, boost rate:  1.0263, Training Loss:  0.01919, Val Loss:  0.01679\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  8.7 sec, boost rate:  1.0408, Training Loss:  0.01829, Val Loss:  0.01654\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  9.1 sec, boost rate:  1.0562, Training Loss:  0.01777, Val Loss:  0.01651\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  10.1 sec, boost rate:  1.0719, Training Loss:  0.01727, Val Loss:  0.01658\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  10.9 sec, boost rate:  1.0802, Training Loss:  0.01648, Val Loss:  0.01660\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  11.9 sec, boost rate:  1.0888, Training Loss:  0.01607, Val Loss:  0.01674\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  12.6 sec, boost rate:  1.0974, Training Loss:  0.01568, Val Loss:  0.01676\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  13.6 sec, boost rate:  1.1018, Training Loss:  0.01506, Val Loss:  0.01675\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  14.6 sec, boost rate:  1.1062, Training Loss:  0.01472, Val Loss:  0.01686\n",
      "early stopped!\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  4.2 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01883\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  6.8 sec, boost rate:  1.0036, Training Loss:  0.02034, Val Loss:  0.01720\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  7.7 sec, boost rate:  1.0180, Training Loss:  0.01931, Val Loss:  0.01679\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  8.7 sec, boost rate:  1.0334, Training Loss:  0.01837, Val Loss:  0.01665\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  9.5 sec, boost rate:  1.0483, Training Loss:  0.01782, Val Loss:  0.01656\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  10.4 sec, boost rate:  1.0633, Training Loss:  0.01730, Val Loss:  0.01651\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  11.3 sec, boost rate:  1.0715, Training Loss:  0.01650, Val Loss:  0.01655\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  11.8 sec, boost rate:  1.0798, Training Loss:  0.01605, Val Loss:  0.01666\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  12.9 sec, boost rate:  1.0883, Training Loss:  0.01568, Val Loss:  0.01678\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  13.7 sec, boost rate:  1.0926, Training Loss:  0.01506, Val Loss:  0.01675\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  14.7 sec, boost rate:  1.0970, Training Loss:  0.01475, Val Loss:  0.01689\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  15.4 sec, boost rate:  1.1014, Training Loss:  0.01453, Val Loss:  0.01700\n",
      "early stopped!\n",
      "Best validation stage: 5\n",
      "========================= fold: 4 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  4.2 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01840\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  6.9 sec, boost rate:  1.0070, Training Loss:  0.02033, Val Loss:  0.01677\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  7.7 sec, boost rate:  1.0201, Training Loss:  0.01937, Val Loss:  0.01634\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  8.7 sec, boost rate:  1.0351, Training Loss:  0.01848, Val Loss:  0.01606\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  9.5 sec, boost rate:  1.0506, Training Loss:  0.01792, Val Loss:  0.01611\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  10.4 sec, boost rate:  1.0662, Training Loss:  0.01743, Val Loss:  0.01618\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  11.3 sec, boost rate:  1.0747, Training Loss:  0.01659, Val Loss:  0.01609\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  11.9 sec, boost rate:  1.0830, Training Loss:  0.01622, Val Loss:  0.01627\n",
      "Weight decoupling enabled in AdaBelief\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage - 8, training time:  12.9 sec, boost rate:  1.0913, Training Loss:  0.01584, Val Loss:  0.01618\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  13.8 sec, boost rate:  1.0958, Training Loss:  0.01523, Val Loss:  0.01627\n",
      "early stopped!\n",
      "Best validation stage: 3\n",
      "\n",
      "CV log_loss  0.016172997296311952\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 15\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"optimizer\"] = \"adabelief\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:30:34.863775Z",
     "start_time": "2020-11-20T10:24:00.248299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adabelief', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 15, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438a6a999de7435db1b76a4e0c6d4de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  3.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01942\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0253, Training Loss:  0.02083, Val Loss:  0.01705\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0436, Training Loss:  0.01941, Val Loss:  0.01670\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0585, Training Loss:  0.01841, Val Loss:  0.01656\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0744, Training Loss:  0.01789, Val Loss:  0.01642\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.6 sec, boost rate:  1.0904, Training Loss:  0.01732, Val Loss:  0.01648\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.2 sec, boost rate:  1.0988, Training Loss:  0.01647, Val Loss:  0.01646\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  8.0 sec, boost rate:  1.1072, Training Loss:  0.01598, Val Loss:  0.01659\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.7 sec, boost rate:  1.1161, Training Loss:  0.01557, Val Loss:  0.01664\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.0 sec, boost rate:  1.1205, Training Loss:  0.01491, Val Loss:  0.01676\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.2 sec, boost rate:  1.1250, Training Loss:  0.01456, Val Loss:  0.01680\n",
      "early stopped!\n",
      "Best validation stage: 4\n",
      "========================= fold: 1 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01908\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0264, Training Loss:  0.02074, Val Loss:  0.01692\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0461, Training Loss:  0.01941, Val Loss:  0.01662\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0619, Training Loss:  0.01839, Val Loss:  0.01634\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.9 sec, boost rate:  1.0774, Training Loss:  0.01786, Val Loss:  0.01634\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.7 sec, boost rate:  1.0930, Training Loss:  0.01734, Val Loss:  0.01641\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.4 sec, boost rate:  1.1015, Training Loss:  0.01649, Val Loss:  0.01633\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  8.0 sec, boost rate:  1.1099, Training Loss:  0.01600, Val Loss:  0.01647\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.7 sec, boost rate:  1.1183, Training Loss:  0.01560, Val Loss:  0.01650\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.5 sec, boost rate:  1.1228, Training Loss:  0.01492, Val Loss:  0.01660\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.0 sec, boost rate:  1.1273, Training Loss:  0.01463, Val Loss:  0.01669\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  11.0 sec, boost rate:  1.1317, Training Loss:  0.01436, Val Loss:  0.01674\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 12, training time:  11.6 sec, boost rate:  1.1340, Training Loss:  0.01390, Val Loss:  0.01676\n",
      "early stopped!\n",
      "Best validation stage: 6\n",
      "========================= fold: 2 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01943\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0246, Training Loss:  0.02076, Val Loss:  0.01719\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0489, Training Loss:  0.01936, Val Loss:  0.01676\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0641, Training Loss:  0.01835, Val Loss:  0.01651\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0789, Training Loss:  0.01783, Val Loss:  0.01656\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.5 sec, boost rate:  1.0949, Training Loss:  0.01725, Val Loss:  0.01654\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.2 sec, boost rate:  1.1035, Training Loss:  0.01637, Val Loss:  0.01663\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  7.8 sec, boost rate:  1.1122, Training Loss:  0.01597, Val Loss:  0.01671\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.6 sec, boost rate:  1.1209, Training Loss:  0.01552, Val Loss:  0.01679\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.1 sec, boost rate:  1.1253, Training Loss:  0.01484, Val Loss:  0.01688\n",
      "early stopped!\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01945\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0229, Training Loss:  0.02068, Val Loss:  0.01716\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0417, Training Loss:  0.01933, Val Loss:  0.01683\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0583, Training Loss:  0.01828, Val Loss:  0.01656\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0737, Training Loss:  0.01770, Val Loss:  0.01657\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.5 sec, boost rate:  1.0895, Training Loss:  0.01722, Val Loss:  0.01657\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.3 sec, boost rate:  1.0982, Training Loss:  0.01630, Val Loss:  0.01658\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  8.0 sec, boost rate:  1.1068, Training Loss:  0.01585, Val Loss:  0.01672\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.7 sec, boost rate:  1.1153, Training Loss:  0.01542, Val Loss:  0.01674\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.5 sec, boost rate:  1.1198, Training Loss:  0.01473, Val Loss:  0.01684\n",
      "early stopped!\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01906\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0205, Training Loss:  0.02080, Val Loss:  0.01693\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0383, Training Loss:  0.01950, Val Loss:  0.01641\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0533, Training Loss:  0.01853, Val Loss:  0.01614\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0688, Training Loss:  0.01793, Val Loss:  0.01615\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.6 sec, boost rate:  1.0847, Training Loss:  0.01738, Val Loss:  0.01615\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.3 sec, boost rate:  1.0933, Training Loss:  0.01656, Val Loss:  0.01613\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  8.0 sec, boost rate:  1.1015, Training Loss:  0.01611, Val Loss:  0.01626\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.7 sec, boost rate:  1.1102, Training Loss:  0.01565, Val Loss:  0.01629\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.5 sec, boost rate:  1.1146, Training Loss:  0.01498, Val Loss:  0.01637\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.3 sec, boost rate:  1.1190, Training Loss:  0.01468, Val Loss:  0.01635\n",
      "Weight decoupling enabled in AdaBelief\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage - 11, training time:  11.0 sec, boost rate:  1.1234, Training Loss:  0.01441, Val Loss:  0.01652\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 12, training time:  11.7 sec, boost rate:  1.1257, Training Loss:  0.01395, Val Loss:  0.01652\n",
      "early stopped!\n",
      "Best validation stage: 6\n",
      "\n",
      "CV log_loss  0.016199415631157055\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 15\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"optimizer\"] = \"adabelief\"\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T10:54:08.924180Z",
     "start_time": "2020-11-20T10:42:53.022868Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_weight_norm', 'optimizer': 'adabelief', 'lr': 0.0001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 30, 'epochs_per_stage': 1, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50215662fdc47ae9f79ee8e0698c3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  3.1 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01987\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0022, Training Loss:  0.02241, Val Loss:  0.01893\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0059, Training Loss:  0.02159, Val Loss:  0.01832\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.0 sec, boost rate:  1.0077, Training Loss:  0.02103, Val Loss:  0.01806\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.0095, Training Loss:  0.02076, Val Loss:  0.01781\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.5 sec, boost rate:  1.0112, Training Loss:  0.02046, Val Loss:  0.01766\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.3 sec, boost rate:  1.0121, Training Loss:  0.02023, Val Loss:  0.01758\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  8.0 sec, boost rate:  1.0129, Training Loss:  0.02013, Val Loss:  0.01754\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.7 sec, boost rate:  1.0137, Training Loss:  0.02005, Val Loss:  0.01749\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.5 sec, boost rate:  1.0141, Training Loss:  0.01997, Val Loss:  0.01757\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.1 sec, boost rate:  1.0144, Training Loss:  0.01993, Val Loss:  0.01753\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  11.0 sec, boost rate:  1.0147, Training Loss:  0.01991, Val Loss:  0.01757\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 12, training time:  11.6 sec, boost rate:  1.0147, Training Loss:  0.01993, Val Loss:  0.01762\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 13, training time:  12.0 sec, boost rate:  1.0147, Training Loss:  0.01998, Val Loss:  0.01763\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 14, training time:  13.1 sec, boost rate:  1.0146, Training Loss:  0.02001, Val Loss:  0.01776\n",
      "early stopped!\n",
      "Best validation stage: 8\n",
      "========================= fold: 1 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01967\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0024, Training Loss:  0.02242, Val Loss:  0.01877\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0058, Training Loss:  0.02162, Val Loss:  0.01822\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0075, Training Loss:  0.02109, Val Loss:  0.01797\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.7 sec, boost rate:  1.0093, Training Loss:  0.02077, Val Loss:  0.01773\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.6 sec, boost rate:  1.0110, Training Loss:  0.02047, Val Loss:  0.01757\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.3 sec, boost rate:  1.0118, Training Loss:  0.02026, Val Loss:  0.01752\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  7.9 sec, boost rate:  1.0126, Training Loss:  0.02017, Val Loss:  0.01751\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.7 sec, boost rate:  1.0134, Training Loss:  0.02008, Val Loss:  0.01744\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.4 sec, boost rate:  1.0138, Training Loss:  0.01996, Val Loss:  0.01740\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.2 sec, boost rate:  1.0141, Training Loss:  0.02000, Val Loss:  0.01741\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  10.6 sec, boost rate:  1.0143, Training Loss:  0.01998, Val Loss:  0.01747\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 12, training time:  11.7 sec, boost rate:  1.0144, Training Loss:  0.01996, Val Loss:  0.01750\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 13, training time:  12.2 sec, boost rate:  1.0143, Training Loss:  0.02002, Val Loss:  0.01760\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 14, training time:  12.9 sec, boost rate:  1.0142, Training Loss:  0.02008, Val Loss:  0.01768\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 15, training time:  13.7 sec, boost rate:  1.0141, Training Loss:  0.02011, Val Loss:  0.01766\n",
      "early stopped!\n",
      "Best validation stage: 9\n",
      "========================= fold: 2 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01994\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0023, Training Loss:  0.02234, Val Loss:  0.01901\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.3 sec, boost rate:  1.0059, Training Loss:  0.02150, Val Loss:  0.01843\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0076, Training Loss:  0.02098, Val Loss:  0.01819\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0094, Training Loss:  0.02068, Val Loss:  0.01801\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.6 sec, boost rate:  1.0111, Training Loss:  0.02042, Val Loss:  0.01785\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.3 sec, boost rate:  1.0119, Training Loss:  0.02020, Val Loss:  0.01773\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  8.0 sec, boost rate:  1.0127, Training Loss:  0.02009, Val Loss:  0.01774\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.6 sec, boost rate:  1.0135, Training Loss:  0.02001, Val Loss:  0.01771\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.3 sec, boost rate:  1.0139, Training Loss:  0.01992, Val Loss:  0.01771\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.1 sec, boost rate:  1.0142, Training Loss:  0.01993, Val Loss:  0.01767\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  10.8 sec, boost rate:  1.0145, Training Loss:  0.01989, Val Loss:  0.01774\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 12, training time:  11.4 sec, boost rate:  1.0145, Training Loss:  0.01992, Val Loss:  0.01776\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 13, training time:  11.9 sec, boost rate:  1.0145, Training Loss:  0.01992, Val Loss:  0.01788\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 14, training time:  12.8 sec, boost rate:  1.0144, Training Loss:  0.01996, Val Loss:  0.01794\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 15, training time:  13.5 sec, boost rate:  1.0143, Training Loss:  0.02001, Val Loss:  0.01800\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 16, training time:  14.3 sec, boost rate:  1.0142, Training Loss:  0.02010, Val Loss:  0.01807\n",
      "early stopped!\n",
      "Best validation stage: 10\n",
      "========================= fold: 3 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.02007\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.7 sec, boost rate:  1.0020, Training Loss:  0.02237, Val Loss:  0.01907\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0057, Training Loss:  0.02152, Val Loss:  0.01843\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0075, Training Loss:  0.02097, Val Loss:  0.01818\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0093, Training Loss:  0.02066, Val Loss:  0.01801\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.4 sec, boost rate:  1.0110, Training Loss:  0.02041, Val Loss:  0.01786\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.2 sec, boost rate:  1.0119, Training Loss:  0.02016, Val Loss:  0.01783\n",
      "Weight decoupling enabled in AdaBelief\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage - 7, training time:  7.9 sec, boost rate:  1.0128, Training Loss:  0.02008, Val Loss:  0.01772\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.6 sec, boost rate:  1.0136, Training Loss:  0.01997, Val Loss:  0.01772\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.5 sec, boost rate:  1.0139, Training Loss:  0.01987, Val Loss:  0.01769\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.1 sec, boost rate:  1.0143, Training Loss:  0.01988, Val Loss:  0.01780\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  10.8 sec, boost rate:  1.0145, Training Loss:  0.01990, Val Loss:  0.01776\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 12, training time:  11.6 sec, boost rate:  1.0146, Training Loss:  0.01987, Val Loss:  0.01781\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 13, training time:  12.3 sec, boost rate:  1.0146, Training Loss:  0.01993, Val Loss:  0.01800\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 14, training time:  12.9 sec, boost rate:  1.0145, Training Loss:  0.01993, Val Loss:  0.01793\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 15, training time:  13.6 sec, boost rate:  1.0144, Training Loss:  0.01998, Val Loss:  0.01789\n",
      "early stopped!\n",
      "Best validation stage: 9\n",
      "========================= fold: 4 =========================\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 0, training time:  1.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01966\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 1, training time:  3.6 sec, boost rate:  1.0030, Training Loss:  0.02243, Val Loss:  0.01878\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 2, training time:  4.4 sec, boost rate:  1.0065, Training Loss:  0.02166, Val Loss:  0.01822\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 3, training time:  5.1 sec, boost rate:  1.0082, Training Loss:  0.02109, Val Loss:  0.01794\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 4, training time:  5.8 sec, boost rate:  1.0099, Training Loss:  0.02081, Val Loss:  0.01778\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 5, training time:  6.6 sec, boost rate:  1.0117, Training Loss:  0.02054, Val Loss:  0.01760\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 6, training time:  7.3 sec, boost rate:  1.0125, Training Loss:  0.02027, Val Loss:  0.01751\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 7, training time:  7.7 sec, boost rate:  1.0134, Training Loss:  0.02026, Val Loss:  0.01752\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 8, training time:  8.8 sec, boost rate:  1.0142, Training Loss:  0.02011, Val Loss:  0.01746\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 9, training time:  9.0 sec, boost rate:  1.0145, Training Loss:  0.02007, Val Loss:  0.01746\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 10, training time:  10.0 sec, boost rate:  1.0148, Training Loss:  0.02006, Val Loss:  0.01749\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 11, training time:  10.7 sec, boost rate:  1.0149, Training Loss:  0.02007, Val Loss:  0.01753\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 12, training time:  11.5 sec, boost rate:  1.0150, Training Loss:  0.02003, Val Loss:  0.01752\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 13, training time:  12.2 sec, boost rate:  1.0149, Training Loss:  0.02005, Val Loss:  0.01760\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 14, training time:  12.3 sec, boost rate:  1.0148, Training Loss:  0.02011, Val Loss:  0.01768\n",
      "Weight decoupling enabled in AdaBelief\n",
      "Stage - 15, training time:  13.5 sec, boost rate:  1.0147, Training Loss:  0.02011, Val Loss:  0.01769\n",
      "early stopped!\n",
      "Best validation stage: 9\n",
      "\n",
      "CV log_loss  0.01723842655829715\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 30\n",
    "params[\"model\"] = \"MLP_2HL_weight_norm\"\n",
    "params[\"optimizer\"] = \"adabelief\"\n",
    "params[\"lr\"] = 0.0001\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T11:20:22.238545Z",
     "start_time": "2020-11-20T11:15:40.806842Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'n_genes_pca': 50, 'n_cells_pca': 20, 'batch_size': 256, 'model': 'MLP_2HL_leaky_relu', 'optimizer': 'adam', 'lr': 0.001, 'weight_decay': 1e-05, 'n_folds': 5, 'early_stopping_steps': 5, 'hidden_size': 512, 'boost_rate': 1.0, 'num_nets': 5, 'epochs_per_stage': 3, 'correct_epoch': 1, 'model_order': 'second', 'feat_d': 873}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49cd99dd1e84ac098d40c1764a20c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  7.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01938\n",
      "Stage - 1, training time:  9.2 sec, boost rate:  0.9770, Training Loss:  0.02119, Val Loss:  0.01744\n",
      "Stage - 2, training time:  10.8 sec, boost rate:  0.9590, Training Loss:  0.01970, Val Loss:  0.01707\n",
      "Stage - 3, training time:  12.7 sec, boost rate:  0.9710, Training Loss:  0.01857, Val Loss:  0.01677\n",
      "Stage - 4, training time:  13.7 sec, boost rate:  0.9865, Training Loss:  0.01777, Val Loss:  0.01685\n",
      "Best validation stage: 3\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  5.0 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01908\n",
      "Stage - 1, training time:  9.2 sec, boost rate:  0.9708, Training Loss:  0.02123, Val Loss:  0.01742\n",
      "Stage - 2, training time:  10.8 sec, boost rate:  0.9542, Training Loss:  0.01980, Val Loss:  0.01694\n",
      "Stage - 3, training time:  12.5 sec, boost rate:  0.9659, Training Loss:  0.01855, Val Loss:  0.01678\n",
      "Stage - 4, training time:  14.3 sec, boost rate:  0.9785, Training Loss:  0.01779, Val Loss:  0.01675\n",
      "Best validation stage: 4\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  5.5 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01933\n",
      "Stage - 1, training time:  9.8 sec, boost rate:  0.9733, Training Loss:  0.02105, Val Loss:  0.01759\n",
      "Stage - 2, training time:  10.3 sec, boost rate:  0.9607, Training Loss:  0.01969, Val Loss:  0.01722\n",
      "Stage - 3, training time:  12.9 sec, boost rate:  0.9729, Training Loss:  0.01846, Val Loss:  0.01695\n",
      "Stage - 4, training time:  14.7 sec, boost rate:  0.9871, Training Loss:  0.01772, Val Loss:  0.01695\n",
      "Best validation stage: 4\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  5.3 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01965\n",
      "Stage - 1, training time:  9.4 sec, boost rate:  0.9743, Training Loss:  0.02115, Val Loss:  0.01759\n",
      "Stage - 2, training time:  11.6 sec, boost rate:  0.9533, Training Loss:  0.01972, Val Loss:  0.01703\n",
      "Stage - 3, training time:  12.9 sec, boost rate:  0.9661, Training Loss:  0.01846, Val Loss:  0.01699\n",
      "Stage - 4, training time:  12.0 sec, boost rate:  0.9797, Training Loss:  0.01775, Val Loss:  0.01699\n",
      "Best validation stage: 4\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  5.4 sec, boost rate:  1.0000, Training Loss:  0.00000, Val Loss:  0.01917\n",
      "Stage - 1, training time:  9.4 sec, boost rate:  0.9744, Training Loss:  0.02113, Val Loss:  0.01727\n",
      "Stage - 2, training time:  11.4 sec, boost rate:  0.9575, Training Loss:  0.01975, Val Loss:  0.01679\n",
      "Stage - 3, training time:  12.6 sec, boost rate:  0.9697, Training Loss:  0.01856, Val Loss:  0.01660\n",
      "Stage - 4, training time:  14.9 sec, boost rate:  0.9837, Training Loss:  0.01779, Val Loss:  0.01648\n",
      "Best validation stage: 4\n",
      "\n",
      "CV log_loss  0.016366973046641434\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from grownet_funcs import train_fn, params\n",
    "n_seeds = 1\n",
    "params[\"num_nets\"] = 5\n",
    "params[\"model\"] = \"MLP_2HL_leaky_relu\"\n",
    "params[\"epochs_per_stage\"] = 3\n",
    "score, y_pred = train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T12:57:29.011118Z",
     "start_time": "2020-11-19T12:57:28.948176Z"
    }
   },
   "source": [
    "# objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T07:57:33.685124Z",
     "start_time": "2020-11-20T07:57:33.584366Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"feat_d\": len(grownet_funcs.feature_cols),\n",
    "        \"early_stopping_steps\": 5,\n",
    "        \"n_folds\": 5,\n",
    "        \"hidden_size\": 512,\n",
    "        \"num_nets\": 40,\n",
    "        \"epochs_per_stage\": 1,  # Number of epochs to learn the Kth model. original: 1\n",
    "        \"correct_epoch\": 1,  #  Number of epochs to correct the whole week models original: 1\n",
    "        \"model_order\": \"second\",  # You could put \"first\" according to the original implemention, but error occurs. original: \"second\"\n",
    "    }\n",
    "    params[\"model\"]   = trial.suggest_categorical(\"model\", [\"MLP_2HL\",  \"MLP_2HL_weight_norm\"])\n",
    "    params[\"batch_size\"]   = trial.suggest_categorical(\"batch_size\", [8, 16, 64, 256, 1024])\n",
    "    params[\"lr\"]           = trial.suggest_categorical(\"lr\", [0.001, 0.01, 0.03])\n",
    "    params[\"optimizer\"]   = trial.suggest_categorical(\"optimizer\", [\"adam\",  \"adabelief\"])\n",
    "    params[\"weight_decay\"] = trial.suggest_loguniform(\"weight_decay\", 1e-07, 1e-3)\n",
    "    #params[\"hidden_size\"]  = trial.suggest_categorical(\"hidden_size\", [16, 64, 128, 256, 512, 1024])\n",
    "    params[\"boost_rate\"]   = trial.suggest_categorical(\"boost_rate\", [1.0, 5.0])  # ブースティング率. 修正ステップ中に自動的に調整される  # 0.5, \n",
    "    #params[\"num_nets\"]     = trial.suggest_categorical(\"num_nets\", [20, 40, 100])\n",
    "    \n",
    "    grownet_funcs.params = params\n",
    "    score, y_pred = grownet_funcs.train_fn(n_seeds)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T08:19:12.229387Z",
     "start_time": "2020-11-20T07:57:34.218514Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feat_d': 873, 'early_stopping_steps': 5, 'n_folds': 5, 'hidden_size': 512, 'num_nets': 40, 'epochs_per_stage': 10, 'correct_epoch': 1, 'model_order': 'second', 'model': 'MLP_2HL_weight_norm', 'batch_size': 256, 'lr': 0.001, 'optimizer': 'adam', 'weight_decay': 1.001053986051048e-07, 'boost_rate': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e085466f86fd4617a145890d569cb25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n",
      "Stage - 0, training time:  13.1 sec, boost rate:  5.0000, Training Loss:  0.00000, Val Loss:  0.01986\n",
      "Stage - 1, training time:  17.5 sec, boost rate:  4.9780, Training Loss:  0.02140, Val Loss:  0.01758\n",
      "Stage - 2, training time:  19.1 sec, boost rate:  4.9526, Training Loss:  0.02021, Val Loss:  0.01717\n",
      "Stage - 3, training time:  21.0 sec, boost rate:  4.9446, Training Loss:  0.01940, Val Loss:  0.01699\n",
      "Stage - 4, training time:  22.2 sec, boost rate:  4.9352, Training Loss:  0.01893, Val Loss:  0.01716\n",
      "Stage - 5, training time:  23.2 sec, boost rate:  4.9237, Training Loss:  0.01857, Val Loss:  0.01712\n",
      "Stage - 6, training time:  24.8 sec, boost rate:  4.9277, Training Loss:  0.01772, Val Loss:  0.01705\n",
      "Stage - 7, training time:  26.6 sec, boost rate:  4.9305, Training Loss:  0.01732, Val Loss:  0.01709\n",
      "Stage - 8, training time:  28.4 sec, boost rate:  4.9319, Training Loss:  0.01701, Val Loss:  0.01737\n",
      "Stage - 9, training time:  30.4 sec, boost rate:  4.9354, Training Loss:  0.01625, Val Loss:  0.01736\n",
      "early stopped!\n",
      "Best validation stage: 3\n",
      "========================= fold: 1 =========================\n",
      "Stage - 0, training time:  12.9 sec, boost rate:  5.0000, Training Loss:  0.00000, Val Loss:  0.01981\n",
      "Stage - 1, training time:  17.3 sec, boost rate:  4.9767, Training Loss:  0.02146, Val Loss:  0.01752\n",
      "Stage - 2, training time:  19.0 sec, boost rate:  4.9514, Training Loss:  0.02033, Val Loss:  0.01713\n",
      "Stage - 3, training time:  20.7 sec, boost rate:  4.9452, Training Loss:  0.01944, Val Loss:  0.01702\n",
      "Stage - 4, training time:  22.3 sec, boost rate:  4.9341, Training Loss:  0.01904, Val Loss:  0.01711\n",
      "Stage - 5, training time:  23.7 sec, boost rate:  4.9233, Training Loss:  0.01867, Val Loss:  0.01697\n",
      "Stage - 6, training time:  25.3 sec, boost rate:  4.9267, Training Loss:  0.01781, Val Loss:  0.01717\n",
      "Stage - 7, training time:  26.7 sec, boost rate:  4.9289, Training Loss:  0.01747, Val Loss:  0.01715\n",
      "Stage - 8, training time:  27.9 sec, boost rate:  4.9286, Training Loss:  0.01710, Val Loss:  0.01742\n",
      "Stage - 9, training time:  29.1 sec, boost rate:  4.9323, Training Loss:  0.01633, Val Loss:  0.01734\n",
      "Stage - 10, training time:  31.1 sec, boost rate:  4.9358, Training Loss:  0.01606, Val Loss:  0.01765\n",
      "Stage - 11, training time:  32.2 sec, boost rate:  4.9385, Training Loss:  0.01588, Val Loss:  0.01773\n",
      "early stopped!\n",
      "Best validation stage: 5\n",
      "========================= fold: 2 =========================\n",
      "Stage - 0, training time:  12.9 sec, boost rate:  5.0000, Training Loss:  0.00000, Val Loss:  0.02007\n",
      "Stage - 1, training time:  17.3 sec, boost rate:  4.9765, Training Loss:  0.02144, Val Loss:  0.01762\n",
      "Stage - 2, training time:  19.0 sec, boost rate:  4.9516, Training Loss:  0.02019, Val Loss:  0.01712\n",
      "Stage - 3, training time:  20.5 sec, boost rate:  4.9448, Training Loss:  0.01926, Val Loss:  0.01705\n",
      "Stage - 4, training time:  22.1 sec, boost rate:  4.9334, Training Loss:  0.01893, Val Loss:  0.01707\n",
      "Stage - 5, training time:  23.3 sec, boost rate:  4.9226, Training Loss:  0.01849, Val Loss:  0.01733\n",
      "Stage - 6, training time:  25.0 sec, boost rate:  4.9269, Training Loss:  0.01761, Val Loss:  0.01711\n",
      "Stage - 7, training time:  26.7 sec, boost rate:  4.9302, Training Loss:  0.01726, Val Loss:  0.01732\n",
      "Stage - 8, training time:  27.5 sec, boost rate:  4.9318, Training Loss:  0.01688, Val Loss:  0.01755\n",
      "Stage - 9, training time:  30.2 sec, boost rate:  4.9357, Training Loss:  0.01620, Val Loss:  0.01748\n",
      "early stopped!\n",
      "Best validation stage: 3\n",
      "========================= fold: 3 =========================\n",
      "Stage - 0, training time:  12.9 sec, boost rate:  5.0000, Training Loss:  0.00000, Val Loss:  0.01994\n",
      "Stage - 1, training time:  17.3 sec, boost rate:  4.9790, Training Loss:  0.02129, Val Loss:  0.01780\n",
      "Stage - 2, training time:  18.8 sec, boost rate:  4.9571, Training Loss:  0.02021, Val Loss:  0.01738\n",
      "Stage - 3, training time:  20.4 sec, boost rate:  4.9501, Training Loss:  0.01930, Val Loss:  0.01710\n",
      "Stage - 4, training time:  22.4 sec, boost rate:  4.9406, Training Loss:  0.01892, Val Loss:  0.01717\n",
      "Stage - 5, training time:  23.8 sec, boost rate:  4.9298, Training Loss:  0.01850, Val Loss:  0.01722\n",
      "Stage - 6, training time:  25.0 sec, boost rate:  4.9343, Training Loss:  0.01767, Val Loss:  0.01722\n",
      "Stage - 7, training time:  26.8 sec, boost rate:  4.9370, Training Loss:  0.01735, Val Loss:  0.01729\n",
      "Stage - 8, training time:  28.8 sec, boost rate:  4.9374, Training Loss:  0.01699, Val Loss:  0.01740\n",
      "Stage - 9, training time:  30.5 sec, boost rate:  4.9411, Training Loss:  0.01620, Val Loss:  0.01756\n",
      "early stopped!\n",
      "Best validation stage: 3\n",
      "========================= fold: 4 =========================\n",
      "Stage - 0, training time:  12.9 sec, boost rate:  5.0000, Training Loss:  0.00000, Val Loss:  0.01927\n",
      "Stage - 1, training time:  17.3 sec, boost rate:  4.9809, Training Loss:  0.02129, Val Loss:  0.01749\n",
      "Stage - 2, training time:  19.0 sec, boost rate:  4.9560, Training Loss:  0.02027, Val Loss:  0.01703\n",
      "Stage - 3, training time:  20.5 sec, boost rate:  4.9475, Training Loss:  0.01940, Val Loss:  0.01667\n",
      "Stage - 4, training time:  22.0 sec, boost rate:  4.9389, Training Loss:  0.01903, Val Loss:  0.01674\n",
      "Stage - 5, training time:  23.8 sec, boost rate:  4.9285, Training Loss:  0.01857, Val Loss:  0.01688\n",
      "Stage - 6, training time:  25.5 sec, boost rate:  4.9332, Training Loss:  0.01773, Val Loss:  0.01665\n",
      "Stage - 7, training time:  26.7 sec, boost rate:  4.9374, Training Loss:  0.01732, Val Loss:  0.01699\n",
      "Stage - 8, training time:  28.2 sec, boost rate:  4.9388, Training Loss:  0.01704, Val Loss:  0.01704\n",
      "Stage - 9, training time:  29.9 sec, boost rate:  4.9427, Training Loss:  0.01627, Val Loss:  0.01707\n",
      "Stage - 10, training time:  31.6 sec, boost rate:  4.9462, Training Loss:  0.01596, Val Loss:  0.01712\n",
      "Stage - 11, training time:  32.7 sec, boost rate:  4.9498, Training Loss:  0.01575, Val Loss:  0.01724\n",
      "Stage - 12, training time:  34.4 sec, boost rate:  4.9519, Training Loss:  0.01517, Val Loss:  0.01722\n",
      "early stopped!\n",
      "Best validation stage: 6\n",
      "\n",
      "CV log_loss  0.016586758462650217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-11-20 17:19:11,760] Finished trial#0 resulted in value: 0.016586758462650217. Current best value is 0.016586758462650217 with parameters: {'model': 'MLP_2HL_weight_norm', 'batch_size': 256, 'lr': 0.001, 'optimizer': 'adam', 'weight_decay': 1.001053986051048e-07, 'boost_rate': 5.0}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feat_d': 873, 'early_stopping_steps': 5, 'n_folds': 5, 'hidden_size': 512, 'num_nets': 40, 'epochs_per_stage': 10, 'correct_epoch': 1, 'model_order': 'second', 'model': 'MLP_2HL_weight_norm', 'batch_size': 8, 'lr': 0.001, 'optimizer': 'adabelief', 'weight_decay': 5.559565426712564e-07, 'boost_rate': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf74f08417c4a018439180bccbed48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "========================= fold: 0 =========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2020-11-20 17:19:12,137] Setting status of trial#1 as TrialState.FAIL because of the following error: TypeError('super(type, obj): obj must be an instance or subtype of type')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\81908\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\", line 539, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-15-368b99b19937>\", line 25, in objective\n",
      "    score, y_pred = grownet_funcs.train_fn(n_seeds)\n",
      "  File \"C:\\Users\\81908\\jupyter_notebook\\pytorch_work\\grownet_pytorch\\20201119_objective\\grownet_funcs.py\", line 625, in train_fn\n",
      "    optimizer = get_optim_adabelief(model.parameters(), lr, L2)\n",
      "  File \"C:\\Users\\81908\\jupyter_notebook\\pytorch_work\\grownet_pytorch\\20201119_objective\\grownet_funcs.py\", line 528, in get_optim_adabelief\n",
      "    rectify=False,\n",
      "  File \"C:\\Users\\81908\\Git\\Adabelief-Optimizer\\pypi_packages\\adabelief_pytorch0.1.0\\adabelief_pytorch\\AdaBelief.py\", line 102, in __init__\n",
      "    super(AdaBelief, self).__init__(params, defaults)\n",
      "TypeError: super(type, obj): obj must be an instance or subtype of type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 self._optimize_sequential(func, n_trials, timeout, catch, callbacks,\n\u001b[1;32m--> 261\u001b[1;33m                                           gc_after_trial)\n\u001b[0m\u001b[0;32m    262\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                 self._optimize_parallel(func, n_trials, timeout, n_jobs, catch, callbacks,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     def _optimize_parallel(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             message = 'Setting status of trial#{} as {}. {}'.format(trial_number,\n",
      "\u001b[1;32m<ipython-input-15-368b99b19937>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mgrownet_funcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrownet_funcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_seeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\pytorch_work\\grownet_pytorch\\20201119_objective\\grownet_funcs.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[1;34m(n_seeds)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"optimizer\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"adabelief\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optim_adabelief\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mnet_ensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Set the models in ensemble net to train mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\pytorch_work\\grownet_pytorch\\20201119_objective\\grownet_funcs.py\u001b[0m in \u001b[0;36mget_optim_adabelief\u001b[1;34m(params, lr, weight_decay)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[0mbetas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mweight_decouple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[0mrectify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m     )\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Git\\Adabelief-Optimizer\\pypi_packages\\adabelief_pytorch0.1.0\\adabelief_pytorch\\AdaBelief.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, weight_decouple, fixed_decay, rectify, degenerated_to_sgd)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mbuffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         )\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdaBelief\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegenerated_to_sgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdegenerated_to_sgd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_seeds = 1\n",
    "n_trials = 100\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"study\",\n",
    "    #storage=f\"sqlite:///study.db\",\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=1),\n",
    ")\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "study.trials_dataframe().to_csv(f\"objective_history.csv\", index=False)\n",
    "with open(f\"objective_best_params.txt\", mode=\"w\") as f:\n",
    "    f.write(str(study.best_params))\n",
    "print(f\"\\nstudy.best_params:\\n{study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run best param "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T06:33:04.189785Z",
     "start_time": "2020-11-20T06:32:57.450771Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36mbest_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\optuna\\storages\\in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[1;34m(self, study_id)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No trials are completed yet.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = study.best_params\n",
    "\n",
    "params[\"feat_d\"] = len(grownet_funcs.feature_cols)\n",
    "params[\"early_stopping_steps\"] = 30\n",
    "params[\"n_folds\"] = 5\n",
    "params[\"hidden_size\"] = 512\n",
    "params[\"num_nets\"] = 40\n",
    "params[\"epochs_per_stage\"] = 1\n",
    "params[\"correct_epoch\"] = 1\n",
    "params[\"model_order\"] = \"second\"\n",
    "\n",
    "grownet_funcs.params = params\n",
    "score, y_pred = grownet_funcs.train_fn(n_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T06:33:04.286523Z",
     "start_time": "2020-11-20T06:33:04.190753Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d2d780e36333>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T06:33:04.287496Z",
     "start_time": "2020-11-20T06:25:49.319Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r\"Y_pred.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    Y_pred = pickle.load(f)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T06:33:04.288494Z",
     "start_time": "2020-11-20T06:25:49.320Z"
    }
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\n",
    "    f\"{DATADIR}/train_features.csv\"\n",
    "    #, dtype=dtype, index_col=index_col\n",
    ")\n",
    "X = train_features.select_dtypes(\"number\")\n",
    "\n",
    "#test_features = pd.read_csv(\"../input/lish-moa/test_features.csv\")\n",
    "#sample_submission = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n",
    "sample_submission = pd.read_csv(f\"{DATADIR}/sample_submission.csv\")\n",
    "test_features = pd.read_csv(f\"{DATADIR}/test_features.csv\")\n",
    "\n",
    "test = test_features.copy()\n",
    "with open(\"./clipped_features.pkl\", \"rb\") as f:\n",
    "    clipped_features = pickle.load(f)\n",
    "test[X.columns] = clipped_features.transform(test[X.columns])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T06:33:04.289490Z",
     "start_time": "2020-11-20T06:25:49.321Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "x_test = test[feature_cols].values\n",
    "test_ds = TestDataset(x_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "for seed in tqdm(range(n_seeds)):\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    for fold in range(params[\"n_folds\"]):\n",
    "        net_ensemble = DynamicNet.from_file(\n",
    "            f\"./{fold}FOLD_{seed}_.pth\", lambda stage: MLP_2HL.get_model(stage, params)\n",
    "        )\n",
    "        if device == \"cuda\":\n",
    "            net_ensemble.to_cuda()\n",
    "        net_ensemble.to_eval()\n",
    "\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                x = data[\"x\"].to(device)\n",
    "                _, pred = net_ensemble.forward(x)\n",
    "                preds.append(pred.sigmoid().detach().cpu().numpy())\n",
    "        predictions += np.concatenate(preds) / (params[\"n_folds\"] * n_seeds)\n",
    "\n",
    "sample_submission[target_cols] = predictions\n",
    "\n",
    "sample_submission.loc[:, [\"atp-sensitive_potassium_channel_antagonist\", \"erbb2_inhibitor\"]] = 0.000012\n",
    "\n",
    "test = test.set_index(\"sig_id\")\n",
    "sample_submission = sample_submission.set_index(\"sig_id\")\n",
    "sample_submission[test[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n",
    "\n",
    "sample_submission.to_csv(\"submission.csv\")\n",
    "\n",
    "display(sample_submission)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
