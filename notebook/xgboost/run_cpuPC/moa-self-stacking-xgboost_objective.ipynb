{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Stacking GroupCV XGBoost\n",
    "\n",
    "In this notebook, I introduce a self-stacking XGBoost (XGB) pipeline. \n",
    "\n",
    "XGB model does not support multi-label learning so it cannot fully learn the label correlation as well as neural networks (NNs). Then I come up with an idea of self-stacking learning for XGB. The purpose is to enhance the label correlation learning by taking the first-stage predictions as additional features for the second-stage learning.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "- XGBoostでself-stacking  \n",
    "第1段階の予測値を第2段階の学習の追加特徴量とし、クラス間の関係性を学習させるのが目的\n",
    "https://www.kaggle.com/gogo827jz/self-stacking-groupcv-xgboost\n",
    "\n",
    "\n",
    "- ポジティブサンプル(=1)を多く含むターゲットを最初に学習させる\n",
    "oofを保存し、oofの予測値を特徴量として追加することで、ポジティブなサンプル数が少ない学習対象の特徴量を得る  \n",
    "https://www.kaggle.com/underwearfitting/partial-self-stacking-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.322220Z",
     "start_time": "2020-11-26T21:44:31.373224Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "kw1VW6DCvgSq",
    "outputId": "030d81e0-579d-463d-b2ed-6c714151a063"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import joblib\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.337223Z",
     "start_time": "2020-11-26T21:44:32.325224Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    rn.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.429221Z",
     "start_time": "2020-11-26T21:44:32.340222Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def score(Y, Y_pred):\n",
    "    _, n_classes = Y.shape\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for j in range(n_classes):\n",
    "        loss = log_loss(Y.iloc[:, j], Y_pred.iloc[:, j], labels=[0, 1])\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.522264Z",
     "start_time": "2020-11-26T21:44:32.431224Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def auc_score(Y, Y_pred):\n",
    "    _, n_classes = Y.shape\n",
    "\n",
    "    aucs = []\n",
    "\n",
    "    for j in range(n_classes):\n",
    "        auc = roc_auc_score(Y.iloc[:, j], Y_pred.iloc[:, j])\n",
    "\n",
    "        aucs.append(auc)\n",
    "\n",
    "    return np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.632199Z",
     "start_time": "2020-11-26T21:44:32.524231Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_row_statistics(X, prefix=\"\"):\n",
    "    Xt = pd.DataFrame()\n",
    "\n",
    "    for agg_func in [\n",
    "        # \"min\",\n",
    "        # \"max\",\n",
    "        \"mean\",\n",
    "        \"std\",\n",
    "        \"kurtosis\",\n",
    "        \"skew\",\n",
    "    ]:\n",
    "        Xt[f\"{prefix}{agg_func}\"] = X.agg(agg_func, axis=1)\n",
    "\n",
    "    return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.727232Z",
     "start_time": "2020-11-26T21:44:32.634205Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class ClippedFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, copy=True, high=0.99, low=0.01):\n",
    "        self.copy = copy\n",
    "        self.high = high\n",
    "        self.low = low\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.data_max_ = X.quantile(q=self.high)\n",
    "        self.data_min_ = X.quantile(q=self.low)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.copy:\n",
    "            X = X.copy()\n",
    "\n",
    "        X.clip(self.data_min_, self.data_max_, axis=1, inplace=True)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.834205Z",
     "start_time": "2020-11-26T21:44:32.731214Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "sys.path.append(r'C:\\Users\\yokoi.shingo\\GitHub\\iterative-stratification')\n",
    "\n",
    "import numpy as np\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "\n",
    "\n",
    "class MultilabelStratifiedGroupKFold(_BaseKFold):\n",
    "    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n",
    "        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "\n",
    "    def _iter_test_indices(self, X=None, y=None, groups=None):\n",
    "        cv = MultilabelStratifiedKFold(\n",
    "            n_splits=self.n_splits,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=self.shuffle,\n",
    "        )\n",
    "\n",
    "        value_counts = groups.value_counts()\n",
    "        regluar_indices = value_counts.loc[\n",
    "            (value_counts == 6) | (value_counts == 12) | (value_counts == 18)\n",
    "        ].index.sort_values()\n",
    "        irregluar_indices = value_counts.loc[\n",
    "            (value_counts != 6) & (value_counts != 12) & (value_counts != 18)\n",
    "        ].index.sort_values()\n",
    "\n",
    "        group_to_fold = {}\n",
    "        tmp = y.groupby(groups).mean().loc[regluar_indices]\n",
    "\n",
    "        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n",
    "            group_to_fold.update({group: fold for group in tmp.index[test]})\n",
    "\n",
    "        sample_to_fold = {}\n",
    "        tmp = y.loc[groups.isin(irregluar_indices)]\n",
    "\n",
    "        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n",
    "            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n",
    "\n",
    "        folds = groups.map(group_to_fold)\n",
    "        is_na = folds.isna()\n",
    "        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            yield np.where(folds == i)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSVuPpi2vgSv"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:32.927204Z",
     "start_time": "2020-11-26T21:44:32.836201Z"
    }
   },
   "outputs": [],
   "source": [
    "#dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\n",
    "#index_col = \"sig_id\"\n",
    "#\n",
    "#train_features = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_features.csv\", dtype=dtype, index_col=index_col\n",
    "#)\n",
    "#X = train_features.select_dtypes(\"number\")\n",
    "#Y_nonscored = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_targets_nonscored.csv\", index_col=index_col\n",
    "#)\n",
    "#Y = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\n",
    "#groups = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n",
    "#)\n",
    "#\n",
    "#test_features = pd.read_csv(\n",
    "#    \"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n",
    "#)\n",
    "#X_test = test_features.select_dtypes(\"number\")\n",
    "#\n",
    "#columns = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:37.085469Z",
     "start_time": "2020-11-26T21:44:32.929201Z"
    }
   },
   "outputs": [],
   "source": [
    "DATADIR = (\n",
    "    r\"C:\\Users\\yokoi.shingo\\my_task\\MoA_Prediction\\input\\lish-moa\"\n",
    ")\n",
    "\n",
    "dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\n",
    "index_col = \"sig_id\"\n",
    "\n",
    "train_features = pd.read_csv(\n",
    "    f\"{DATADIR}/train_features.csv\", dtype=dtype, index_col=index_col\n",
    ")\n",
    "X = train_features.select_dtypes(\"number\")\n",
    "Y_nonscored = pd.read_csv(\n",
    "    f\"{DATADIR}/train_targets_nonscored.csv\", index_col=index_col\n",
    ")\n",
    "Y = pd.read_csv(f\"{DATADIR}/train_targets_scored.csv\", index_col=index_col)\n",
    "groups = pd.read_csv(\n",
    "    f\"{DATADIR}/train_drug.csv\", index_col=index_col, squeeze=True\n",
    ")\n",
    "\n",
    "columns = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:40.936322Z",
     "start_time": "2020-11-26T21:44:37.087466Z"
    }
   },
   "outputs": [],
   "source": [
    "clipped_features = ClippedFeatures()\n",
    "X = clipped_features.fit_transform(X)\n",
    "\n",
    "with open(\"clipped_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clipped_features, f)\n",
    "\n",
    "c_prefix = \"c-\"\n",
    "g_prefix = \"g-\"\n",
    "c_columns = X.columns.str.startswith(c_prefix)\n",
    "g_columns = X.columns.str.startswith(g_prefix)\n",
    "X_c = compute_row_statistics(X.loc[:, c_columns], prefix=c_prefix)\n",
    "X_g = compute_row_statistics(X.loc[:, g_columns], prefix=g_prefix)\n",
    "X = pd.concat([X, X_c, X_g], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eDJ68r-vgTA"
   },
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:40.952296Z",
     "start_time": "2020-11-26T21:44:40.938294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: True\n"
     ]
    }
   ],
   "source": [
    "n_seeds = 1\n",
    "n_splits = 5\n",
    "LBS = 0.0008\n",
    "\n",
    "#param = {'objective': 'binary:logistic',\n",
    "#         'eval_metric': 'logloss', \n",
    "#         #'tree_method': 'gpu_hist', \n",
    "#         'verbosity': 0, \n",
    "#         'colsample_bytree': 0.1818593017814899, \n",
    "#         'eta': 0.012887963193108452, \n",
    "#         'gamma': 6.576022976359221, \n",
    "#         'max_depth': 8, \n",
    "#         'min_child_weight': 8.876744371188476, \n",
    "#         'subsample': 0.7813380253086911, \n",
    "#        }\n",
    "n_estimators = 2000\n",
    "early_stopping_rounds = 100\n",
    "\n",
    "\n",
    "#DEBUG = True\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    n_splits = 2\n",
    "    \n",
    "    n_estimators = 5\n",
    "    early_stopping_rounds = 2\n",
    "    \n",
    "    columns = [\n",
    "        \"atp-sensitive_potassium_channel_antagonist\",  # 陽性ラベル1個だけ\n",
    "        \"erbb2_inhibitor\",  # 陽性ラベル1個だけ\n",
    "        \"antiarrhythmic\",  # 陽性ラベル6個だけ\n",
    "#        \"aldehyde_dehydrogenase_inhibitor\",  # 陽性ラベル7個だけ\n",
    "#        \"lipase_inhibitor\",  # 陽性ラベル12個だけ\n",
    "#        \"sphingosine_receptor_agonist\",  # 陽性ラベル25個だけ\n",
    "#        \"igf-1_inhibitor\",  # 陽性ラベル37個だけ\n",
    "#        \"potassium_channel_activator\",  # 陽性ラベル55個だけ\n",
    "#        \"potassium_channel_antagonist\",  # 陽性ラベル98個だけ\n",
    "#        \"dopamine_receptor_agonist\",  # 陽性ラベル121個だけ\n",
    "#        \"nfkb_inhibitor\",  # 陽性ラベル832個\n",
    "#        \"cyclooxygenase_inhibitor\",  # 陽性ラベル435個\n",
    "#        \"dna_inhibitor\",  # 陽性ラベル402個\n",
    "#        \"glutamate_receptor_antagonist\",  # 陽性ラベル367個\n",
    "#        \"tubulin_inhibitor\",  # 陽性ラベル316個\n",
    "#        \"pdgfr_inhibitor\",  # 陽性ラベル297個\n",
    "#        \"calcium_channel_blocker\",  # 陽性ラベル281個\n",
    "        \"flt3_inhibitor\",  # 陽性ラベル279個\n",
    "        \"progesterone_receptor_agonist\",  # 陽性ラベル119個\n",
    "        \"hdac_inhibitor\",  # 陽性ラベル106個\n",
    "    ]\n",
    "    Y = Y[columns]\n",
    "    \n",
    "    top_k = Y.shape[1] // 2\n",
    "\n",
    "    print(f\"DEBUG: {DEBUG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:41.028293Z",
     "start_time": "2020-11-26T21:44:40.954297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes: 6\n"
     ]
    }
   ],
   "source": [
    "train_size, n_features = X.shape\n",
    "_, n_classes = Y.shape\n",
    "print(\"n_classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:41.104293Z",
     "start_time": "2020-11-26T21:44:41.030294Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_xgb(x, y, outdir, param):\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    y_pred = np.zeros((train_size, y.shape[1]))\n",
    "    y_pred = pd.DataFrame(y_pred, columns=y.columns, index=y.index)\n",
    "\n",
    "    for i in tqdm(range(n_seeds)):\n",
    "        set_seed(seed=i)\n",
    "\n",
    "        cv = MultilabelStratifiedGroupKFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "        cv_split = cv.split(x, y, groups)\n",
    "\n",
    "        for j, (trn_idx, val_idx) in enumerate(cv_split):\n",
    "            print(f\"------------ fold:{j} ------------\")\n",
    "\n",
    "            x_train, x_val = x.iloc[trn_idx], x.iloc[val_idx]\n",
    "            y_train_targets, y_val_targets = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "            # Label Smoothing\n",
    "            y_train_targets = y_train_targets * (1 - LBS) + 0.5 * LBS\n",
    "\n",
    "            for tar, tar_col in enumerate(y.columns):\n",
    "                y_train, y_val = y_train_targets.values[:, tar], y_val_targets.values[:, tar]\n",
    "\n",
    "                xgb_tr  = xgb.DMatrix(x_train, label=y_train, nthread=-1)\n",
    "                xgb_val = xgb.DMatrix(x_val, label=y_val, nthread=-1)\n",
    "\n",
    "                model = xgb.train(\n",
    "                    param,\n",
    "                    xgb_tr,\n",
    "                    n_estimators,\n",
    "                    [(xgb_val, 'eval')],\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose_eval=0,\n",
    "                )\n",
    "\n",
    "                y_pred[tar_col][val_idx] += (\n",
    "                    model.predict(xgb_val, ntree_limit=model.best_ntree_limit) / n_seeds\n",
    "                )\n",
    "\n",
    "                joblib.dump(\n",
    "                    model, f\"{outdir}/model_seed_{i}_fold_{j}_{y.columns[tar]}.jlb\", compress=True\n",
    "                )\n",
    "\n",
    "    y_pred[train_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:44:41.649294Z",
     "start_time": "2020-11-26T21:44:41.106301Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # https://www.kaggle.com/kst6690/make-your-xgboost-model-awesome-with-optuna\n",
    "    param = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        #'tree_method': 'gpu_hist',\n",
    "        \"verbosity\": 0,\n",
    "        \"nthread\": -1,\n",
    "    }\n",
    "    param[\"eta\"] = trial.suggest_loguniform(\"eta\", 0.005, 0.5)\n",
    "    param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 7)\n",
    "    param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 0, 5)\n",
    "    param[\"subsample\"] = trial.suggest_discrete_uniform(\"subsample\", 0.5, 1, 0.05)\n",
    "    param[\"alpha\"] = trial.suggest_loguniform(\"alpha\", 1e-8, 1.0)\n",
    "    param[\"gamma\"] = trial.suggest_int(\"gamma\", 0, 5)\n",
    "    param[\"colsample_bytree\"] = trial.suggest_discrete_uniform(\n",
    "        \"colsample_bytree\", 0.1, 1, 0.01\n",
    "    )\n",
    "\n",
    "    # pick top features that have more postive samples\n",
    "    if DEBUG:\n",
    "        top_k = trial.suggest_int(f\"top_k\", 2 , 4)\n",
    "    else:\n",
    "        top_k = trial.suggest_int(f\"top_k\", 10, 150)\n",
    "\n",
    "    easy_tar = Y.sum(axis=0).sort_values(ascending=False)[:top_k].index.values\n",
    "    hard_tar = Y.sum(axis=0).sort_values(ascending=False)[top_k:].index.values\n",
    "\n",
    "    # Stage 1: Training 'Easy' Target, more positive samples\n",
    "    Y_pred_easy = run_xgb(X, Y[easy_tar], \"first\", param)\n",
    "\n",
    "    # Stage 2(Self-Stacking): Training 'hard' targets, less postive samples\n",
    "    # update train and test for stage 2, append the oofs as features\n",
    "    X_add = pd.concat([X, Y_pred_easy[easy_tar]], axis=1)\n",
    "    Y_pred_hard = run_xgb(X_add, Y[hard_tar], \"second\", param)\n",
    "\n",
    "    # oof\n",
    "    Y_pred = Y_pred_hard.join(Y_pred_easy)\n",
    "    Y_pred = Y_pred[columns]\n",
    "    oof_logloss = score(Y[columns], Y_pred[columns])\n",
    "    oof_auc = auc_score(Y[columns], Y_pred[columns])\n",
    "    print(f\"oof_logloss:\", oof_logloss)\n",
    "    print(f\"oof_auc:\", oof_auc)\n",
    "\n",
    "    return oof_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:45:47.746952Z",
     "start_time": "2020-11-26T21:44:41.651302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-11-27 06:44:41,696] Using an existing study with name 'study' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd9545cc94d4453ad18718c19ccd9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flt3_inhibitor</th>\n",
       "      <th>progesterone_receptor_agonist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>0.421609</td>\n",
       "      <td>0.421611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0.421580</td>\n",
       "      <td>0.421339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>0.422089</td>\n",
       "      <td>0.421339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>0.421580</td>\n",
       "      <td>0.421339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>0.421580</td>\n",
       "      <td>0.421339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffb1ceed</th>\n",
       "      <td>0.422550</td>\n",
       "      <td>0.421611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffb70c0c</th>\n",
       "      <td>0.421580</td>\n",
       "      <td>0.421339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffc1c3f4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffcb9e7c</th>\n",
       "      <td>0.421580</td>\n",
       "      <td>0.421339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_ffffdd77b</th>\n",
       "      <td>0.422079</td>\n",
       "      <td>0.421611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              flt3_inhibitor  progesterone_receptor_agonist\n",
       "sig_id                                                     \n",
       "id_000644bb2        0.421609                       0.421611\n",
       "id_000779bfc        0.421580                       0.421339\n",
       "id_000a6266a        0.422089                       0.421339\n",
       "id_0015fd391        0.421580                       0.421339\n",
       "id_001626bd3        0.421580                       0.421339\n",
       "...                      ...                            ...\n",
       "id_fffb1ceed        0.422550                       0.421611\n",
       "id_fffb70c0c        0.421580                       0.421339\n",
       "id_fffc1c3f4        0.000000                       0.000000\n",
       "id_fffcb9e7c        0.421580                       0.421339\n",
       "id_ffffdd77b        0.422079                       0.421611\n",
       "\n",
       "[23814 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7126559bd7ec4764a8b0bd06cc9b4051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "\n",
      "oof_logloss: 0.504814312519931\n",
      "oof_auc: 0.509719358317022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-11-27 06:45:01,692] Trial 1 finished with value: 0.504814312519931 and parameters: {'eta': 0.03412039213549417, 'max_depth': 5, 'min_child_weight': 0, 'subsample': 0.5, 'alpha': 2.622168410226067e-06, 'gamma': 0, 'colsample_bytree': 0.18, 'top_k': 2}. Best is trial 1 with value: 0.504814312519931.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6a6fed3535421888d9cdf8298bfbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flt3_inhibitor</th>\n",
       "      <th>progesterone_receptor_agonist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>0.430183</td>\n",
       "      <td>0.430724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0.430624</td>\n",
       "      <td>0.430551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>0.430624</td>\n",
       "      <td>0.430551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>0.430624</td>\n",
       "      <td>0.430551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>0.430624</td>\n",
       "      <td>0.430551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffb1ceed</th>\n",
       "      <td>0.430183</td>\n",
       "      <td>0.430724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffb70c0c</th>\n",
       "      <td>0.430624</td>\n",
       "      <td>0.430551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffc1c3f4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffcb9e7c</th>\n",
       "      <td>0.430624</td>\n",
       "      <td>0.430551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_ffffdd77b</th>\n",
       "      <td>0.432445</td>\n",
       "      <td>0.430724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              flt3_inhibitor  progesterone_receptor_agonist\n",
       "sig_id                                                     \n",
       "id_000644bb2        0.430183                       0.430724\n",
       "id_000779bfc        0.430624                       0.430551\n",
       "id_000a6266a        0.430624                       0.430551\n",
       "id_0015fd391        0.430624                       0.430551\n",
       "id_001626bd3        0.430624                       0.430551\n",
       "...                      ...                            ...\n",
       "id_fffb1ceed        0.430183                       0.430724\n",
       "id_fffb70c0c        0.430624                       0.430551\n",
       "id_fffc1c3f4        0.000000                       0.000000\n",
       "id_fffcb9e7c        0.430624                       0.430551\n",
       "id_ffffdd77b        0.432445                       0.430724\n",
       "\n",
       "[23814 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f43cb3bef564a758d929a2d4a5eff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "\n",
      "oof_logloss: 0.519471593084108\n",
      "oof_auc: 0.5137671019767709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-11-27 06:45:26,844] Trial 2 finished with value: 0.519471593084108 and parameters: {'eta': 0.029839496219183886, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.75, 'alpha': 2.257127620305132e-05, 'gamma': 2, 'colsample_bytree': 0.5700000000000001, 'top_k': 2}. Best is trial 1 with value: 0.504814312519931.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932a2e73dc9e44429809e44e1c3793b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flt3_inhibitor</th>\n",
       "      <th>progesterone_receptor_agonist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>0.111980</td>\n",
       "      <td>0.113775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0.111986</td>\n",
       "      <td>0.113006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>0.123975</td>\n",
       "      <td>0.113006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>0.112655</td>\n",
       "      <td>0.113006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>0.111986</td>\n",
       "      <td>0.113006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffb1ceed</th>\n",
       "      <td>0.111980</td>\n",
       "      <td>0.113775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffb70c0c</th>\n",
       "      <td>0.111986</td>\n",
       "      <td>0.113006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffc1c3f4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_fffcb9e7c</th>\n",
       "      <td>0.111986</td>\n",
       "      <td>0.113006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_ffffdd77b</th>\n",
       "      <td>0.135189</td>\n",
       "      <td>0.113775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              flt3_inhibitor  progesterone_receptor_agonist\n",
       "sig_id                                                     \n",
       "id_000644bb2        0.111980                       0.113775\n",
       "id_000779bfc        0.111986                       0.113006\n",
       "id_000a6266a        0.123975                       0.113006\n",
       "id_0015fd391        0.112655                       0.113006\n",
       "id_001626bd3        0.111986                       0.113006\n",
       "...                      ...                            ...\n",
       "id_fffb1ceed        0.111980                       0.113775\n",
       "id_fffb70c0c        0.111986                       0.113006\n",
       "id_fffc1c3f4        0.000000                       0.000000\n",
       "id_fffcb9e7c        0.111986                       0.113006\n",
       "id_ffffdd77b        0.135189                       0.113775\n",
       "\n",
       "[23814 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063c53896e734b1ea52627692183cb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "\n",
      "oof_logloss: 0.11495277667391858\n",
      "oof_auc: 0.5228976170358587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-11-27 06:45:47,673] Trial 3 finished with value: 0.11495277667391858 and parameters: {'eta': 0.285236354410184, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 1.0, 'alpha': 4.546094549217937e-05, 'gamma': 1, 'colsample_bytree': 0.22, 'top_k': 2}. Best is trial 3 with value: 0.11495277667391858.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "study.best_params:\n",
      "{'alpha': 4.546094549217937e-05, 'colsample_bytree': 0.22, 'eta': 0.285236354410184, 'gamma': 1, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 1.0, 'top_k': 2}\n",
      "\n",
      "study.best_value:\n",
      "0.11495277667391858\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_trials = 400\n",
    "#n_trials = 100\n",
    "#n_trials = 3\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"study\",\n",
    "    storage=f\"sqlite:///study.db\",\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=1),\n",
    ")\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "study.trials_dataframe().to_csv(f\"objective_history.csv\", index=False)\n",
    "with open(f\"objective_best_params.txt\", mode=\"w\") as f:\n",
    "    f.write(str(study.best_params))\n",
    "print(f\"\\nstudy.best_params:\\n{study.best_params}\")\n",
    "print(f\"\\nstudy.best_value:\\n{study.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:45:47.983041Z",
     "start_time": "2020-11-26T21:45:47.748951Z"
    },
    "incorrectly_encoded_metadata": "_kg_hide-output=true"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/lish-moa/test_features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/lish-moa/test_features.csv'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_features = pd.read_csv(\n",
    "    \"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n",
    ")\n",
    "X_test = test_features.select_dtypes(\"number\")\n",
    "\n",
    "\n",
    "with open(\"./clipped_features.pkl\", \"rb\") as f:\n",
    "    clipped_features = pickle.load(f)\n",
    "X_test = clipped_features.transform(X_test)\n",
    "X_c = compute_row_statistics(X_test.loc[:, c_columns], prefix=c_prefix)\n",
    "X_g = compute_row_statistics(X_test.loc[:, g_columns], prefix=g_prefix)\n",
    "X_test = pd.concat([X_test, X_c, X_g], axis=1)\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "\n",
    "xgb_tt = xgb.DMatrix(X_test, nthread=-1)\n",
    "\n",
    "Y_test_pred = np.zeros((X_test.shape[0], len(columns)))\n",
    "Y_test_pred = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\n",
    "\n",
    "for i in range(n_seeds):\n",
    "    for j in range(n_splits):\n",
    "        for tar, tar_col in enumerate(easy_tar):\n",
    "\n",
    "            m_path = f\"first/model_seed_{i}_fold_{j}_{tar_col}.jlb\"\n",
    "\n",
    "            if os.path.exists(m_path):\n",
    "                print(m_path)\n",
    "                model = joblib.load(m_path)\n",
    "                Y_test_pred.loc[:, tar_col] += model.predict(xgb_tt, ntree_limit=model.best_ntree_limit) / (n_seeds * n_splits)\n",
    "            else:\n",
    "                Y_test_pred.loc[:, tar_col] += np.array([Y_pred.iloc[:,tar].mean()] * X_test.shape[0]) / (n_seeds * n_splits)\n",
    "\n",
    "X_test = pd.concat([X_test, Y_test_pred[easy_tar]], axis=1)\n",
    "xgb_tt = xgb.DMatrix(X_test, nthread=-1)\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "                \n",
    "for i in range(n_seeds):\n",
    "    for j in range(n_splits):\n",
    "        for tar, tar_col in enumerate(hard_tar):\n",
    "\n",
    "            m_path = f\"second/model_seed_{i}_fold_{j}_{tar_col}.jlb\"\n",
    "\n",
    "            if os.path.exists(m_path):\n",
    "                print(m_path)\n",
    "                model = joblib.load(m_path)\n",
    "                Y_test_pred.loc[:, tar_col] += model.predict(xgb_tt, ntree_limit=model.best_ntree_limit) / (n_seeds * n_splits)\n",
    "            else:\n",
    "                Y_test_pred.loc[:, tar_col] += np.array([Y_pred.iloc[:,tar].mean()] * X_test.shape[0]) / (n_seeds * n_splits)\n",
    "\n",
    "\n",
    "Y_test_pred[test_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n",
    "\n",
    "Y_test_pred.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T21:45:47.998016Z",
     "start_time": "2020-11-26T21:45:47.985032Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1ddd87432f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(Y_test_pred.shape)\n",
    "display(Y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
