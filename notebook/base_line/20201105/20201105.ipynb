{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:45.331028Z",
     "start_time": "2020-11-06T01:11:45.310058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\81908\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\notebook\\base_line\\20201105\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:46.624954Z",
     "start_time": "2020-11-06T01:11:46.053309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\users\\\\81908\\\\appdata\\\\local\\\\pypoetry\\\\cache\\\\virtualenvs\\\\tfgpu-ehdmne1y-py3.8\\\\scripts\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:53.648554Z",
     "start_time": "2020-11-06T01:11:46.719723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\81908\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\")\n",
    "import mlp_tf, datasets, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:53.773219Z",
     "start_time": "2020-11-06T01:11:53.649525Z"
    },
    "code_folding": [],
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        train_targets_nonscored,\n",
    "        train_drug,\n",
    "    ) = datasets.load_orig_data()\n",
    "    train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "        train, train_targets, test, train_targets_nonscored\n",
    "    )\n",
    "    return (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        train.columns[2:],\n",
    "        train_targets_nonscored,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 条件かえてoof_log_loss確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:57.079356Z",
     "start_time": "2020-11-06T01:11:53.774191Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:57.266387Z",
     "start_time": "2020-11-06T01:11:57.079356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>adrenergic_receptor_antagonist</th>\n",
       "      <th>akt_inhibitor</th>\n",
       "      <th>aldehyde_dehydrogenase_inhibitor</th>\n",
       "      <th>alk_inhibitor</th>\n",
       "      <th>ampk_activator</th>\n",
       "      <th>analgesic</th>\n",
       "      <th>androgen_receptor_agonist</th>\n",
       "      <th>androgen_receptor_antagonist</th>\n",
       "      <th>anesthetic_-_local</th>\n",
       "      <th>angiogenesis_inhibitor</th>\n",
       "      <th>angiotensin_receptor_antagonist</th>\n",
       "      <th>anti-inflammatory</th>\n",
       "      <th>antiarrhythmic</th>\n",
       "      <th>antibiotic</th>\n",
       "      <th>anticonvulsant</th>\n",
       "      <th>antifungal</th>\n",
       "      <th>antihistamine</th>\n",
       "      <th>antimalarial</th>\n",
       "      <th>antioxidant</th>\n",
       "      <th>antiprotozoal</th>\n",
       "      <th>antiviral</th>\n",
       "      <th>apoptosis_stimulant</th>\n",
       "      <th>aromatase_inhibitor</th>\n",
       "      <th>atm_kinase_inhibitor</th>\n",
       "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
       "      <th>atp_synthase_inhibitor</th>\n",
       "      <th>atpase_inhibitor</th>\n",
       "      <th>atr_kinase_inhibitor</th>\n",
       "      <th>aurora_kinase_inhibitor</th>\n",
       "      <th>autotaxin_inhibitor</th>\n",
       "      <th>bacterial_30s_ribosomal_subunit_inhibitor</th>\n",
       "      <th>bacterial_50s_ribosomal_subunit_inhibitor</th>\n",
       "      <th>bacterial_antifolate</th>\n",
       "      <th>bacterial_cell_wall_synthesis_inhibitor</th>\n",
       "      <th>bacterial_dna_gyrase_inhibitor</th>\n",
       "      <th>bacterial_dna_inhibitor</th>\n",
       "      <th>bacterial_membrane_integrity_inhibitor</th>\n",
       "      <th>bcl_inhibitor</th>\n",
       "      <th>bcr-abl_inhibitor</th>\n",
       "      <th>benzodiazepine_receptor_agonist</th>\n",
       "      <th>beta_amyloid_inhibitor</th>\n",
       "      <th>bromodomain_inhibitor</th>\n",
       "      <th>btk_inhibitor</th>\n",
       "      <th>calcineurin_inhibitor</th>\n",
       "      <th>calcium_channel_blocker</th>\n",
       "      <th>cannabinoid_receptor_agonist</th>\n",
       "      <th>cannabinoid_receptor_antagonist</th>\n",
       "      <th>carbonic_anhydrase_inhibitor</th>\n",
       "      <th>casein_kinase_inhibitor</th>\n",
       "      <th>caspase_activator</th>\n",
       "      <th>catechol_o_methyltransferase_inhibitor</th>\n",
       "      <th>cc_chemokine_receptor_antagonist</th>\n",
       "      <th>cck_receptor_antagonist</th>\n",
       "      <th>cdk_inhibitor</th>\n",
       "      <th>chelating_agent</th>\n",
       "      <th>chk_inhibitor</th>\n",
       "      <th>chloride_channel_blocker</th>\n",
       "      <th>cholesterol_inhibitor</th>\n",
       "      <th>cholinergic_receptor_antagonist</th>\n",
       "      <th>coagulation_factor_inhibitor</th>\n",
       "      <th>corticosteroid_agonist</th>\n",
       "      <th>cyclooxygenase_inhibitor</th>\n",
       "      <th>cytochrome_p450_inhibitor</th>\n",
       "      <th>dihydrofolate_reductase_inhibitor</th>\n",
       "      <th>dipeptidyl_peptidase_inhibitor</th>\n",
       "      <th>diuretic</th>\n",
       "      <th>dna_alkylating_agent</th>\n",
       "      <th>dna_inhibitor</th>\n",
       "      <th>dopamine_receptor_agonist</th>\n",
       "      <th>dopamine_receptor_antagonist</th>\n",
       "      <th>egfr_inhibitor</th>\n",
       "      <th>elastase_inhibitor</th>\n",
       "      <th>erbb2_inhibitor</th>\n",
       "      <th>estrogen_receptor_agonist</th>\n",
       "      <th>estrogen_receptor_antagonist</th>\n",
       "      <th>faah_inhibitor</th>\n",
       "      <th>farnesyltransferase_inhibitor</th>\n",
       "      <th>fatty_acid_receptor_agonist</th>\n",
       "      <th>fgfr_inhibitor</th>\n",
       "      <th>flt3_inhibitor</th>\n",
       "      <th>focal_adhesion_kinase_inhibitor</th>\n",
       "      <th>free_radical_scavenger</th>\n",
       "      <th>fungal_squalene_epoxidase_inhibitor</th>\n",
       "      <th>gaba_receptor_agonist</th>\n",
       "      <th>gaba_receptor_antagonist</th>\n",
       "      <th>gamma_secretase_inhibitor</th>\n",
       "      <th>glucocorticoid_receptor_agonist</th>\n",
       "      <th>glutamate_inhibitor</th>\n",
       "      <th>glutamate_receptor_agonist</th>\n",
       "      <th>glutamate_receptor_antagonist</th>\n",
       "      <th>gonadotropin_receptor_agonist</th>\n",
       "      <th>gsk_inhibitor</th>\n",
       "      <th>hcv_inhibitor</th>\n",
       "      <th>hdac_inhibitor</th>\n",
       "      <th>histamine_receptor_agonist</th>\n",
       "      <th>histamine_receptor_antagonist</th>\n",
       "      <th>histone_lysine_demethylase_inhibitor</th>\n",
       "      <th>histone_lysine_methyltransferase_inhibitor</th>\n",
       "      <th>hiv_inhibitor</th>\n",
       "      <th>hmgcr_inhibitor</th>\n",
       "      <th>hsp_inhibitor</th>\n",
       "      <th>igf-1_inhibitor</th>\n",
       "      <th>ikk_inhibitor</th>\n",
       "      <th>imidazoline_receptor_agonist</th>\n",
       "      <th>immunosuppressant</th>\n",
       "      <th>insulin_secretagogue</th>\n",
       "      <th>insulin_sensitizer</th>\n",
       "      <th>integrin_inhibitor</th>\n",
       "      <th>jak_inhibitor</th>\n",
       "      <th>kit_inhibitor</th>\n",
       "      <th>laxative</th>\n",
       "      <th>leukotriene_inhibitor</th>\n",
       "      <th>leukotriene_receptor_antagonist</th>\n",
       "      <th>lipase_inhibitor</th>\n",
       "      <th>lipoxygenase_inhibitor</th>\n",
       "      <th>lxr_agonist</th>\n",
       "      <th>mdm_inhibitor</th>\n",
       "      <th>mek_inhibitor</th>\n",
       "      <th>membrane_integrity_inhibitor</th>\n",
       "      <th>mineralocorticoid_receptor_antagonist</th>\n",
       "      <th>monoacylglycerol_lipase_inhibitor</th>\n",
       "      <th>monoamine_oxidase_inhibitor</th>\n",
       "      <th>monopolar_spindle_1_kinase_inhibitor</th>\n",
       "      <th>mtor_inhibitor</th>\n",
       "      <th>mucolytic_agent</th>\n",
       "      <th>neuropeptide_receptor_antagonist</th>\n",
       "      <th>nfkb_inhibitor</th>\n",
       "      <th>nicotinic_receptor_agonist</th>\n",
       "      <th>nitric_oxide_donor</th>\n",
       "      <th>nitric_oxide_production_inhibitor</th>\n",
       "      <th>nitric_oxide_synthase_inhibitor</th>\n",
       "      <th>norepinephrine_reuptake_inhibitor</th>\n",
       "      <th>nrf2_activator</th>\n",
       "      <th>opioid_receptor_agonist</th>\n",
       "      <th>opioid_receptor_antagonist</th>\n",
       "      <th>orexin_receptor_antagonist</th>\n",
       "      <th>p38_mapk_inhibitor</th>\n",
       "      <th>p-glycoprotein_inhibitor</th>\n",
       "      <th>parp_inhibitor</th>\n",
       "      <th>pdgfr_inhibitor</th>\n",
       "      <th>pdk_inhibitor</th>\n",
       "      <th>phosphodiesterase_inhibitor</th>\n",
       "      <th>phospholipase_inhibitor</th>\n",
       "      <th>pi3k_inhibitor</th>\n",
       "      <th>pkc_inhibitor</th>\n",
       "      <th>potassium_channel_activator</th>\n",
       "      <th>potassium_channel_antagonist</th>\n",
       "      <th>ppar_receptor_agonist</th>\n",
       "      <th>ppar_receptor_antagonist</th>\n",
       "      <th>progesterone_receptor_agonist</th>\n",
       "      <th>progesterone_receptor_antagonist</th>\n",
       "      <th>prostaglandin_inhibitor</th>\n",
       "      <th>prostanoid_receptor_antagonist</th>\n",
       "      <th>proteasome_inhibitor</th>\n",
       "      <th>protein_kinase_inhibitor</th>\n",
       "      <th>protein_phosphatase_inhibitor</th>\n",
       "      <th>protein_synthesis_inhibitor</th>\n",
       "      <th>protein_tyrosine_kinase_inhibitor</th>\n",
       "      <th>radiopaque_medium</th>\n",
       "      <th>raf_inhibitor</th>\n",
       "      <th>ras_gtpase_inhibitor</th>\n",
       "      <th>retinoid_receptor_agonist</th>\n",
       "      <th>retinoid_receptor_antagonist</th>\n",
       "      <th>rho_associated_kinase_inhibitor</th>\n",
       "      <th>ribonucleoside_reductase_inhibitor</th>\n",
       "      <th>rna_polymerase_inhibitor</th>\n",
       "      <th>serotonin_receptor_agonist</th>\n",
       "      <th>serotonin_receptor_antagonist</th>\n",
       "      <th>serotonin_reuptake_inhibitor</th>\n",
       "      <th>sigma_receptor_agonist</th>\n",
       "      <th>sigma_receptor_antagonist</th>\n",
       "      <th>smoothened_receptor_antagonist</th>\n",
       "      <th>sodium_channel_inhibitor</th>\n",
       "      <th>sphingosine_receptor_agonist</th>\n",
       "      <th>src_inhibitor</th>\n",
       "      <th>steroid</th>\n",
       "      <th>syk_inhibitor</th>\n",
       "      <th>tachykinin_antagonist</th>\n",
       "      <th>tgf-beta_receptor_inhibitor</th>\n",
       "      <th>thrombin_inhibitor</th>\n",
       "      <th>thymidylate_synthase_inhibitor</th>\n",
       "      <th>tlr_agonist</th>\n",
       "      <th>tlr_antagonist</th>\n",
       "      <th>tnf_inhibitor</th>\n",
       "      <th>topoisomerase_inhibitor</th>\n",
       "      <th>transient_receptor_potential_channel_antagonist</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  adrenergic_receptor_agonist  \\\n",
       "0                               0                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "23809                           0                            0   \n",
       "23810                           0                            0   \n",
       "23811                           0                            0   \n",
       "23812                           0                            0   \n",
       "23813                           0                            0   \n",
       "\n",
       "       adrenergic_receptor_antagonist  akt_inhibitor  \\\n",
       "0                                   0              0   \n",
       "1                                   0              0   \n",
       "2                                   0              0   \n",
       "3                                   0              0   \n",
       "4                                   0              0   \n",
       "...                               ...            ...   \n",
       "23809                               0              0   \n",
       "23810                               0              0   \n",
       "23811                               0              0   \n",
       "23812                               0              0   \n",
       "23813                               0              0   \n",
       "\n",
       "       aldehyde_dehydrogenase_inhibitor  alk_inhibitor  ampk_activator  \\\n",
       "0                                     0              0               0   \n",
       "1                                     0              0               0   \n",
       "2                                     0              0               0   \n",
       "3                                     0              0               0   \n",
       "4                                     0              0               0   \n",
       "...                                 ...            ...             ...   \n",
       "23809                                 0              0               0   \n",
       "23810                                 0              0               0   \n",
       "23811                                 0              0               0   \n",
       "23812                                 0              0               0   \n",
       "23813                                 0              0               0   \n",
       "\n",
       "       analgesic  androgen_receptor_agonist  androgen_receptor_antagonist  \\\n",
       "0              0                          0                             0   \n",
       "1              0                          0                             0   \n",
       "2              0                          0                             0   \n",
       "3              0                          0                             0   \n",
       "4              0                          0                             0   \n",
       "...          ...                        ...                           ...   \n",
       "23809          0                          0                             0   \n",
       "23810          0                          0                             0   \n",
       "23811          0                          0                             0   \n",
       "23812          0                          0                             0   \n",
       "23813          0                          0                             0   \n",
       "\n",
       "       anesthetic_-_local  angiogenesis_inhibitor  \\\n",
       "0                       0                       0   \n",
       "1                       0                       0   \n",
       "2                       0                       0   \n",
       "3                       0                       0   \n",
       "4                       0                       0   \n",
       "...                   ...                     ...   \n",
       "23809                   0                       0   \n",
       "23810                   0                       0   \n",
       "23811                   0                       0   \n",
       "23812                   0                       0   \n",
       "23813                   0                       0   \n",
       "\n",
       "       angiotensin_receptor_antagonist  anti-inflammatory  antiarrhythmic  \\\n",
       "0                                    0                  0               0   \n",
       "1                                    0                  0               0   \n",
       "2                                    0                  0               0   \n",
       "3                                    0                  0               0   \n",
       "4                                    0                  0               0   \n",
       "...                                ...                ...             ...   \n",
       "23809                                0                  0               0   \n",
       "23810                                0                  0               0   \n",
       "23811                                0                  0               0   \n",
       "23812                                0                  0               0   \n",
       "23813                                0                  0               0   \n",
       "\n",
       "       antibiotic  anticonvulsant  antifungal  antihistamine  antimalarial  \\\n",
       "0               0               0           0              0             0   \n",
       "1               0               0           0              0             0   \n",
       "2               0               0           0              0             0   \n",
       "3               0               0           0              0             0   \n",
       "4               0               0           0              0             0   \n",
       "...           ...             ...         ...            ...           ...   \n",
       "23809           0               0           0              0             0   \n",
       "23810           0               0           0              0             0   \n",
       "23811           0               0           0              0             0   \n",
       "23812           0               0           0              0             0   \n",
       "23813           0               0           0              0             0   \n",
       "\n",
       "       antioxidant  antiprotozoal  antiviral  apoptosis_stimulant  \\\n",
       "0                0              0          0                    0   \n",
       "1                0              0          0                    0   \n",
       "2                0              0          0                    0   \n",
       "3                0              0          0                    0   \n",
       "4                0              0          0                    0   \n",
       "...            ...            ...        ...                  ...   \n",
       "23809            0              0          0                    0   \n",
       "23810            0              0          0                    0   \n",
       "23811            0              0          0                    0   \n",
       "23812            0              0          0                    0   \n",
       "23813            0              0          0                    0   \n",
       "\n",
       "       aromatase_inhibitor  atm_kinase_inhibitor  \\\n",
       "0                        0                     0   \n",
       "1                        0                     0   \n",
       "2                        0                     0   \n",
       "3                        0                     0   \n",
       "4                        0                     0   \n",
       "...                    ...                   ...   \n",
       "23809                    0                     0   \n",
       "23810                    0                     0   \n",
       "23811                    0                     0   \n",
       "23812                    0                     0   \n",
       "23813                    0                     0   \n",
       "\n",
       "       atp-sensitive_potassium_channel_antagonist  atp_synthase_inhibitor  \\\n",
       "0                                               0                       0   \n",
       "1                                               0                       0   \n",
       "2                                               0                       0   \n",
       "3                                               0                       0   \n",
       "4                                               0                       0   \n",
       "...                                           ...                     ...   \n",
       "23809                                           0                       0   \n",
       "23810                                           0                       0   \n",
       "23811                                           0                       0   \n",
       "23812                                           0                       0   \n",
       "23813                                           0                       0   \n",
       "\n",
       "       atpase_inhibitor  atr_kinase_inhibitor  aurora_kinase_inhibitor  \\\n",
       "0                     0                     0                        0   \n",
       "1                     0                     0                        0   \n",
       "2                     0                     0                        0   \n",
       "3                     0                     0                        0   \n",
       "4                     0                     0                        0   \n",
       "...                 ...                   ...                      ...   \n",
       "23809                 0                     0                        0   \n",
       "23810                 0                     0                        0   \n",
       "23811                 0                     0                        0   \n",
       "23812                 0                     0                        0   \n",
       "23813                 0                     0                        0   \n",
       "\n",
       "       autotaxin_inhibitor  bacterial_30s_ribosomal_subunit_inhibitor  \\\n",
       "0                        0                                          0   \n",
       "1                        0                                          0   \n",
       "2                        0                                          0   \n",
       "3                        0                                          0   \n",
       "4                        0                                          0   \n",
       "...                    ...                                        ...   \n",
       "23809                    0                                          0   \n",
       "23810                    0                                          0   \n",
       "23811                    0                                          0   \n",
       "23812                    0                                          0   \n",
       "23813                    0                                          0   \n",
       "\n",
       "       bacterial_50s_ribosomal_subunit_inhibitor  bacterial_antifolate  \\\n",
       "0                                              0                     0   \n",
       "1                                              0                     0   \n",
       "2                                              0                     0   \n",
       "3                                              0                     0   \n",
       "4                                              0                     0   \n",
       "...                                          ...                   ...   \n",
       "23809                                          0                     0   \n",
       "23810                                          0                     0   \n",
       "23811                                          0                     0   \n",
       "23812                                          0                     0   \n",
       "23813                                          0                     0   \n",
       "\n",
       "       bacterial_cell_wall_synthesis_inhibitor  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "23809                                        0   \n",
       "23810                                        0   \n",
       "23811                                        0   \n",
       "23812                                        0   \n",
       "23813                                        0   \n",
       "\n",
       "       bacterial_dna_gyrase_inhibitor  bacterial_dna_inhibitor  \\\n",
       "0                                   0                        0   \n",
       "1                                   0                        0   \n",
       "2                                   0                        0   \n",
       "3                                   0                        0   \n",
       "4                                   0                        0   \n",
       "...                               ...                      ...   \n",
       "23809                               0                        0   \n",
       "23810                               0                        0   \n",
       "23811                               0                        0   \n",
       "23812                               0                        0   \n",
       "23813                               0                        0   \n",
       "\n",
       "       bacterial_membrane_integrity_inhibitor  bcl_inhibitor  \\\n",
       "0                                           0              0   \n",
       "1                                           0              0   \n",
       "2                                           0              0   \n",
       "3                                           0              0   \n",
       "4                                           0              0   \n",
       "...                                       ...            ...   \n",
       "23809                                       0              0   \n",
       "23810                                       0              0   \n",
       "23811                                       0              0   \n",
       "23812                                       0              0   \n",
       "23813                                       0              0   \n",
       "\n",
       "       bcr-abl_inhibitor  benzodiazepine_receptor_agonist  \\\n",
       "0                      0                                0   \n",
       "1                      0                                0   \n",
       "2                      1                                0   \n",
       "3                      0                                0   \n",
       "4                      0                                0   \n",
       "...                  ...                              ...   \n",
       "23809                  0                                0   \n",
       "23810                  0                                0   \n",
       "23811                  0                                0   \n",
       "23812                  0                                0   \n",
       "23813                  0                                0   \n",
       "\n",
       "       beta_amyloid_inhibitor  bromodomain_inhibitor  btk_inhibitor  \\\n",
       "0                           0                      0              0   \n",
       "1                           0                      0              0   \n",
       "2                           0                      0              0   \n",
       "3                           0                      0              0   \n",
       "4                           0                      0              0   \n",
       "...                       ...                    ...            ...   \n",
       "23809                       0                      0              0   \n",
       "23810                       0                      0              0   \n",
       "23811                       0                      0              0   \n",
       "23812                       0                      0              0   \n",
       "23813                       0                      0              0   \n",
       "\n",
       "       calcineurin_inhibitor  calcium_channel_blocker  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        1   \n",
       "...                      ...                      ...   \n",
       "23809                      0                        0   \n",
       "23810                      0                        0   \n",
       "23811                      0                        0   \n",
       "23812                      0                        0   \n",
       "23813                      0                        0   \n",
       "\n",
       "       cannabinoid_receptor_agonist  cannabinoid_receptor_antagonist  \\\n",
       "0                                 0                                0   \n",
       "1                                 0                                0   \n",
       "2                                 0                                0   \n",
       "3                                 0                                0   \n",
       "4                                 0                                0   \n",
       "...                             ...                              ...   \n",
       "23809                             0                                0   \n",
       "23810                             0                                0   \n",
       "23811                             0                                0   \n",
       "23812                             0                                0   \n",
       "23813                             0                                0   \n",
       "\n",
       "       carbonic_anhydrase_inhibitor  casein_kinase_inhibitor  \\\n",
       "0                                 0                        0   \n",
       "1                                 0                        0   \n",
       "2                                 0                        0   \n",
       "3                                 0                        0   \n",
       "4                                 0                        0   \n",
       "...                             ...                      ...   \n",
       "23809                             0                        0   \n",
       "23810                             0                        0   \n",
       "23811                             0                        0   \n",
       "23812                             0                        0   \n",
       "23813                             0                        0   \n",
       "\n",
       "       caspase_activator  catechol_o_methyltransferase_inhibitor  \\\n",
       "0                      0                                       0   \n",
       "1                      0                                       0   \n",
       "2                      0                                       0   \n",
       "3                      0                                       0   \n",
       "4                      0                                       0   \n",
       "...                  ...                                     ...   \n",
       "23809                  0                                       0   \n",
       "23810                  0                                       0   \n",
       "23811                  0                                       0   \n",
       "23812                  0                                       0   \n",
       "23813                  0                                       0   \n",
       "\n",
       "       cc_chemokine_receptor_antagonist  cck_receptor_antagonist  \\\n",
       "0                                     0                        0   \n",
       "1                                     0                        0   \n",
       "2                                     0                        0   \n",
       "3                                     0                        0   \n",
       "4                                     0                        0   \n",
       "...                                 ...                      ...   \n",
       "23809                                 0                        0   \n",
       "23810                                 0                        0   \n",
       "23811                                 0                        0   \n",
       "23812                                 0                        0   \n",
       "23813                                 0                        0   \n",
       "\n",
       "       cdk_inhibitor  chelating_agent  chk_inhibitor  \\\n",
       "0                  0                0              0   \n",
       "1                  0                0              0   \n",
       "2                  0                0              0   \n",
       "3                  0                0              0   \n",
       "4                  0                0              0   \n",
       "...              ...              ...            ...   \n",
       "23809              0                0              0   \n",
       "23810              0                0              0   \n",
       "23811              0                0              0   \n",
       "23812              1                0              0   \n",
       "23813              0                0              0   \n",
       "\n",
       "       chloride_channel_blocker  cholesterol_inhibitor  \\\n",
       "0                             0                      0   \n",
       "1                             0                      0   \n",
       "2                             0                      0   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "...                         ...                    ...   \n",
       "23809                         0                      0   \n",
       "23810                         0                      0   \n",
       "23811                         0                      0   \n",
       "23812                         0                      0   \n",
       "23813                         0                      0   \n",
       "\n",
       "       cholinergic_receptor_antagonist  coagulation_factor_inhibitor  \\\n",
       "0                                    0                             0   \n",
       "1                                    0                             0   \n",
       "2                                    0                             0   \n",
       "3                                    0                             0   \n",
       "4                                    0                             0   \n",
       "...                                ...                           ...   \n",
       "23809                                0                             0   \n",
       "23810                                0                             0   \n",
       "23811                                0                             0   \n",
       "23812                                0                             0   \n",
       "23813                                0                             0   \n",
       "\n",
       "       corticosteroid_agonist  cyclooxygenase_inhibitor  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "...                       ...                       ...   \n",
       "23809                       0                         0   \n",
       "23810                       0                         0   \n",
       "23811                       0                         0   \n",
       "23812                       0                         0   \n",
       "23813                       0                         0   \n",
       "\n",
       "       cytochrome_p450_inhibitor  dihydrofolate_reductase_inhibitor  \\\n",
       "0                              0                                  0   \n",
       "1                              0                                  0   \n",
       "2                              0                                  0   \n",
       "3                              0                                  0   \n",
       "4                              0                                  0   \n",
       "...                          ...                                ...   \n",
       "23809                          0                                  0   \n",
       "23810                          0                                  0   \n",
       "23811                          0                                  0   \n",
       "23812                          0                                  0   \n",
       "23813                          0                                  0   \n",
       "\n",
       "       dipeptidyl_peptidase_inhibitor  diuretic  dna_alkylating_agent  \\\n",
       "0                                   0         0                     0   \n",
       "1                                   0         0                     0   \n",
       "2                                   0         0                     0   \n",
       "3                                   0         0                     0   \n",
       "4                                   0         0                     0   \n",
       "...                               ...       ...                   ...   \n",
       "23809                               0         0                     0   \n",
       "23810                               0         0                     0   \n",
       "23811                               0         0                     0   \n",
       "23812                               0         0                     0   \n",
       "23813                               0         0                     0   \n",
       "\n",
       "       dna_inhibitor  dopamine_receptor_agonist  dopamine_receptor_antagonist  \\\n",
       "0                  0                          0                             0   \n",
       "1                  0                          0                             0   \n",
       "2                  0                          0                             0   \n",
       "3                  0                          0                             0   \n",
       "4                  0                          0                             0   \n",
       "...              ...                        ...                           ...   \n",
       "23809              0                          0                             0   \n",
       "23810              0                          0                             0   \n",
       "23811              0                          0                             0   \n",
       "23812              0                          0                             0   \n",
       "23813              0                          0                             0   \n",
       "\n",
       "       egfr_inhibitor  elastase_inhibitor  erbb2_inhibitor  \\\n",
       "0                   0                   0                0   \n",
       "1                   0                   0                0   \n",
       "2                   0                   0                0   \n",
       "3                   0                   0                0   \n",
       "4                   0                   0                0   \n",
       "...               ...                 ...              ...   \n",
       "23809               0                   0                0   \n",
       "23810               0                   0                0   \n",
       "23811               0                   0                0   \n",
       "23812               0                   0                0   \n",
       "23813               0                   0                0   \n",
       "\n",
       "       estrogen_receptor_agonist  estrogen_receptor_antagonist  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              0                             0   \n",
       "...                          ...                           ...   \n",
       "23809                          0                             0   \n",
       "23810                          0                             0   \n",
       "23811                          0                             0   \n",
       "23812                          0                             0   \n",
       "23813                          0                             0   \n",
       "\n",
       "       faah_inhibitor  farnesyltransferase_inhibitor  \\\n",
       "0                   0                              0   \n",
       "1                   0                              0   \n",
       "2                   0                              0   \n",
       "3                   0                              0   \n",
       "4                   0                              0   \n",
       "...               ...                            ...   \n",
       "23809               0                              0   \n",
       "23810               0                              0   \n",
       "23811               0                              0   \n",
       "23812               0                              0   \n",
       "23813               0                              0   \n",
       "\n",
       "       fatty_acid_receptor_agonist  fgfr_inhibitor  flt3_inhibitor  \\\n",
       "0                                0               0               0   \n",
       "1                                0               0               0   \n",
       "2                                0               0               0   \n",
       "3                                0               0               0   \n",
       "4                                0               0               0   \n",
       "...                            ...             ...             ...   \n",
       "23809                            0               0               0   \n",
       "23810                            0               0               0   \n",
       "23811                            0               0               0   \n",
       "23812                            0               0               0   \n",
       "23813                            0               0               0   \n",
       "\n",
       "       focal_adhesion_kinase_inhibitor  free_radical_scavenger  \\\n",
       "0                                    0                       0   \n",
       "1                                    0                       0   \n",
       "2                                    0                       0   \n",
       "3                                    0                       0   \n",
       "4                                    0                       0   \n",
       "...                                ...                     ...   \n",
       "23809                                0                       0   \n",
       "23810                                0                       0   \n",
       "23811                                0                       0   \n",
       "23812                                0                       0   \n",
       "23813                                0                       0   \n",
       "\n",
       "       fungal_squalene_epoxidase_inhibitor  gaba_receptor_agonist  \\\n",
       "0                                        0                      0   \n",
       "1                                        0                      0   \n",
       "2                                        0                      0   \n",
       "3                                        0                      0   \n",
       "4                                        0                      0   \n",
       "...                                    ...                    ...   \n",
       "23809                                    0                      0   \n",
       "23810                                    0                      0   \n",
       "23811                                    0                      0   \n",
       "23812                                    0                      0   \n",
       "23813                                    0                      0   \n",
       "\n",
       "       gaba_receptor_antagonist  gamma_secretase_inhibitor  \\\n",
       "0                             0                          0   \n",
       "1                             0                          0   \n",
       "2                             0                          0   \n",
       "3                             0                          0   \n",
       "4                             0                          0   \n",
       "...                         ...                        ...   \n",
       "23809                         0                          0   \n",
       "23810                         0                          0   \n",
       "23811                         0                          0   \n",
       "23812                         0                          0   \n",
       "23813                         0                          0   \n",
       "\n",
       "       glucocorticoid_receptor_agonist  glutamate_inhibitor  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "...                                ...                  ...   \n",
       "23809                                0                    0   \n",
       "23810                                0                    0   \n",
       "23811                                0                    0   \n",
       "23812                                0                    0   \n",
       "23813                                0                    0   \n",
       "\n",
       "       glutamate_receptor_agonist  glutamate_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       gonadotropin_receptor_agonist  gsk_inhibitor  hcv_inhibitor  \\\n",
       "0                                  0              1              0   \n",
       "1                                  0              0              0   \n",
       "2                                  0              0              0   \n",
       "3                                  0              0              0   \n",
       "4                                  0              0              0   \n",
       "...                              ...            ...            ...   \n",
       "23809                              0              0              0   \n",
       "23810                              0              0              0   \n",
       "23811                              0              0              0   \n",
       "23812                              0              0              0   \n",
       "23813                              0              0              0   \n",
       "\n",
       "       hdac_inhibitor  histamine_receptor_agonist  \\\n",
       "0                   0                           0   \n",
       "1                   0                           0   \n",
       "2                   0                           0   \n",
       "3                   0                           0   \n",
       "4                   0                           0   \n",
       "...               ...                         ...   \n",
       "23809               0                           0   \n",
       "23810               0                           0   \n",
       "23811               0                           0   \n",
       "23812               0                           0   \n",
       "23813               0                           0   \n",
       "\n",
       "       histamine_receptor_antagonist  histone_lysine_demethylase_inhibitor  \\\n",
       "0                                  0                                     0   \n",
       "1                                  0                                     0   \n",
       "2                                  0                                     0   \n",
       "3                                  0                                     0   \n",
       "4                                  0                                     0   \n",
       "...                              ...                                   ...   \n",
       "23809                              0                                     0   \n",
       "23810                              0                                     0   \n",
       "23811                              0                                     0   \n",
       "23812                              0                                     0   \n",
       "23813                              0                                     0   \n",
       "\n",
       "       histone_lysine_methyltransferase_inhibitor  hiv_inhibitor  \\\n",
       "0                                               0              0   \n",
       "1                                               0              0   \n",
       "2                                               0              0   \n",
       "3                                               0              0   \n",
       "4                                               0              0   \n",
       "...                                           ...            ...   \n",
       "23809                                           0              0   \n",
       "23810                                           0              0   \n",
       "23811                                           0              0   \n",
       "23812                                           0              0   \n",
       "23813                                           0              0   \n",
       "\n",
       "       hmgcr_inhibitor  hsp_inhibitor  igf-1_inhibitor  ikk_inhibitor  \\\n",
       "0                    0              0                0              0   \n",
       "1                    0              0                0              0   \n",
       "2                    0              0                0              0   \n",
       "3                    0              0                0              0   \n",
       "4                    0              0                0              0   \n",
       "...                ...            ...              ...            ...   \n",
       "23809                0              0                0              0   \n",
       "23810                0              0                0              0   \n",
       "23811                0              0                0              0   \n",
       "23812                0              0                0              0   \n",
       "23813                0              0                0              0   \n",
       "\n",
       "       imidazoline_receptor_agonist  immunosuppressant  insulin_secretagogue  \\\n",
       "0                                 0                  0                     0   \n",
       "1                                 0                  0                     0   \n",
       "2                                 0                  0                     0   \n",
       "3                                 0                  0                     0   \n",
       "4                                 0                  0                     0   \n",
       "...                             ...                ...                   ...   \n",
       "23809                             0                  0                     0   \n",
       "23810                             0                  0                     0   \n",
       "23811                             0                  0                     0   \n",
       "23812                             0                  0                     0   \n",
       "23813                             0                  0                     0   \n",
       "\n",
       "       insulin_sensitizer  integrin_inhibitor  jak_inhibitor  kit_inhibitor  \\\n",
       "0                       0                   0              0              0   \n",
       "1                       0                   0              0              0   \n",
       "2                       0                   0              0              1   \n",
       "3                       0                   0              0              0   \n",
       "4                       0                   0              0              0   \n",
       "...                   ...                 ...            ...            ...   \n",
       "23809                   0                   0              0              0   \n",
       "23810                   0                   0              0              0   \n",
       "23811                   0                   0              0              0   \n",
       "23812                   0                   0              0              0   \n",
       "23813                   0                   0              0              0   \n",
       "\n",
       "       laxative  leukotriene_inhibitor  leukotriene_receptor_antagonist  \\\n",
       "0             0                      0                                0   \n",
       "1             0                      0                                0   \n",
       "2             0                      0                                0   \n",
       "3             0                      0                                0   \n",
       "4             0                      0                                0   \n",
       "...         ...                    ...                              ...   \n",
       "23809         0                      0                                0   \n",
       "23810         0                      0                                0   \n",
       "23811         0                      0                                0   \n",
       "23812         0                      0                                0   \n",
       "23813         0                      0                                0   \n",
       "\n",
       "       lipase_inhibitor  lipoxygenase_inhibitor  lxr_agonist  mdm_inhibitor  \\\n",
       "0                     0                       0            0              0   \n",
       "1                     0                       0            0              0   \n",
       "2                     0                       0            0              0   \n",
       "3                     0                       0            0              0   \n",
       "4                     0                       0            0              0   \n",
       "...                 ...                     ...          ...            ...   \n",
       "23809                 0                       0            0              0   \n",
       "23810                 0                       0            0              0   \n",
       "23811                 0                       0            0              0   \n",
       "23812                 0                       0            0              0   \n",
       "23813                 0                       0            0              0   \n",
       "\n",
       "       mek_inhibitor  membrane_integrity_inhibitor  \\\n",
       "0                  0                             0   \n",
       "1                  0                             0   \n",
       "2                  0                             0   \n",
       "3                  0                             0   \n",
       "4                  0                             0   \n",
       "...              ...                           ...   \n",
       "23809              0                             0   \n",
       "23810              0                             0   \n",
       "23811              0                             0   \n",
       "23812              0                             0   \n",
       "23813              0                             0   \n",
       "\n",
       "       mineralocorticoid_receptor_antagonist  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "...                                      ...   \n",
       "23809                                      0   \n",
       "23810                                      0   \n",
       "23811                                      0   \n",
       "23812                                      0   \n",
       "23813                                      0   \n",
       "\n",
       "       monoacylglycerol_lipase_inhibitor  monoamine_oxidase_inhibitor  \\\n",
       "0                                      0                            0   \n",
       "1                                      0                            0   \n",
       "2                                      0                            0   \n",
       "3                                      0                            0   \n",
       "4                                      0                            0   \n",
       "...                                  ...                          ...   \n",
       "23809                                  0                            0   \n",
       "23810                                  0                            0   \n",
       "23811                                  0                            0   \n",
       "23812                                  0                            0   \n",
       "23813                                  0                            0   \n",
       "\n",
       "       monopolar_spindle_1_kinase_inhibitor  mtor_inhibitor  mucolytic_agent  \\\n",
       "0                                         0               0                0   \n",
       "1                                         0               0                0   \n",
       "2                                         0               0                0   \n",
       "3                                         0               0                0   \n",
       "4                                         0               0                0   \n",
       "...                                     ...             ...              ...   \n",
       "23809                                     0               0                0   \n",
       "23810                                     0               0                0   \n",
       "23811                                     0               0                0   \n",
       "23812                                     0               0                0   \n",
       "23813                                     0               0                0   \n",
       "\n",
       "       neuropeptide_receptor_antagonist  nfkb_inhibitor  \\\n",
       "0                                     0               0   \n",
       "1                                     0               0   \n",
       "2                                     0               0   \n",
       "3                                     0               0   \n",
       "4                                     0               0   \n",
       "...                                 ...             ...   \n",
       "23809                                 0               0   \n",
       "23810                                 0               0   \n",
       "23811                                 0               0   \n",
       "23812                                 0               0   \n",
       "23813                                 0               0   \n",
       "\n",
       "       nicotinic_receptor_agonist  nitric_oxide_donor  \\\n",
       "0                               0                   0   \n",
       "1                               0                   0   \n",
       "2                               0                   0   \n",
       "3                               0                   0   \n",
       "4                               0                   0   \n",
       "...                           ...                 ...   \n",
       "23809                           0                   0   \n",
       "23810                           0                   0   \n",
       "23811                           0                   0   \n",
       "23812                           0                   0   \n",
       "23813                           0                   0   \n",
       "\n",
       "       nitric_oxide_production_inhibitor  nitric_oxide_synthase_inhibitor  \\\n",
       "0                                      0                                0   \n",
       "1                                      0                                0   \n",
       "2                                      0                                0   \n",
       "3                                      0                                0   \n",
       "4                                      0                                0   \n",
       "...                                  ...                              ...   \n",
       "23809                                  0                                0   \n",
       "23810                                  0                                0   \n",
       "23811                                  0                                0   \n",
       "23812                                  0                                0   \n",
       "23813                                  0                                0   \n",
       "\n",
       "       norepinephrine_reuptake_inhibitor  nrf2_activator  \\\n",
       "0                                      0               0   \n",
       "1                                      0               0   \n",
       "2                                      0               0   \n",
       "3                                      0               0   \n",
       "4                                      0               0   \n",
       "...                                  ...             ...   \n",
       "23809                                  0               0   \n",
       "23810                                  0               0   \n",
       "23811                                  0               0   \n",
       "23812                                  0               0   \n",
       "23813                                  0               0   \n",
       "\n",
       "       opioid_receptor_agonist  opioid_receptor_antagonist  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "...                        ...                         ...   \n",
       "23809                        0                           0   \n",
       "23810                        0                           0   \n",
       "23811                        0                           0   \n",
       "23812                        0                           0   \n",
       "23813                        0                           0   \n",
       "\n",
       "       orexin_receptor_antagonist  p38_mapk_inhibitor  \\\n",
       "0                               0                   0   \n",
       "1                               0                   0   \n",
       "2                               0                   0   \n",
       "3                               0                   0   \n",
       "4                               0                   0   \n",
       "...                           ...                 ...   \n",
       "23809                           0                   0   \n",
       "23810                           0                   0   \n",
       "23811                           0                   0   \n",
       "23812                           0                   0   \n",
       "23813                           0                   0   \n",
       "\n",
       "       p-glycoprotein_inhibitor  parp_inhibitor  pdgfr_inhibitor  \\\n",
       "0                             0               0                0   \n",
       "1                             0               0                0   \n",
       "2                             0               0                1   \n",
       "3                             0               0                0   \n",
       "4                             0               0                0   \n",
       "...                         ...             ...              ...   \n",
       "23809                         0               0                0   \n",
       "23810                         0               0                0   \n",
       "23811                         0               0                0   \n",
       "23812                         0               0                0   \n",
       "23813                         0               0                0   \n",
       "\n",
       "       pdk_inhibitor  phosphodiesterase_inhibitor  phospholipase_inhibitor  \\\n",
       "0                  0                            0                        0   \n",
       "1                  0                            0                        0   \n",
       "2                  0                            0                        0   \n",
       "3                  0                            0                        0   \n",
       "4                  0                            0                        0   \n",
       "...              ...                          ...                      ...   \n",
       "23809              0                            0                        0   \n",
       "23810              0                            0                        0   \n",
       "23811              0                            0                        0   \n",
       "23812              0                            0                        0   \n",
       "23813              0                            0                        0   \n",
       "\n",
       "       pi3k_inhibitor  pkc_inhibitor  potassium_channel_activator  \\\n",
       "0                   0              0                            0   \n",
       "1                   0              0                            0   \n",
       "2                   0              0                            0   \n",
       "3                   0              0                            0   \n",
       "4                   0              0                            0   \n",
       "...               ...            ...                          ...   \n",
       "23809               0              0                            0   \n",
       "23810               0              0                            0   \n",
       "23811               0              0                            0   \n",
       "23812               0              0                            0   \n",
       "23813               0              0                            0   \n",
       "\n",
       "       potassium_channel_antagonist  ppar_receptor_agonist  \\\n",
       "0                                 0                      0   \n",
       "1                                 0                      0   \n",
       "2                                 0                      0   \n",
       "3                                 0                      0   \n",
       "4                                 0                      0   \n",
       "...                             ...                    ...   \n",
       "23809                             0                      0   \n",
       "23810                             0                      1   \n",
       "23811                             0                      0   \n",
       "23812                             0                      0   \n",
       "23813                             0                      0   \n",
       "\n",
       "       ppar_receptor_antagonist  progesterone_receptor_agonist  \\\n",
       "0                             0                              0   \n",
       "1                             0                              0   \n",
       "2                             0                              0   \n",
       "3                             0                              0   \n",
       "4                             0                              0   \n",
       "...                         ...                            ...   \n",
       "23809                         0                              0   \n",
       "23810                         0                              0   \n",
       "23811                         0                              0   \n",
       "23812                         0                              0   \n",
       "23813                         0                              0   \n",
       "\n",
       "       progesterone_receptor_antagonist  prostaglandin_inhibitor  \\\n",
       "0                                     0                        0   \n",
       "1                                     0                        0   \n",
       "2                                     0                        0   \n",
       "3                                     0                        0   \n",
       "4                                     0                        0   \n",
       "...                                 ...                      ...   \n",
       "23809                                 0                        0   \n",
       "23810                                 0                        0   \n",
       "23811                                 0                        0   \n",
       "23812                                 0                        0   \n",
       "23813                                 0                        0   \n",
       "\n",
       "       prostanoid_receptor_antagonist  proteasome_inhibitor  \\\n",
       "0                                   0                     0   \n",
       "1                                   0                     0   \n",
       "2                                   0                     0   \n",
       "3                                   0                     0   \n",
       "4                                   0                     0   \n",
       "...                               ...                   ...   \n",
       "23809                               0                     0   \n",
       "23810                               0                     0   \n",
       "23811                               0                     0   \n",
       "23812                               0                     0   \n",
       "23813                               0                     0   \n",
       "\n",
       "       protein_kinase_inhibitor  protein_phosphatase_inhibitor  \\\n",
       "0                             0                              0   \n",
       "1                             0                              0   \n",
       "2                             0                              0   \n",
       "3                             0                              0   \n",
       "4                             0                              0   \n",
       "...                         ...                            ...   \n",
       "23809                         0                              0   \n",
       "23810                         0                              0   \n",
       "23811                         0                              0   \n",
       "23812                         0                              0   \n",
       "23813                         0                              0   \n",
       "\n",
       "       protein_synthesis_inhibitor  protein_tyrosine_kinase_inhibitor  \\\n",
       "0                                0                                  0   \n",
       "1                                0                                  0   \n",
       "2                                0                                  0   \n",
       "3                                0                                  0   \n",
       "4                                0                                  0   \n",
       "...                            ...                                ...   \n",
       "23809                            0                                  0   \n",
       "23810                            0                                  0   \n",
       "23811                            0                                  0   \n",
       "23812                            0                                  0   \n",
       "23813                            0                                  0   \n",
       "\n",
       "       radiopaque_medium  raf_inhibitor  ras_gtpase_inhibitor  \\\n",
       "0                      0              0                     0   \n",
       "1                      0              0                     0   \n",
       "2                      0              0                     0   \n",
       "3                      0              0                     0   \n",
       "4                      0              0                     0   \n",
       "...                  ...            ...                   ...   \n",
       "23809                  0              0                     0   \n",
       "23810                  0              0                     0   \n",
       "23811                  0              0                     0   \n",
       "23812                  0              0                     0   \n",
       "23813                  0              0                     0   \n",
       "\n",
       "       retinoid_receptor_agonist  retinoid_receptor_antagonist  \\\n",
       "0                              0                             0   \n",
       "1                              0                             0   \n",
       "2                              0                             0   \n",
       "3                              0                             0   \n",
       "4                              0                             0   \n",
       "...                          ...                           ...   \n",
       "23809                          0                             0   \n",
       "23810                          0                             0   \n",
       "23811                          0                             0   \n",
       "23812                          0                             0   \n",
       "23813                          0                             0   \n",
       "\n",
       "       rho_associated_kinase_inhibitor  ribonucleoside_reductase_inhibitor  \\\n",
       "0                                    0                                   0   \n",
       "1                                    0                                   0   \n",
       "2                                    0                                   0   \n",
       "3                                    0                                   0   \n",
       "4                                    0                                   0   \n",
       "...                                ...                                 ...   \n",
       "23809                                0                                   0   \n",
       "23810                                0                                   0   \n",
       "23811                                0                                   0   \n",
       "23812                                0                                   0   \n",
       "23813                                0                                   0   \n",
       "\n",
       "       rna_polymerase_inhibitor  serotonin_receptor_agonist  \\\n",
       "0                             0                           0   \n",
       "1                             0                           0   \n",
       "2                             0                           0   \n",
       "3                             0                           0   \n",
       "4                             0                           0   \n",
       "...                         ...                         ...   \n",
       "23809                         0                           0   \n",
       "23810                         0                           0   \n",
       "23811                         0                           0   \n",
       "23812                         0                           0   \n",
       "23813                         0                           0   \n",
       "\n",
       "       serotonin_receptor_antagonist  serotonin_reuptake_inhibitor  \\\n",
       "0                                  0                             0   \n",
       "1                                  0                             0   \n",
       "2                                  0                             0   \n",
       "3                                  0                             0   \n",
       "4                                  0                             0   \n",
       "...                              ...                           ...   \n",
       "23809                              1                             0   \n",
       "23810                              0                             0   \n",
       "23811                              0                             0   \n",
       "23812                              0                             0   \n",
       "23813                              0                             0   \n",
       "\n",
       "       sigma_receptor_agonist  sigma_receptor_antagonist  \\\n",
       "0                           0                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "...                       ...                        ...   \n",
       "23809                       0                          0   \n",
       "23810                       0                          0   \n",
       "23811                       0                          0   \n",
       "23812                       0                          0   \n",
       "23813                       0                          0   \n",
       "\n",
       "       smoothened_receptor_antagonist  sodium_channel_inhibitor  \\\n",
       "0                                   0                         0   \n",
       "1                                   0                         0   \n",
       "2                                   0                         0   \n",
       "3                                   0                         0   \n",
       "4                                   0                         0   \n",
       "...                               ...                       ...   \n",
       "23809                               0                         0   \n",
       "23810                               0                         0   \n",
       "23811                               0                         0   \n",
       "23812                               0                         0   \n",
       "23813                               0                         0   \n",
       "\n",
       "       sphingosine_receptor_agonist  src_inhibitor  steroid  syk_inhibitor  \\\n",
       "0                                 0              0        0              0   \n",
       "1                                 0              0        0              0   \n",
       "2                                 0              0        0              0   \n",
       "3                                 0              0        0              0   \n",
       "4                                 0              0        0              0   \n",
       "...                             ...            ...      ...            ...   \n",
       "23809                             0              0        0              0   \n",
       "23810                             0              0        0              0   \n",
       "23811                             0              0        0              0   \n",
       "23812                             0              0        0              0   \n",
       "23813                             0              0        0              0   \n",
       "\n",
       "       tachykinin_antagonist  tgf-beta_receptor_inhibitor  thrombin_inhibitor  \\\n",
       "0                          0                            0                   0   \n",
       "1                          0                            0                   0   \n",
       "2                          0                            0                   0   \n",
       "3                          0                            0                   0   \n",
       "4                          0                            0                   0   \n",
       "...                      ...                          ...                 ...   \n",
       "23809                      0                            0                   0   \n",
       "23810                      0                            0                   0   \n",
       "23811                      0                            0                   0   \n",
       "23812                      0                            0                   0   \n",
       "23813                      0                            0                   0   \n",
       "\n",
       "       thymidylate_synthase_inhibitor  tlr_agonist  tlr_antagonist  \\\n",
       "0                                   0            0               0   \n",
       "1                                   0            0               0   \n",
       "2                                   0            0               0   \n",
       "3                                   0            0               0   \n",
       "4                                   0            0               0   \n",
       "...                               ...          ...             ...   \n",
       "23809                               0            0               0   \n",
       "23810                               0            0               0   \n",
       "23811                               0            0               0   \n",
       "23812                               0            0               0   \n",
       "23813                               0            0               0   \n",
       "\n",
       "       tnf_inhibitor  topoisomerase_inhibitor  \\\n",
       "0                  0                        0   \n",
       "1                  0                        0   \n",
       "2                  0                        0   \n",
       "3                  0                        0   \n",
       "4                  0                        0   \n",
       "...              ...                      ...   \n",
       "23809              0                        0   \n",
       "23810              0                        0   \n",
       "23811              0                        0   \n",
       "23812              0                        0   \n",
       "23813              0                        0   \n",
       "\n",
       "       transient_receptor_potential_channel_antagonist  \\\n",
       "0                                                    0   \n",
       "1                                                    0   \n",
       "2                                                    0   \n",
       "3                                                    0   \n",
       "4                                                    0   \n",
       "...                                                ...   \n",
       "23809                                                0   \n",
       "23810                                                0   \n",
       "23811                                                0   \n",
       "23812                                                0   \n",
       "23813                                                0   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "23809                                      0             0                0   \n",
       "23810                                      0             0                0   \n",
       "23811                                      0             0                0   \n",
       "23812                                      0             0                0   \n",
       "23813                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "23809                  0                          0   \n",
       "23810                  0                          0   \n",
       "23811                  0                          0   \n",
       "23812                  0                          0   \n",
       "23813                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "23809                                      0                0          0   \n",
       "23810                                      0                0          0   \n",
       "23811                                      0                0          0   \n",
       "23812                                      0                0          0   \n",
       "23813                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "23809                           0              0  \n",
       "23810                           0              0  \n",
       "23811                           0              0  \n",
       "23812                           0              0  \n",
       "23813                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:57.512762Z",
     "start_time": "2020-11-06T01:11:57.273368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc_transporter_expression_enhancer</th>\n",
       "      <th>abl_inhibitor</th>\n",
       "      <th>ace_inhibitor</th>\n",
       "      <th>acetylcholine_release_enhancer</th>\n",
       "      <th>adenosine_deaminase_inhibitor</th>\n",
       "      <th>adenosine_kinase_inhibitor</th>\n",
       "      <th>adenylyl_cyclase_inhibitor</th>\n",
       "      <th>age_inhibitor</th>\n",
       "      <th>alcohol_dehydrogenase_inhibitor</th>\n",
       "      <th>aldehyde_dehydrogenase_activator</th>\n",
       "      <th>aldose_reductase_inhibitor</th>\n",
       "      <th>alpha_mannosidase_inhibitor</th>\n",
       "      <th>ampk_inhibitor</th>\n",
       "      <th>androgen_biosynthesis_inhibitor</th>\n",
       "      <th>angiotensin_receptor_agonist</th>\n",
       "      <th>antacid</th>\n",
       "      <th>anthelmintic</th>\n",
       "      <th>antihypertensive</th>\n",
       "      <th>antimetabolite</th>\n",
       "      <th>antipruritic</th>\n",
       "      <th>antirheumatic_drug</th>\n",
       "      <th>antiseptic</th>\n",
       "      <th>antispasmodic</th>\n",
       "      <th>antithyroid_agent</th>\n",
       "      <th>antitussive</th>\n",
       "      <th>anxiolytic</th>\n",
       "      <th>ap_inhibitor</th>\n",
       "      <th>apolipoprotein_expression_enhancer</th>\n",
       "      <th>apoptosis_inhibitor</th>\n",
       "      <th>arf_inhibitor</th>\n",
       "      <th>aryl_hydrocarbon_receptor_agonist</th>\n",
       "      <th>aryl_hydrocarbon_receptor_antagonist</th>\n",
       "      <th>aspartic_protease_inhibitor</th>\n",
       "      <th>atherogenesis_inhibitor</th>\n",
       "      <th>atherosclerosis_formation_inhibitor</th>\n",
       "      <th>atp-sensitive_potassium_channel_agonist</th>\n",
       "      <th>atp-sensitive_potassium_channel_inhibitor</th>\n",
       "      <th>atp_channel_activator</th>\n",
       "      <th>atp_channel_blocker</th>\n",
       "      <th>atp_citrase_lyase_inhibitor</th>\n",
       "      <th>autophagy_inducer</th>\n",
       "      <th>axl_kinase_inhibitor</th>\n",
       "      <th>bacterial_atpase_inhibitor</th>\n",
       "      <th>bacterial_permeability_inducer</th>\n",
       "      <th>bacterial_protein_synthesis_inhibitor</th>\n",
       "      <th>benzodiazepine_receptor_antagonist</th>\n",
       "      <th>beta_catenin_inhibitor</th>\n",
       "      <th>beta_lactamase_inhibitor</th>\n",
       "      <th>beta_secretase_inhibitor</th>\n",
       "      <th>big1_inhibitor</th>\n",
       "      <th>bile_acid</th>\n",
       "      <th>biliverdin_reductase_a_activator</th>\n",
       "      <th>bone_resorption_inhibitor</th>\n",
       "      <th>botulin_neurotoxin_inhibitor</th>\n",
       "      <th>bradykinin_receptor_antagonist</th>\n",
       "      <th>breast_cancer_resistance_protein_inhibitor</th>\n",
       "      <th>bronchodilator</th>\n",
       "      <th>calcitonin_antagonist</th>\n",
       "      <th>calcium_channel_activator</th>\n",
       "      <th>calmodulin_inhibitor</th>\n",
       "      <th>calpain_inhibitor</th>\n",
       "      <th>camp_stimulant</th>\n",
       "      <th>capillary_stabilizing_agent</th>\n",
       "      <th>car_agonist</th>\n",
       "      <th>car_antagonist</th>\n",
       "      <th>carboxylesterase_inhibitor</th>\n",
       "      <th>carcinogen</th>\n",
       "      <th>cardiac_glycoside</th>\n",
       "      <th>carnitine_palmitoyltransferase_inhibitor</th>\n",
       "      <th>caspase_inhibitor</th>\n",
       "      <th>cathepsin_inhibitor</th>\n",
       "      <th>cc_chemokine_receptor_agonist</th>\n",
       "      <th>cdc_inhibitor</th>\n",
       "      <th>cdk_expression_enhancer</th>\n",
       "      <th>cell_cycle_inhibitor</th>\n",
       "      <th>cell_proliferation_inhibitor</th>\n",
       "      <th>ceramidase_inhibitor</th>\n",
       "      <th>cftr_channel_agonist</th>\n",
       "      <th>cftr_channel_antagonist</th>\n",
       "      <th>chitin_inhibitor</th>\n",
       "      <th>chloride_channel_activator</th>\n",
       "      <th>choleretic_agent</th>\n",
       "      <th>cholinergic_receptor_agonist</th>\n",
       "      <th>cholinesterase_inhibitor</th>\n",
       "      <th>clk_inhibitor</th>\n",
       "      <th>coenzyme_a_precursor</th>\n",
       "      <th>collagenase_inhibitor</th>\n",
       "      <th>collapsin_response_mediator_protein_stimulant</th>\n",
       "      <th>coloring_agent</th>\n",
       "      <th>complement_antagonist</th>\n",
       "      <th>complement_inhibitor</th>\n",
       "      <th>contraceptive_agent</th>\n",
       "      <th>contrast_agent</th>\n",
       "      <th>corticosteroid_antagonist</th>\n",
       "      <th>cyclin_d_inhibitor</th>\n",
       "      <th>cysteine_peptidase_inhibitor</th>\n",
       "      <th>cytidine_deaminase_inhibitor</th>\n",
       "      <th>cytokine_production_inhibitor</th>\n",
       "      <th>dehydrogenase_inhibitor</th>\n",
       "      <th>deubiquitinase_inhibitor</th>\n",
       "      <th>diacylglycerol_kinase_inhibitor</th>\n",
       "      <th>diacylglycerol_o_acyltransferase_inhibitor</th>\n",
       "      <th>differentiation_inducer</th>\n",
       "      <th>dihydroorotate_dehydrogenase_inhibitor</th>\n",
       "      <th>dihydropteroate_synthase_inhibitor</th>\n",
       "      <th>dihydropyrimidine_dehydrogenase_inhibitor</th>\n",
       "      <th>dna_dependent_protein_kinase_inhibitor</th>\n",
       "      <th>dna_methyltransferase_inhibitor</th>\n",
       "      <th>dna_polymerase_inhibitor</th>\n",
       "      <th>dna_repair_enzyme_inhibitor</th>\n",
       "      <th>dna_synthesis_inhibitor</th>\n",
       "      <th>dopamine_release_enhancer</th>\n",
       "      <th>dot1l_inhibitor</th>\n",
       "      <th>dynamin_inhibitor</th>\n",
       "      <th>dyrk_inhibitor</th>\n",
       "      <th>dystrophin_stimulant</th>\n",
       "      <th>endothelin_receptor_antagonist</th>\n",
       "      <th>enkephalinase_inhibitor</th>\n",
       "      <th>ephrin_inhibitor</th>\n",
       "      <th>epoxide_hydolase_inhibitor</th>\n",
       "      <th>etv1_inhibitor</th>\n",
       "      <th>eukaryotic_translation_initiation_factor_inhibitor</th>\n",
       "      <th>exportin_antagonist</th>\n",
       "      <th>fabi_inhibitor</th>\n",
       "      <th>farnesyl_pyrophosphate_synthase_inhibitor</th>\n",
       "      <th>fatty_acid_receptor_antagonist</th>\n",
       "      <th>fatty_acid_synthase_inhibitor</th>\n",
       "      <th>folate_receptor_ligand</th>\n",
       "      <th>free_fatty_acid_receptor_agonist</th>\n",
       "      <th>fungal_1,3-beta-d-glucan_synthase_inhibitor</th>\n",
       "      <th>fungal_ergosterol_inhibitor</th>\n",
       "      <th>fungal_lanosterol_demethylase_inhibitor</th>\n",
       "      <th>fxr_agonist</th>\n",
       "      <th>fxr_antagonist</th>\n",
       "      <th>g_protein-coupled_receptor_agonist</th>\n",
       "      <th>g_protein-coupled_receptor_antagonist</th>\n",
       "      <th>g_protein_signaling_inhibitor</th>\n",
       "      <th>gaba_gated_chloride_channel_blocker</th>\n",
       "      <th>gaba_receptor_modulator</th>\n",
       "      <th>gaba_uptake_inhibitor</th>\n",
       "      <th>gap_junction_modulator</th>\n",
       "      <th>gastrin_inhibitor</th>\n",
       "      <th>gat_inhibitor</th>\n",
       "      <th>glcnac_phosphotransferase_inhibitor</th>\n",
       "      <th>gli_antagonist</th>\n",
       "      <th>glp_receptor_agonist</th>\n",
       "      <th>glucagon_receptor_antagonist</th>\n",
       "      <th>glucocorticoid_receptor_antagonist</th>\n",
       "      <th>glucokinase_activator</th>\n",
       "      <th>glucokinase_inhibitor</th>\n",
       "      <th>gluconeogenesis_inhibitor</th>\n",
       "      <th>glucose_dependent_insulinotropic_receptor_agonist</th>\n",
       "      <th>glucosidase_inhibitor</th>\n",
       "      <th>glutamate_receptor_modulator</th>\n",
       "      <th>glutathione_peroxidase_agonist</th>\n",
       "      <th>glutathione_reductase_(nadph)_activators</th>\n",
       "      <th>glutathione_transferase_inhibitor</th>\n",
       "      <th>glycine_receptor_antagonist</th>\n",
       "      <th>glycine_transporter_inhibitor</th>\n",
       "      <th>glycogen_phosphorylase_inhibitor</th>\n",
       "      <th>glycolysis_inhibitor</th>\n",
       "      <th>glycosylation_inhibitor</th>\n",
       "      <th>gonadotropin_receptor_antagonist</th>\n",
       "      <th>growth_factor_receptor_inhibitor</th>\n",
       "      <th>gtpase_inhibitor</th>\n",
       "      <th>guanylate_cyclase_activator</th>\n",
       "      <th>guanylate_cyclase_stimulant</th>\n",
       "      <th>guanylyl_cyclase_activator</th>\n",
       "      <th>h+_k+-atpase_inhibitor</th>\n",
       "      <th>haemostatic_agent</th>\n",
       "      <th>hcn_channel_antagonist</th>\n",
       "      <th>hedgehog_pathway_inhibitor</th>\n",
       "      <th>heme_oxygenase_activators</th>\n",
       "      <th>hemoglobin_antagonist</th>\n",
       "      <th>hexokinase_inhibitor</th>\n",
       "      <th>hgf_receptor_inhibitor</th>\n",
       "      <th>hif_inhibitor</th>\n",
       "      <th>histamine_release_inhibitor</th>\n",
       "      <th>histone_acetyltransferase_inhibitor</th>\n",
       "      <th>histone_demethylase_inhibitor</th>\n",
       "      <th>hiv_integrase_inhibitor</th>\n",
       "      <th>hiv_protease_inhibitor</th>\n",
       "      <th>hsp_inducer</th>\n",
       "      <th>hydantoin_antiepileptic</th>\n",
       "      <th>hydroxycarboxylic_acid_receptor_agonist</th>\n",
       "      <th>icam1_antagonist</th>\n",
       "      <th>icam1_inhibitor</th>\n",
       "      <th>id1_expression_inhibitor</th>\n",
       "      <th>imidazoline_ligand</th>\n",
       "      <th>immunostimulant</th>\n",
       "      <th>indoleamine_2,3-dioxygenase_inhibitor</th>\n",
       "      <th>inosine_monophosphate_dehydrogenase_inhibitor</th>\n",
       "      <th>inositol_monophosphatase_inhibitor</th>\n",
       "      <th>interferon_inducer</th>\n",
       "      <th>interleukin_inhibitor</th>\n",
       "      <th>interleukin_receptor_agonist</th>\n",
       "      <th>ion_channel_antagonist</th>\n",
       "      <th>ip1_prostacyclin_receptor_agonist</th>\n",
       "      <th>iron_absorption_inhibitor</th>\n",
       "      <th>isocitrate_dehydrogenase_inhibitor</th>\n",
       "      <th>jnk_inhibitor</th>\n",
       "      <th>kainate_receptor_antagonist</th>\n",
       "      <th>katp_activator</th>\n",
       "      <th>keap1_ligand</th>\n",
       "      <th>kinesin_inhibitor</th>\n",
       "      <th>l3mbtl_antagonist</th>\n",
       "      <th>lactamase_inhibitor</th>\n",
       "      <th>lactate_dehydrogenase_inhibitor</th>\n",
       "      <th>lanosterol_demethylase_inhibitor</th>\n",
       "      <th>leucyl-trna_synthetase_inhibitor</th>\n",
       "      <th>leukocyte_elastase_inhibitor</th>\n",
       "      <th>leukotriene_synthesis_inhibitor</th>\n",
       "      <th>lim_inhibitor</th>\n",
       "      <th>lipase_clearing_factor_inhibitor</th>\n",
       "      <th>lipid_peroxidase_inhibitor</th>\n",
       "      <th>lipoprotein_lipase_activator</th>\n",
       "      <th>lrkk2_inhibitor</th>\n",
       "      <th>lymphocyte_inhibitor</th>\n",
       "      <th>lysophosphatidic_acid_receptor_antagonist</th>\n",
       "      <th>macrophage_inhibitor</th>\n",
       "      <th>macrophage_migration_inhibiting_factor_inhibitor</th>\n",
       "      <th>map_k</th>\n",
       "      <th>map_kinase_inhibitor</th>\n",
       "      <th>matrix_metalloprotease_inhibitor</th>\n",
       "      <th>mcl1_inhibitor</th>\n",
       "      <th>melanin_inhibitor</th>\n",
       "      <th>melanocortin_receptor_agonist</th>\n",
       "      <th>melatonin_receptor_agonist</th>\n",
       "      <th>membrane_permeability_enhancer</th>\n",
       "      <th>membrane_permeability_inhibitor</th>\n",
       "      <th>mer_tyrosine_kinase_inhibitor</th>\n",
       "      <th>met_inhibitor</th>\n",
       "      <th>metalloproteinase_inhibitor</th>\n",
       "      <th>mineralocorticoid_receptor_agonist</th>\n",
       "      <th>mitochondrial_inhibitor</th>\n",
       "      <th>mitochondrial_na+_ca2+_exchanger_antagonist</th>\n",
       "      <th>monocarboxylate_transporter_inhibitor</th>\n",
       "      <th>motilin_receptor_agonist</th>\n",
       "      <th>mrp_inhibitor</th>\n",
       "      <th>mth1_inhibitor</th>\n",
       "      <th>mucolytic</th>\n",
       "      <th>mucus_protecting_agent</th>\n",
       "      <th>muscle_relaxant</th>\n",
       "      <th>na_k-atpase_inhibitor</th>\n",
       "      <th>nadph_inhibitor</th>\n",
       "      <th>nampt_inhibitor</th>\n",
       "      <th>neprilysin_inhibitor</th>\n",
       "      <th>neural_stem_cell_inducer</th>\n",
       "      <th>neuraminidase_inhibitor</th>\n",
       "      <th>neurokinin_receptor_antagonist</th>\n",
       "      <th>neurotensin_receptor_agonist</th>\n",
       "      <th>neurotensin_receptor_antagonist</th>\n",
       "      <th>neurotransmitter</th>\n",
       "      <th>neurotrophic_agent</th>\n",
       "      <th>nfkb_activator</th>\n",
       "      <th>niemann-pick_c1-like_1_protein_antagonist</th>\n",
       "      <th>nitric_oxide_scavenger</th>\n",
       "      <th>nitric_oxide_stimulant</th>\n",
       "      <th>nociceptin_orphanin_fq_(nop)_receptor_antagonist</th>\n",
       "      <th>non-nucleoside_reverse_transcriptase_inhibitor</th>\n",
       "      <th>nootropic_agent</th>\n",
       "      <th>nop_receptor_agonist</th>\n",
       "      <th>noradrenaline_uptake_inhibitor</th>\n",
       "      <th>norepinephrine_inhibitor</th>\n",
       "      <th>notch_signaling_inhibitor</th>\n",
       "      <th>ntpdase_inhibitor</th>\n",
       "      <th>nucleoside_reverse_transcriptase_inhibitor</th>\n",
       "      <th>oct_activator</th>\n",
       "      <th>omega_3_fatty_acid_stimulant</th>\n",
       "      <th>osteoclast_inhibitor</th>\n",
       "      <th>oxidizing_agent</th>\n",
       "      <th>oxidosqualene_cyclase_inhibitor</th>\n",
       "      <th>oxytocin_receptor_agonist</th>\n",
       "      <th>oxytocin_receptor_antagonist</th>\n",
       "      <th>p21_activated_kinase_inhibitor</th>\n",
       "      <th>p53_activator</th>\n",
       "      <th>p53_inhibitor</th>\n",
       "      <th>paba_antagonist</th>\n",
       "      <th>pdk1_inhibitor</th>\n",
       "      <th>penicillin_binding_protein_inhibitor</th>\n",
       "      <th>peptidase_inhibitor</th>\n",
       "      <th>perk_inhibitor</th>\n",
       "      <th>phosphatase_inhibitor</th>\n",
       "      <th>phosphofructokinase_inhibitor</th>\n",
       "      <th>phospholipase_activator</th>\n",
       "      <th>pim_inhibitor</th>\n",
       "      <th>pka_activator</th>\n",
       "      <th>pka_inhibitor</th>\n",
       "      <th>plasminogen_activator_inhibitor</th>\n",
       "      <th>platelet_activating_factor_receptor_antagonist</th>\n",
       "      <th>platelet_aggregation_inhibitor</th>\n",
       "      <th>plk_inhibitor</th>\n",
       "      <th>porcupine_inhibitor</th>\n",
       "      <th>potassium_channel_agonist</th>\n",
       "      <th>potassium_channel_blocker</th>\n",
       "      <th>prmt_inhibitor</th>\n",
       "      <th>progestogen_hormone</th>\n",
       "      <th>prolactin_inhibitor</th>\n",
       "      <th>prostacyclin_analog</th>\n",
       "      <th>prostanoid_receptor_agonist</th>\n",
       "      <th>prostanoid_receptor_inhibitor</th>\n",
       "      <th>protease_inhibitor</th>\n",
       "      <th>protein_kinase_activator</th>\n",
       "      <th>protein_synthesis_stimulant</th>\n",
       "      <th>psychoactive_drug</th>\n",
       "      <th>purine_antagonist</th>\n",
       "      <th>purinergic_receptor_antagonist</th>\n",
       "      <th>pxr_ligand</th>\n",
       "      <th>pyruvate_dehydrogenase_inhibitor</th>\n",
       "      <th>pyruvate_kinase_isozyme_activator</th>\n",
       "      <th>quorum_sensing_signaling_modulator</th>\n",
       "      <th>rad51_inhibitor</th>\n",
       "      <th>rage_receptor_antagonist</th>\n",
       "      <th>receptor_tyrosine_protein_kinase_inhibitor</th>\n",
       "      <th>reducing_agent</th>\n",
       "      <th>ret_inhibitor</th>\n",
       "      <th>ret_tyrosine_kinase_inhibitor</th>\n",
       "      <th>reverse_transcriptase_inhibitor</th>\n",
       "      <th>ribosomal_protein_inhibitor</th>\n",
       "      <th>ripk_inhibitor</th>\n",
       "      <th>rna_synthesis_inhibitor</th>\n",
       "      <th>ror_inverse_agonist</th>\n",
       "      <th>rsv_fusion_inhibitor</th>\n",
       "      <th>s100a9_inhibitor</th>\n",
       "      <th>sars_coronavirus_3c-like_protease_inhibitor</th>\n",
       "      <th>sedative</th>\n",
       "      <th>selective_estrogen_receptor_modulator_(serm)</th>\n",
       "      <th>selective_serotonin_reuptake_inhibitor_(ssri)</th>\n",
       "      <th>serine_protease_inhibitor</th>\n",
       "      <th>serine_threonine_kinase_inhibitor</th>\n",
       "      <th>serine_threonine_protein_phosphatase_activator</th>\n",
       "      <th>serotonin_release_inhibitor</th>\n",
       "      <th>sirt_activator</th>\n",
       "      <th>sirt_inhibitor</th>\n",
       "      <th>smoothened_receptor_agonist</th>\n",
       "      <th>sodium_calcium_exchange_inhibitor</th>\n",
       "      <th>sodium_channel_activator</th>\n",
       "      <th>sodium_channel_blocker</th>\n",
       "      <th>somatostatin_receptor_agonist</th>\n",
       "      <th>sphingosine_1_phosphate_receptor_agonist</th>\n",
       "      <th>sphingosine_kinase_inhibitor</th>\n",
       "      <th>src_activator</th>\n",
       "      <th>srebp_inhibitor</th>\n",
       "      <th>stat_inhibitor</th>\n",
       "      <th>stearoyl-coa_desaturase_inhibitor</th>\n",
       "      <th>steroid_sulfatase_inhibitor</th>\n",
       "      <th>steroidal_progestin</th>\n",
       "      <th>sterol_demethylase_inhibitor</th>\n",
       "      <th>sterol_regulatory_element_binding_protein_(srebp)_inhibitor</th>\n",
       "      <th>steryl_sulfatase_inhibitor</th>\n",
       "      <th>structural_glycoprotein_antagonist</th>\n",
       "      <th>succinimide_antiepileptic</th>\n",
       "      <th>sulfonylurea</th>\n",
       "      <th>synthetic_estrogen</th>\n",
       "      <th>t_cell_inhibitor</th>\n",
       "      <th>tankyrase_inhibitor</th>\n",
       "      <th>telomerase_inhibitor</th>\n",
       "      <th>testosterone_receptor_antagonist</th>\n",
       "      <th>thiazide_diuretic</th>\n",
       "      <th>thioredoxin_inhibitor</th>\n",
       "      <th>thrombopoietin_receptor_agonist</th>\n",
       "      <th>thromboxane_receptor_antagonist</th>\n",
       "      <th>thromboxane_synthase_inhibitor</th>\n",
       "      <th>thyroid_hormone_inhibitor</th>\n",
       "      <th>thyroid_hormone_stimulant</th>\n",
       "      <th>thyrotropin_releasing_hormone_receptor_agonist</th>\n",
       "      <th>tie_inhibitor</th>\n",
       "      <th>tissue_transglutaminase_inhibitor</th>\n",
       "      <th>topical_anesthetic</th>\n",
       "      <th>topical_sunscreen_agent</th>\n",
       "      <th>trace_amine_associated_receptor_agonist</th>\n",
       "      <th>trace_amine_associated_receptor_antagonist</th>\n",
       "      <th>trail_modulator</th>\n",
       "      <th>transient_receptor_potential_channel_agonist</th>\n",
       "      <th>triacylglycerol_lipase_inhibitor</th>\n",
       "      <th>tricyclic_antidepressant</th>\n",
       "      <th>tryptophan_hydroxylase_inhibitor</th>\n",
       "      <th>tyrosinase_inhibitor</th>\n",
       "      <th>tyrosine_hydroxylase_inhibitor</th>\n",
       "      <th>tyrosine_phosphatase_inhibitor</th>\n",
       "      <th>ubiquitin-conjugating_enzyme_inhibitor</th>\n",
       "      <th>ubiquitin_ligase_inhibitor</th>\n",
       "      <th>urease_inhibitor</th>\n",
       "      <th>uric_acid_diuretic</th>\n",
       "      <th>uricase_inhibitor</th>\n",
       "      <th>uricosuric</th>\n",
       "      <th>urotensin_receptor_agonist</th>\n",
       "      <th>urotensin_receptor_antagonist</th>\n",
       "      <th>vasoconstrictor</th>\n",
       "      <th>vasodilator</th>\n",
       "      <th>vasopressin_receptor_agonist</th>\n",
       "      <th>vasopressin_receptor_antagonist</th>\n",
       "      <th>ve-cadherin_antagonist</th>\n",
       "      <th>vesicular_monoamine_transporter_inhibitor</th>\n",
       "      <th>vitamin_k_antagonist</th>\n",
       "      <th>voltage-gated_calcium_channel_ligand</th>\n",
       "      <th>voltage-gated_potassium_channel_activator</th>\n",
       "      <th>voltage-gated_sodium_channel_blocker</th>\n",
       "      <th>wdr5_mll_interaction_inhibitor</th>\n",
       "      <th>wnt_agonist</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abc_transporter_expression_enhancer  abl_inhibitor  ace_inhibitor  \\\n",
       "0                                        0              0              0   \n",
       "1                                        0              0              0   \n",
       "2                                        0              0              0   \n",
       "3                                        0              0              0   \n",
       "4                                        0              0              0   \n",
       "...                                    ...            ...            ...   \n",
       "23809                                    0              0              0   \n",
       "23810                                    0              0              0   \n",
       "23811                                    0              0              0   \n",
       "23812                                    0              0              0   \n",
       "23813                                    0              0              0   \n",
       "\n",
       "       acetylcholine_release_enhancer  adenosine_deaminase_inhibitor  \\\n",
       "0                                   0                              0   \n",
       "1                                   0                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "...                               ...                            ...   \n",
       "23809                               0                              0   \n",
       "23810                               0                              0   \n",
       "23811                               0                              0   \n",
       "23812                               0                              0   \n",
       "23813                               0                              0   \n",
       "\n",
       "       adenosine_kinase_inhibitor  adenylyl_cyclase_inhibitor  age_inhibitor  \\\n",
       "0                               0                           0              0   \n",
       "1                               0                           0              0   \n",
       "2                               0                           0              0   \n",
       "3                               0                           0              0   \n",
       "4                               0                           0              0   \n",
       "...                           ...                         ...            ...   \n",
       "23809                           0                           0              0   \n",
       "23810                           0                           0              0   \n",
       "23811                           0                           0              0   \n",
       "23812                           0                           0              0   \n",
       "23813                           0                           0              0   \n",
       "\n",
       "       alcohol_dehydrogenase_inhibitor  aldehyde_dehydrogenase_activator  \\\n",
       "0                                    0                                 0   \n",
       "1                                    0                                 0   \n",
       "2                                    0                                 0   \n",
       "3                                    0                                 0   \n",
       "4                                    0                                 0   \n",
       "...                                ...                               ...   \n",
       "23809                                0                                 0   \n",
       "23810                                0                                 0   \n",
       "23811                                0                                 0   \n",
       "23812                                0                                 0   \n",
       "23813                                0                                 0   \n",
       "\n",
       "       aldose_reductase_inhibitor  alpha_mannosidase_inhibitor  \\\n",
       "0                               0                            0   \n",
       "1                               0                            0   \n",
       "2                               0                            0   \n",
       "3                               0                            0   \n",
       "4                               0                            0   \n",
       "...                           ...                          ...   \n",
       "23809                           0                            0   \n",
       "23810                           0                            0   \n",
       "23811                           0                            0   \n",
       "23812                           0                            0   \n",
       "23813                           0                            0   \n",
       "\n",
       "       ampk_inhibitor  androgen_biosynthesis_inhibitor  \\\n",
       "0                   0                                0   \n",
       "1                   0                                0   \n",
       "2                   0                                0   \n",
       "3                   0                                0   \n",
       "4                   0                                0   \n",
       "...               ...                              ...   \n",
       "23809               0                                0   \n",
       "23810               0                                0   \n",
       "23811               0                                0   \n",
       "23812               0                                0   \n",
       "23813               0                                0   \n",
       "\n",
       "       angiotensin_receptor_agonist  antacid  anthelmintic  antihypertensive  \\\n",
       "0                                 0        0             0                 0   \n",
       "1                                 0        0             0                 0   \n",
       "2                                 0        0             0                 0   \n",
       "3                                 0        0             0                 0   \n",
       "4                                 0        0             0                 0   \n",
       "...                             ...      ...           ...               ...   \n",
       "23809                             0        0             0                 0   \n",
       "23810                             0        0             0                 0   \n",
       "23811                             0        0             0                 0   \n",
       "23812                             0        0             0                 0   \n",
       "23813                             0        0             0                 0   \n",
       "\n",
       "       antimetabolite  antipruritic  antirheumatic_drug  antiseptic  \\\n",
       "0                   0             0                   0           0   \n",
       "1                   0             0                   0           0   \n",
       "2                   0             0                   0           0   \n",
       "3                   0             0                   0           0   \n",
       "4                   0             0                   0           0   \n",
       "...               ...           ...                 ...         ...   \n",
       "23809               0             0                   0           0   \n",
       "23810               0             0                   0           0   \n",
       "23811               0             0                   0           0   \n",
       "23812               0             0                   0           0   \n",
       "23813               0             0                   0           0   \n",
       "\n",
       "       antispasmodic  antithyroid_agent  antitussive  anxiolytic  \\\n",
       "0                  0                  0            0           0   \n",
       "1                  0                  0            0           0   \n",
       "2                  0                  0            0           0   \n",
       "3                  0                  0            0           0   \n",
       "4                  0                  0            0           0   \n",
       "...              ...                ...          ...         ...   \n",
       "23809              0                  0            0           0   \n",
       "23810              0                  0            0           0   \n",
       "23811              0                  0            0           0   \n",
       "23812              0                  0            0           0   \n",
       "23813              0                  0            0           0   \n",
       "\n",
       "       ap_inhibitor  apolipoprotein_expression_enhancer  apoptosis_inhibitor  \\\n",
       "0                 0                                   0                    0   \n",
       "1                 0                                   0                    0   \n",
       "2                 0                                   0                    0   \n",
       "3                 0                                   0                    0   \n",
       "4                 0                                   0                    0   \n",
       "...             ...                                 ...                  ...   \n",
       "23809             0                                   0                    0   \n",
       "23810             0                                   0                    0   \n",
       "23811             0                                   0                    0   \n",
       "23812             0                                   0                    0   \n",
       "23813             0                                   0                    0   \n",
       "\n",
       "       arf_inhibitor  aryl_hydrocarbon_receptor_agonist  \\\n",
       "0                  0                                  0   \n",
       "1                  0                                  0   \n",
       "2                  0                                  0   \n",
       "3                  0                                  0   \n",
       "4                  0                                  0   \n",
       "...              ...                                ...   \n",
       "23809              0                                  0   \n",
       "23810              0                                  0   \n",
       "23811              0                                  0   \n",
       "23812              0                                  0   \n",
       "23813              0                                  0   \n",
       "\n",
       "       aryl_hydrocarbon_receptor_antagonist  aspartic_protease_inhibitor  \\\n",
       "0                                         0                            0   \n",
       "1                                         0                            0   \n",
       "2                                         0                            0   \n",
       "3                                         0                            0   \n",
       "4                                         0                            0   \n",
       "...                                     ...                          ...   \n",
       "23809                                     0                            0   \n",
       "23810                                     0                            0   \n",
       "23811                                     0                            0   \n",
       "23812                                     0                            0   \n",
       "23813                                     0                            0   \n",
       "\n",
       "       atherogenesis_inhibitor  atherosclerosis_formation_inhibitor  \\\n",
       "0                            0                                    0   \n",
       "1                            0                                    0   \n",
       "2                            0                                    0   \n",
       "3                            0                                    0   \n",
       "4                            0                                    0   \n",
       "...                        ...                                  ...   \n",
       "23809                        0                                    0   \n",
       "23810                        0                                    0   \n",
       "23811                        0                                    0   \n",
       "23812                        0                                    0   \n",
       "23813                        0                                    0   \n",
       "\n",
       "       atp-sensitive_potassium_channel_agonist  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "23809                                        0   \n",
       "23810                                        0   \n",
       "23811                                        0   \n",
       "23812                                        0   \n",
       "23813                                        0   \n",
       "\n",
       "       atp-sensitive_potassium_channel_inhibitor  atp_channel_activator  \\\n",
       "0                                              0                      0   \n",
       "1                                              0                      0   \n",
       "2                                              0                      0   \n",
       "3                                              0                      0   \n",
       "4                                              0                      0   \n",
       "...                                          ...                    ...   \n",
       "23809                                          0                      0   \n",
       "23810                                          0                      0   \n",
       "23811                                          0                      0   \n",
       "23812                                          0                      0   \n",
       "23813                                          0                      0   \n",
       "\n",
       "       atp_channel_blocker  atp_citrase_lyase_inhibitor  autophagy_inducer  \\\n",
       "0                        0                            0                  0   \n",
       "1                        0                            0                  0   \n",
       "2                        0                            0                  0   \n",
       "3                        0                            0                  0   \n",
       "4                        0                            0                  0   \n",
       "...                    ...                          ...                ...   \n",
       "23809                    0                            0                  0   \n",
       "23810                    0                            0                  0   \n",
       "23811                    0                            0                  0   \n",
       "23812                    0                            0                  0   \n",
       "23813                    0                            0                  0   \n",
       "\n",
       "       axl_kinase_inhibitor  bacterial_atpase_inhibitor  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "...                     ...                         ...   \n",
       "23809                     0                           0   \n",
       "23810                     0                           0   \n",
       "23811                     0                           0   \n",
       "23812                     0                           0   \n",
       "23813                     0                           0   \n",
       "\n",
       "       bacterial_permeability_inducer  bacterial_protein_synthesis_inhibitor  \\\n",
       "0                                   0                                      0   \n",
       "1                                   0                                      0   \n",
       "2                                   0                                      0   \n",
       "3                                   0                                      0   \n",
       "4                                   0                                      0   \n",
       "...                               ...                                    ...   \n",
       "23809                               0                                      0   \n",
       "23810                               0                                      0   \n",
       "23811                               0                                      0   \n",
       "23812                               0                                      0   \n",
       "23813                               0                                      0   \n",
       "\n",
       "       benzodiazepine_receptor_antagonist  beta_catenin_inhibitor  \\\n",
       "0                                       0                       0   \n",
       "1                                       0                       0   \n",
       "2                                       0                       0   \n",
       "3                                       0                       0   \n",
       "4                                       0                       0   \n",
       "...                                   ...                     ...   \n",
       "23809                                   0                       0   \n",
       "23810                                   0                       0   \n",
       "23811                                   0                       0   \n",
       "23812                                   0                       0   \n",
       "23813                                   0                       0   \n",
       "\n",
       "       beta_lactamase_inhibitor  beta_secretase_inhibitor  big1_inhibitor  \\\n",
       "0                             0                         0               0   \n",
       "1                             0                         0               0   \n",
       "2                             0                         0               0   \n",
       "3                             0                         0               0   \n",
       "4                             0                         0               0   \n",
       "...                         ...                       ...             ...   \n",
       "23809                         0                         0               0   \n",
       "23810                         0                         0               0   \n",
       "23811                         0                         0               0   \n",
       "23812                         0                         0               0   \n",
       "23813                         0                         0               0   \n",
       "\n",
       "       bile_acid  biliverdin_reductase_a_activator  bone_resorption_inhibitor  \\\n",
       "0              0                                 0                          0   \n",
       "1              0                                 0                          0   \n",
       "2              0                                 0                          0   \n",
       "3              0                                 0                          0   \n",
       "4              0                                 0                          0   \n",
       "...          ...                               ...                        ...   \n",
       "23809          0                                 0                          0   \n",
       "23810          0                                 0                          0   \n",
       "23811          0                                 0                          0   \n",
       "23812          0                                 0                          0   \n",
       "23813          0                                 0                          0   \n",
       "\n",
       "       botulin_neurotoxin_inhibitor  bradykinin_receptor_antagonist  \\\n",
       "0                                 0                               0   \n",
       "1                                 0                               0   \n",
       "2                                 0                               0   \n",
       "3                                 0                               0   \n",
       "4                                 0                               0   \n",
       "...                             ...                             ...   \n",
       "23809                             0                               0   \n",
       "23810                             0                               0   \n",
       "23811                             0                               0   \n",
       "23812                             0                               0   \n",
       "23813                             0                               0   \n",
       "\n",
       "       breast_cancer_resistance_protein_inhibitor  bronchodilator  \\\n",
       "0                                               0               0   \n",
       "1                                               0               0   \n",
       "2                                               0               0   \n",
       "3                                               0               0   \n",
       "4                                               0               0   \n",
       "...                                           ...             ...   \n",
       "23809                                           0               0   \n",
       "23810                                           0               0   \n",
       "23811                                           0               0   \n",
       "23812                                           0               0   \n",
       "23813                                           0               0   \n",
       "\n",
       "       calcitonin_antagonist  calcium_channel_activator  calmodulin_inhibitor  \\\n",
       "0                          0                          0                     0   \n",
       "1                          0                          0                     0   \n",
       "2                          0                          0                     0   \n",
       "3                          0                          0                     0   \n",
       "4                          0                          0                     0   \n",
       "...                      ...                        ...                   ...   \n",
       "23809                      0                          0                     0   \n",
       "23810                      0                          0                     0   \n",
       "23811                      0                          0                     0   \n",
       "23812                      0                          0                     0   \n",
       "23813                      0                          0                     0   \n",
       "\n",
       "       calpain_inhibitor  camp_stimulant  capillary_stabilizing_agent  \\\n",
       "0                      0               0                            0   \n",
       "1                      0               0                            0   \n",
       "2                      0               0                            0   \n",
       "3                      0               0                            0   \n",
       "4                      0               0                            0   \n",
       "...                  ...             ...                          ...   \n",
       "23809                  0               0                            0   \n",
       "23810                  0               0                            0   \n",
       "23811                  0               0                            0   \n",
       "23812                  0               0                            0   \n",
       "23813                  0               0                            0   \n",
       "\n",
       "       car_agonist  car_antagonist  carboxylesterase_inhibitor  carcinogen  \\\n",
       "0                0               0                           0           0   \n",
       "1                0               0                           0           0   \n",
       "2                0               0                           0           0   \n",
       "3                0               0                           0           0   \n",
       "4                0               0                           0           0   \n",
       "...            ...             ...                         ...         ...   \n",
       "23809            0               0                           0           0   \n",
       "23810            0               0                           0           0   \n",
       "23811            0               0                           0           0   \n",
       "23812            0               0                           0           0   \n",
       "23813            0               0                           0           0   \n",
       "\n",
       "       cardiac_glycoside  carnitine_palmitoyltransferase_inhibitor  \\\n",
       "0                      0                                         0   \n",
       "1                      0                                         0   \n",
       "2                      0                                         0   \n",
       "3                      0                                         0   \n",
       "4                      0                                         0   \n",
       "...                  ...                                       ...   \n",
       "23809                  0                                         0   \n",
       "23810                  0                                         0   \n",
       "23811                  0                                         0   \n",
       "23812                  0                                         0   \n",
       "23813                  0                                         0   \n",
       "\n",
       "       caspase_inhibitor  cathepsin_inhibitor  cc_chemokine_receptor_agonist  \\\n",
       "0                      0                    0                              0   \n",
       "1                      0                    0                              0   \n",
       "2                      0                    0                              0   \n",
       "3                      0                    0                              0   \n",
       "4                      0                    0                              0   \n",
       "...                  ...                  ...                            ...   \n",
       "23809                  0                    0                              0   \n",
       "23810                  0                    0                              0   \n",
       "23811                  0                    0                              0   \n",
       "23812                  0                    0                              0   \n",
       "23813                  0                    0                              0   \n",
       "\n",
       "       cdc_inhibitor  cdk_expression_enhancer  cell_cycle_inhibitor  \\\n",
       "0                  0                        0                     0   \n",
       "1                  0                        0                     0   \n",
       "2                  0                        0                     0   \n",
       "3                  0                        0                     0   \n",
       "4                  0                        0                     0   \n",
       "...              ...                      ...                   ...   \n",
       "23809              0                        0                     0   \n",
       "23810              0                        0                     0   \n",
       "23811              0                        0                     0   \n",
       "23812              0                        0                     0   \n",
       "23813              0                        0                     0   \n",
       "\n",
       "       cell_proliferation_inhibitor  ceramidase_inhibitor  \\\n",
       "0                                 0                     0   \n",
       "1                                 0                     0   \n",
       "2                                 0                     0   \n",
       "3                                 0                     0   \n",
       "4                                 0                     0   \n",
       "...                             ...                   ...   \n",
       "23809                             0                     0   \n",
       "23810                             0                     0   \n",
       "23811                             0                     0   \n",
       "23812                             0                     0   \n",
       "23813                             0                     0   \n",
       "\n",
       "       cftr_channel_agonist  cftr_channel_antagonist  chitin_inhibitor  \\\n",
       "0                         0                        0                 0   \n",
       "1                         0                        0                 0   \n",
       "2                         0                        0                 0   \n",
       "3                         0                        0                 0   \n",
       "4                         0                        0                 0   \n",
       "...                     ...                      ...               ...   \n",
       "23809                     0                        0                 0   \n",
       "23810                     0                        0                 0   \n",
       "23811                     0                        0                 0   \n",
       "23812                     0                        0                 0   \n",
       "23813                     0                        0                 0   \n",
       "\n",
       "       chloride_channel_activator  choleretic_agent  \\\n",
       "0                               0                 0   \n",
       "1                               0                 0   \n",
       "2                               0                 0   \n",
       "3                               0                 0   \n",
       "4                               0                 0   \n",
       "...                           ...               ...   \n",
       "23809                           0                 0   \n",
       "23810                           0                 0   \n",
       "23811                           0                 0   \n",
       "23812                           0                 0   \n",
       "23813                           0                 0   \n",
       "\n",
       "       cholinergic_receptor_agonist  cholinesterase_inhibitor  clk_inhibitor  \\\n",
       "0                                 0                         0              0   \n",
       "1                                 0                         0              0   \n",
       "2                                 0                         0              0   \n",
       "3                                 0                         0              0   \n",
       "4                                 0                         0              0   \n",
       "...                             ...                       ...            ...   \n",
       "23809                             0                         0              0   \n",
       "23810                             0                         0              0   \n",
       "23811                             0                         0              0   \n",
       "23812                             0                         0              0   \n",
       "23813                             0                         0              0   \n",
       "\n",
       "       coenzyme_a_precursor  collagenase_inhibitor  \\\n",
       "0                         0                      0   \n",
       "1                         0                      0   \n",
       "2                         0                      0   \n",
       "3                         0                      0   \n",
       "4                         0                      0   \n",
       "...                     ...                    ...   \n",
       "23809                     0                      0   \n",
       "23810                     0                      0   \n",
       "23811                     0                      0   \n",
       "23812                     0                      0   \n",
       "23813                     0                      0   \n",
       "\n",
       "       collapsin_response_mediator_protein_stimulant  coloring_agent  \\\n",
       "0                                                  0               0   \n",
       "1                                                  0               0   \n",
       "2                                                  0               0   \n",
       "3                                                  0               0   \n",
       "4                                                  0               0   \n",
       "...                                              ...             ...   \n",
       "23809                                              0               0   \n",
       "23810                                              0               0   \n",
       "23811                                              0               0   \n",
       "23812                                              0               0   \n",
       "23813                                              0               0   \n",
       "\n",
       "       complement_antagonist  complement_inhibitor  contraceptive_agent  \\\n",
       "0                          0                     0                    0   \n",
       "1                          0                     0                    0   \n",
       "2                          0                     0                    0   \n",
       "3                          0                     0                    0   \n",
       "4                          0                     0                    0   \n",
       "...                      ...                   ...                  ...   \n",
       "23809                      0                     0                    0   \n",
       "23810                      0                     0                    0   \n",
       "23811                      0                     0                    0   \n",
       "23812                      0                     0                    0   \n",
       "23813                      0                     0                    0   \n",
       "\n",
       "       contrast_agent  corticosteroid_antagonist  cyclin_d_inhibitor  \\\n",
       "0                   0                          0                   0   \n",
       "1                   0                          0                   0   \n",
       "2                   0                          0                   0   \n",
       "3                   0                          0                   0   \n",
       "4                   0                          0                   0   \n",
       "...               ...                        ...                 ...   \n",
       "23809               0                          0                   0   \n",
       "23810               0                          0                   0   \n",
       "23811               0                          0                   0   \n",
       "23812               0                          0                   0   \n",
       "23813               0                          0                   0   \n",
       "\n",
       "       cysteine_peptidase_inhibitor  cytidine_deaminase_inhibitor  \\\n",
       "0                                 0                             0   \n",
       "1                                 0                             0   \n",
       "2                                 0                             0   \n",
       "3                                 0                             0   \n",
       "4                                 0                             0   \n",
       "...                             ...                           ...   \n",
       "23809                             0                             0   \n",
       "23810                             0                             0   \n",
       "23811                             0                             0   \n",
       "23812                             0                             0   \n",
       "23813                             0                             0   \n",
       "\n",
       "       cytokine_production_inhibitor  dehydrogenase_inhibitor  \\\n",
       "0                                  0                        0   \n",
       "1                                  0                        0   \n",
       "2                                  0                        0   \n",
       "3                                  0                        0   \n",
       "4                                  0                        0   \n",
       "...                              ...                      ...   \n",
       "23809                              0                        0   \n",
       "23810                              0                        0   \n",
       "23811                              0                        0   \n",
       "23812                              0                        0   \n",
       "23813                              0                        0   \n",
       "\n",
       "       deubiquitinase_inhibitor  diacylglycerol_kinase_inhibitor  \\\n",
       "0                             0                                0   \n",
       "1                             0                                0   \n",
       "2                             0                                0   \n",
       "3                             0                                0   \n",
       "4                             0                                0   \n",
       "...                         ...                              ...   \n",
       "23809                         0                                0   \n",
       "23810                         0                                0   \n",
       "23811                         0                                0   \n",
       "23812                         0                                0   \n",
       "23813                         0                                0   \n",
       "\n",
       "       diacylglycerol_o_acyltransferase_inhibitor  differentiation_inducer  \\\n",
       "0                                               0                        0   \n",
       "1                                               0                        0   \n",
       "2                                               0                        0   \n",
       "3                                               0                        0   \n",
       "4                                               0                        0   \n",
       "...                                           ...                      ...   \n",
       "23809                                           0                        0   \n",
       "23810                                           0                        0   \n",
       "23811                                           0                        0   \n",
       "23812                                           0                        0   \n",
       "23813                                           0                        0   \n",
       "\n",
       "       dihydroorotate_dehydrogenase_inhibitor  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "23809                                       0   \n",
       "23810                                       0   \n",
       "23811                                       0   \n",
       "23812                                       0   \n",
       "23813                                       0   \n",
       "\n",
       "       dihydropteroate_synthase_inhibitor  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "...                                   ...   \n",
       "23809                                   0   \n",
       "23810                                   0   \n",
       "23811                                   0   \n",
       "23812                                   0   \n",
       "23813                                   0   \n",
       "\n",
       "       dihydropyrimidine_dehydrogenase_inhibitor  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "23809                                          0   \n",
       "23810                                          0   \n",
       "23811                                          0   \n",
       "23812                                          0   \n",
       "23813                                          0   \n",
       "\n",
       "       dna_dependent_protein_kinase_inhibitor  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "...                                       ...   \n",
       "23809                                       0   \n",
       "23810                                       0   \n",
       "23811                                       0   \n",
       "23812                                       0   \n",
       "23813                                       0   \n",
       "\n",
       "       dna_methyltransferase_inhibitor  dna_polymerase_inhibitor  \\\n",
       "0                                    0                         0   \n",
       "1                                    0                         0   \n",
       "2                                    0                         0   \n",
       "3                                    0                         0   \n",
       "4                                    0                         0   \n",
       "...                                ...                       ...   \n",
       "23809                                0                         0   \n",
       "23810                                0                         0   \n",
       "23811                                0                         0   \n",
       "23812                                0                         0   \n",
       "23813                                0                         0   \n",
       "\n",
       "       dna_repair_enzyme_inhibitor  dna_synthesis_inhibitor  \\\n",
       "0                                0                        0   \n",
       "1                                0                        0   \n",
       "2                                0                        0   \n",
       "3                                0                        0   \n",
       "4                                0                        0   \n",
       "...                            ...                      ...   \n",
       "23809                            0                        0   \n",
       "23810                            0                        0   \n",
       "23811                            0                        0   \n",
       "23812                            0                        0   \n",
       "23813                            0                        0   \n",
       "\n",
       "       dopamine_release_enhancer  dot1l_inhibitor  dynamin_inhibitor  \\\n",
       "0                              0                0                  0   \n",
       "1                              0                0                  0   \n",
       "2                              0                0                  0   \n",
       "3                              0                0                  0   \n",
       "4                              0                0                  0   \n",
       "...                          ...              ...                ...   \n",
       "23809                          0                0                  0   \n",
       "23810                          0                0                  0   \n",
       "23811                          0                0                  0   \n",
       "23812                          0                0                  0   \n",
       "23813                          0                0                  0   \n",
       "\n",
       "       dyrk_inhibitor  dystrophin_stimulant  endothelin_receptor_antagonist  \\\n",
       "0                   0                     0                               0   \n",
       "1                   0                     0                               0   \n",
       "2                   0                     0                               0   \n",
       "3                   0                     0                               0   \n",
       "4                   0                     0                               0   \n",
       "...               ...                   ...                             ...   \n",
       "23809               0                     0                               0   \n",
       "23810               0                     0                               0   \n",
       "23811               0                     0                               0   \n",
       "23812               0                     0                               0   \n",
       "23813               0                     0                               0   \n",
       "\n",
       "       enkephalinase_inhibitor  ephrin_inhibitor  epoxide_hydolase_inhibitor  \\\n",
       "0                            0                 0                           0   \n",
       "1                            0                 0                           0   \n",
       "2                            0                 0                           0   \n",
       "3                            0                 0                           0   \n",
       "4                            0                 0                           0   \n",
       "...                        ...               ...                         ...   \n",
       "23809                        0                 0                           0   \n",
       "23810                        0                 0                           0   \n",
       "23811                        0                 0                           0   \n",
       "23812                        0                 0                           0   \n",
       "23813                        0                 0                           0   \n",
       "\n",
       "       etv1_inhibitor  eukaryotic_translation_initiation_factor_inhibitor  \\\n",
       "0                   0                                                  0    \n",
       "1                   0                                                  0    \n",
       "2                   0                                                  0    \n",
       "3                   0                                                  0    \n",
       "4                   0                                                  0    \n",
       "...               ...                                                ...    \n",
       "23809               0                                                  0    \n",
       "23810               0                                                  0    \n",
       "23811               0                                                  0    \n",
       "23812               0                                                  0    \n",
       "23813               0                                                  0    \n",
       "\n",
       "       exportin_antagonist  fabi_inhibitor  \\\n",
       "0                        0               0   \n",
       "1                        0               0   \n",
       "2                        0               0   \n",
       "3                        0               0   \n",
       "4                        0               0   \n",
       "...                    ...             ...   \n",
       "23809                    0               0   \n",
       "23810                    0               0   \n",
       "23811                    0               0   \n",
       "23812                    0               0   \n",
       "23813                    0               0   \n",
       "\n",
       "       farnesyl_pyrophosphate_synthase_inhibitor  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "23809                                          0   \n",
       "23810                                          0   \n",
       "23811                                          0   \n",
       "23812                                          0   \n",
       "23813                                          0   \n",
       "\n",
       "       fatty_acid_receptor_antagonist  fatty_acid_synthase_inhibitor  \\\n",
       "0                                   0                              0   \n",
       "1                                   0                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "...                               ...                            ...   \n",
       "23809                               0                              0   \n",
       "23810                               0                              0   \n",
       "23811                               0                              0   \n",
       "23812                               0                              0   \n",
       "23813                               0                              0   \n",
       "\n",
       "       folate_receptor_ligand  free_fatty_acid_receptor_agonist  \\\n",
       "0                           0                                 0   \n",
       "1                           0                                 0   \n",
       "2                           0                                 0   \n",
       "3                           0                                 0   \n",
       "4                           0                                 0   \n",
       "...                       ...                               ...   \n",
       "23809                       0                                 0   \n",
       "23810                       0                                 0   \n",
       "23811                       0                                 0   \n",
       "23812                       0                                 0   \n",
       "23813                       0                                 0   \n",
       "\n",
       "       fungal_1,3-beta-d-glucan_synthase_inhibitor  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "23809                                            0   \n",
       "23810                                            0   \n",
       "23811                                            0   \n",
       "23812                                            0   \n",
       "23813                                            0   \n",
       "\n",
       "       fungal_ergosterol_inhibitor  fungal_lanosterol_demethylase_inhibitor  \\\n",
       "0                                0                                        0   \n",
       "1                                0                                        0   \n",
       "2                                0                                        0   \n",
       "3                                0                                        0   \n",
       "4                                0                                        0   \n",
       "...                            ...                                      ...   \n",
       "23809                            0                                        0   \n",
       "23810                            0                                        0   \n",
       "23811                            0                                        0   \n",
       "23812                            0                                        0   \n",
       "23813                            0                                        0   \n",
       "\n",
       "       fxr_agonist  fxr_antagonist  g_protein-coupled_receptor_agonist  \\\n",
       "0                0               0                                   0   \n",
       "1                0               0                                   0   \n",
       "2                0               0                                   0   \n",
       "3                0               0                                   0   \n",
       "4                0               0                                   0   \n",
       "...            ...             ...                                 ...   \n",
       "23809            0               0                                   0   \n",
       "23810            0               0                                   0   \n",
       "23811            0               0                                   0   \n",
       "23812            0               0                                   0   \n",
       "23813            0               0                                   0   \n",
       "\n",
       "       g_protein-coupled_receptor_antagonist  g_protein_signaling_inhibitor  \\\n",
       "0                                          0                              0   \n",
       "1                                          0                              0   \n",
       "2                                          0                              0   \n",
       "3                                          0                              0   \n",
       "4                                          0                              0   \n",
       "...                                      ...                            ...   \n",
       "23809                                      0                              0   \n",
       "23810                                      0                              0   \n",
       "23811                                      0                              0   \n",
       "23812                                      0                              0   \n",
       "23813                                      0                              0   \n",
       "\n",
       "       gaba_gated_chloride_channel_blocker  gaba_receptor_modulator  \\\n",
       "0                                        0                        0   \n",
       "1                                        0                        0   \n",
       "2                                        0                        0   \n",
       "3                                        0                        0   \n",
       "4                                        0                        0   \n",
       "...                                    ...                      ...   \n",
       "23809                                    0                        0   \n",
       "23810                                    0                        0   \n",
       "23811                                    0                        0   \n",
       "23812                                    0                        0   \n",
       "23813                                    0                        0   \n",
       "\n",
       "       gaba_uptake_inhibitor  gap_junction_modulator  gastrin_inhibitor  \\\n",
       "0                          0                       0                  0   \n",
       "1                          0                       0                  0   \n",
       "2                          0                       0                  0   \n",
       "3                          0                       0                  0   \n",
       "4                          0                       0                  0   \n",
       "...                      ...                     ...                ...   \n",
       "23809                      0                       0                  0   \n",
       "23810                      0                       0                  0   \n",
       "23811                      0                       0                  0   \n",
       "23812                      0                       0                  0   \n",
       "23813                      0                       0                  0   \n",
       "\n",
       "       gat_inhibitor  glcnac_phosphotransferase_inhibitor  gli_antagonist  \\\n",
       "0                  0                                    0               0   \n",
       "1                  0                                    0               0   \n",
       "2                  0                                    0               0   \n",
       "3                  0                                    0               0   \n",
       "4                  0                                    0               0   \n",
       "...              ...                                  ...             ...   \n",
       "23809              0                                    0               0   \n",
       "23810              0                                    0               0   \n",
       "23811              0                                    0               0   \n",
       "23812              0                                    0               0   \n",
       "23813              0                                    0               0   \n",
       "\n",
       "       glp_receptor_agonist  glucagon_receptor_antagonist  \\\n",
       "0                         0                             0   \n",
       "1                         0                             0   \n",
       "2                         0                             0   \n",
       "3                         0                             0   \n",
       "4                         0                             0   \n",
       "...                     ...                           ...   \n",
       "23809                     0                             0   \n",
       "23810                     0                             0   \n",
       "23811                     0                             0   \n",
       "23812                     0                             0   \n",
       "23813                     0                             0   \n",
       "\n",
       "       glucocorticoid_receptor_antagonist  glucokinase_activator  \\\n",
       "0                                       0                      0   \n",
       "1                                       0                      0   \n",
       "2                                       0                      0   \n",
       "3                                       0                      0   \n",
       "4                                       0                      0   \n",
       "...                                   ...                    ...   \n",
       "23809                                   0                      0   \n",
       "23810                                   0                      0   \n",
       "23811                                   0                      0   \n",
       "23812                                   0                      0   \n",
       "23813                                   0                      0   \n",
       "\n",
       "       glucokinase_inhibitor  gluconeogenesis_inhibitor  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "...                      ...                        ...   \n",
       "23809                      0                          0   \n",
       "23810                      0                          0   \n",
       "23811                      0                          0   \n",
       "23812                      0                          0   \n",
       "23813                      0                          0   \n",
       "\n",
       "       glucose_dependent_insulinotropic_receptor_agonist  \\\n",
       "0                                                      0   \n",
       "1                                                      0   \n",
       "2                                                      0   \n",
       "3                                                      0   \n",
       "4                                                      0   \n",
       "...                                                  ...   \n",
       "23809                                                  0   \n",
       "23810                                                  0   \n",
       "23811                                                  0   \n",
       "23812                                                  0   \n",
       "23813                                                  0   \n",
       "\n",
       "       glucosidase_inhibitor  glutamate_receptor_modulator  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "...                      ...                           ...   \n",
       "23809                      0                             0   \n",
       "23810                      0                             0   \n",
       "23811                      0                             0   \n",
       "23812                      0                             0   \n",
       "23813                      0                             0   \n",
       "\n",
       "       glutathione_peroxidase_agonist  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "...                               ...   \n",
       "23809                               0   \n",
       "23810                               0   \n",
       "23811                               0   \n",
       "23812                               0   \n",
       "23813                               0   \n",
       "\n",
       "       glutathione_reductase_(nadph)_activators  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "23809                                         0   \n",
       "23810                                         0   \n",
       "23811                                         0   \n",
       "23812                                         0   \n",
       "23813                                         0   \n",
       "\n",
       "       glutathione_transferase_inhibitor  glycine_receptor_antagonist  \\\n",
       "0                                      0                            0   \n",
       "1                                      0                            0   \n",
       "2                                      0                            0   \n",
       "3                                      0                            0   \n",
       "4                                      0                            0   \n",
       "...                                  ...                          ...   \n",
       "23809                                  0                            0   \n",
       "23810                                  0                            0   \n",
       "23811                                  0                            0   \n",
       "23812                                  0                            0   \n",
       "23813                                  0                            0   \n",
       "\n",
       "       glycine_transporter_inhibitor  glycogen_phosphorylase_inhibitor  \\\n",
       "0                                  0                                 0   \n",
       "1                                  0                                 0   \n",
       "2                                  0                                 0   \n",
       "3                                  0                                 0   \n",
       "4                                  0                                 0   \n",
       "...                              ...                               ...   \n",
       "23809                              0                                 0   \n",
       "23810                              0                                 0   \n",
       "23811                              0                                 0   \n",
       "23812                              0                                 0   \n",
       "23813                              0                                 0   \n",
       "\n",
       "       glycolysis_inhibitor  glycosylation_inhibitor  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "...                     ...                      ...   \n",
       "23809                     0                        0   \n",
       "23810                     0                        0   \n",
       "23811                     0                        0   \n",
       "23812                     0                        0   \n",
       "23813                     0                        0   \n",
       "\n",
       "       gonadotropin_receptor_antagonist  growth_factor_receptor_inhibitor  \\\n",
       "0                                     0                                 0   \n",
       "1                                     0                                 0   \n",
       "2                                     0                                 0   \n",
       "3                                     0                                 0   \n",
       "4                                     0                                 0   \n",
       "...                                 ...                               ...   \n",
       "23809                                 0                                 0   \n",
       "23810                                 0                                 0   \n",
       "23811                                 0                                 0   \n",
       "23812                                 0                                 0   \n",
       "23813                                 0                                 0   \n",
       "\n",
       "       gtpase_inhibitor  guanylate_cyclase_activator  \\\n",
       "0                     0                            0   \n",
       "1                     0                            0   \n",
       "2                     0                            0   \n",
       "3                     0                            0   \n",
       "4                     0                            0   \n",
       "...                 ...                          ...   \n",
       "23809                 0                            0   \n",
       "23810                 0                            0   \n",
       "23811                 0                            0   \n",
       "23812                 0                            0   \n",
       "23813                 0                            0   \n",
       "\n",
       "       guanylate_cyclase_stimulant  guanylyl_cyclase_activator  \\\n",
       "0                                0                           0   \n",
       "1                                0                           0   \n",
       "2                                0                           0   \n",
       "3                                0                           0   \n",
       "4                                0                           0   \n",
       "...                            ...                         ...   \n",
       "23809                            0                           0   \n",
       "23810                            0                           0   \n",
       "23811                            0                           0   \n",
       "23812                            0                           0   \n",
       "23813                            0                           0   \n",
       "\n",
       "       h+_k+-atpase_inhibitor  haemostatic_agent  hcn_channel_antagonist  \\\n",
       "0                           0                  0                       0   \n",
       "1                           0                  0                       0   \n",
       "2                           0                  0                       0   \n",
       "3                           0                  0                       0   \n",
       "4                           0                  0                       0   \n",
       "...                       ...                ...                     ...   \n",
       "23809                       0                  0                       0   \n",
       "23810                       0                  0                       0   \n",
       "23811                       0                  0                       0   \n",
       "23812                       0                  0                       0   \n",
       "23813                       0                  0                       0   \n",
       "\n",
       "       hedgehog_pathway_inhibitor  heme_oxygenase_activators  \\\n",
       "0                               0                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "...                           ...                        ...   \n",
       "23809                           0                          0   \n",
       "23810                           0                          0   \n",
       "23811                           0                          0   \n",
       "23812                           0                          0   \n",
       "23813                           0                          0   \n",
       "\n",
       "       hemoglobin_antagonist  hexokinase_inhibitor  hgf_receptor_inhibitor  \\\n",
       "0                          0                     0                       0   \n",
       "1                          0                     0                       0   \n",
       "2                          0                     0                       0   \n",
       "3                          0                     0                       0   \n",
       "4                          0                     0                       0   \n",
       "...                      ...                   ...                     ...   \n",
       "23809                      0                     0                       0   \n",
       "23810                      0                     0                       0   \n",
       "23811                      0                     0                       0   \n",
       "23812                      0                     0                       0   \n",
       "23813                      0                     0                       0   \n",
       "\n",
       "       hif_inhibitor  histamine_release_inhibitor  \\\n",
       "0                  0                            0   \n",
       "1                  0                            0   \n",
       "2                  0                            0   \n",
       "3                  0                            0   \n",
       "4                  0                            0   \n",
       "...              ...                          ...   \n",
       "23809              0                            0   \n",
       "23810              0                            0   \n",
       "23811              0                            0   \n",
       "23812              0                            0   \n",
       "23813              0                            0   \n",
       "\n",
       "       histone_acetyltransferase_inhibitor  histone_demethylase_inhibitor  \\\n",
       "0                                        0                              0   \n",
       "1                                        0                              0   \n",
       "2                                        0                              0   \n",
       "3                                        0                              0   \n",
       "4                                        0                              0   \n",
       "...                                    ...                            ...   \n",
       "23809                                    0                              0   \n",
       "23810                                    0                              0   \n",
       "23811                                    0                              0   \n",
       "23812                                    0                              0   \n",
       "23813                                    0                              0   \n",
       "\n",
       "       hiv_integrase_inhibitor  hiv_protease_inhibitor  hsp_inducer  \\\n",
       "0                            0                       0            0   \n",
       "1                            0                       0            0   \n",
       "2                            0                       0            0   \n",
       "3                            0                       0            0   \n",
       "4                            0                       0            0   \n",
       "...                        ...                     ...          ...   \n",
       "23809                        0                       0            0   \n",
       "23810                        0                       0            0   \n",
       "23811                        0                       0            0   \n",
       "23812                        0                       0            0   \n",
       "23813                        0                       0            0   \n",
       "\n",
       "       hydantoin_antiepileptic  hydroxycarboxylic_acid_receptor_agonist  \\\n",
       "0                            0                                        0   \n",
       "1                            0                                        0   \n",
       "2                            0                                        0   \n",
       "3                            0                                        0   \n",
       "4                            0                                        0   \n",
       "...                        ...                                      ...   \n",
       "23809                        0                                        0   \n",
       "23810                        0                                        0   \n",
       "23811                        0                                        0   \n",
       "23812                        0                                        0   \n",
       "23813                        0                                        0   \n",
       "\n",
       "       icam1_antagonist  icam1_inhibitor  id1_expression_inhibitor  \\\n",
       "0                     0                0                         0   \n",
       "1                     0                0                         0   \n",
       "2                     0                0                         0   \n",
       "3                     0                0                         0   \n",
       "4                     0                0                         0   \n",
       "...                 ...              ...                       ...   \n",
       "23809                 0                0                         0   \n",
       "23810                 0                0                         0   \n",
       "23811                 0                0                         0   \n",
       "23812                 0                0                         0   \n",
       "23813                 0                0                         0   \n",
       "\n",
       "       imidazoline_ligand  immunostimulant  \\\n",
       "0                       0                0   \n",
       "1                       0                0   \n",
       "2                       0                0   \n",
       "3                       0                0   \n",
       "4                       0                0   \n",
       "...                   ...              ...   \n",
       "23809                   0                0   \n",
       "23810                   0                0   \n",
       "23811                   0                0   \n",
       "23812                   0                0   \n",
       "23813                   0                0   \n",
       "\n",
       "       indoleamine_2,3-dioxygenase_inhibitor  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "...                                      ...   \n",
       "23809                                      0   \n",
       "23810                                      0   \n",
       "23811                                      0   \n",
       "23812                                      0   \n",
       "23813                                      0   \n",
       "\n",
       "       inosine_monophosphate_dehydrogenase_inhibitor  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "23809                                              0   \n",
       "23810                                              0   \n",
       "23811                                              0   \n",
       "23812                                              0   \n",
       "23813                                              0   \n",
       "\n",
       "       inositol_monophosphatase_inhibitor  interferon_inducer  \\\n",
       "0                                       0                   0   \n",
       "1                                       0                   0   \n",
       "2                                       0                   0   \n",
       "3                                       0                   0   \n",
       "4                                       0                   0   \n",
       "...                                   ...                 ...   \n",
       "23809                                   0                   0   \n",
       "23810                                   0                   0   \n",
       "23811                                   0                   0   \n",
       "23812                                   0                   0   \n",
       "23813                                   0                   0   \n",
       "\n",
       "       interleukin_inhibitor  interleukin_receptor_agonist  \\\n",
       "0                          0                             0   \n",
       "1                          0                             0   \n",
       "2                          0                             0   \n",
       "3                          0                             0   \n",
       "4                          0                             0   \n",
       "...                      ...                           ...   \n",
       "23809                      0                             0   \n",
       "23810                      0                             0   \n",
       "23811                      0                             0   \n",
       "23812                      0                             0   \n",
       "23813                      0                             0   \n",
       "\n",
       "       ion_channel_antagonist  ip1_prostacyclin_receptor_agonist  \\\n",
       "0                           0                                  0   \n",
       "1                           0                                  0   \n",
       "2                           0                                  0   \n",
       "3                           0                                  0   \n",
       "4                           0                                  0   \n",
       "...                       ...                                ...   \n",
       "23809                       0                                  0   \n",
       "23810                       0                                  0   \n",
       "23811                       0                                  0   \n",
       "23812                       0                                  0   \n",
       "23813                       0                                  0   \n",
       "\n",
       "       iron_absorption_inhibitor  isocitrate_dehydrogenase_inhibitor  \\\n",
       "0                              0                                   0   \n",
       "1                              0                                   0   \n",
       "2                              0                                   0   \n",
       "3                              0                                   0   \n",
       "4                              0                                   0   \n",
       "...                          ...                                 ...   \n",
       "23809                          0                                   0   \n",
       "23810                          0                                   0   \n",
       "23811                          0                                   0   \n",
       "23812                          0                                   0   \n",
       "23813                          0                                   0   \n",
       "\n",
       "       jnk_inhibitor  kainate_receptor_antagonist  katp_activator  \\\n",
       "0                  0                            0               0   \n",
       "1                  0                            0               0   \n",
       "2                  0                            0               0   \n",
       "3                  0                            0               0   \n",
       "4                  0                            0               0   \n",
       "...              ...                          ...             ...   \n",
       "23809              0                            0               0   \n",
       "23810              0                            0               0   \n",
       "23811              0                            0               0   \n",
       "23812              0                            0               0   \n",
       "23813              0                            0               0   \n",
       "\n",
       "       keap1_ligand  kinesin_inhibitor  l3mbtl_antagonist  \\\n",
       "0                 0                  0                  0   \n",
       "1                 0                  0                  0   \n",
       "2                 0                  0                  0   \n",
       "3                 0                  0                  0   \n",
       "4                 0                  0                  0   \n",
       "...             ...                ...                ...   \n",
       "23809             0                  0                  0   \n",
       "23810             0                  0                  0   \n",
       "23811             0                  0                  0   \n",
       "23812             0                  0                  0   \n",
       "23813             0                  0                  0   \n",
       "\n",
       "       lactamase_inhibitor  lactate_dehydrogenase_inhibitor  \\\n",
       "0                        0                                0   \n",
       "1                        0                                0   \n",
       "2                        0                                0   \n",
       "3                        0                                0   \n",
       "4                        0                                0   \n",
       "...                    ...                              ...   \n",
       "23809                    0                                0   \n",
       "23810                    0                                0   \n",
       "23811                    0                                0   \n",
       "23812                    0                                0   \n",
       "23813                    0                                0   \n",
       "\n",
       "       lanosterol_demethylase_inhibitor  leucyl-trna_synthetase_inhibitor  \\\n",
       "0                                     0                                 0   \n",
       "1                                     0                                 0   \n",
       "2                                     0                                 0   \n",
       "3                                     0                                 0   \n",
       "4                                     0                                 0   \n",
       "...                                 ...                               ...   \n",
       "23809                                 0                                 0   \n",
       "23810                                 0                                 0   \n",
       "23811                                 0                                 0   \n",
       "23812                                 0                                 0   \n",
       "23813                                 0                                 0   \n",
       "\n",
       "       leukocyte_elastase_inhibitor  leukotriene_synthesis_inhibitor  \\\n",
       "0                                 0                                0   \n",
       "1                                 0                                0   \n",
       "2                                 0                                0   \n",
       "3                                 0                                0   \n",
       "4                                 0                                0   \n",
       "...                             ...                              ...   \n",
       "23809                             0                                0   \n",
       "23810                             0                                0   \n",
       "23811                             0                                0   \n",
       "23812                             0                                0   \n",
       "23813                             0                                0   \n",
       "\n",
       "       lim_inhibitor  lipase_clearing_factor_inhibitor  \\\n",
       "0                  0                                 0   \n",
       "1                  0                                 0   \n",
       "2                  0                                 0   \n",
       "3                  0                                 0   \n",
       "4                  0                                 0   \n",
       "...              ...                               ...   \n",
       "23809              0                                 0   \n",
       "23810              0                                 0   \n",
       "23811              0                                 0   \n",
       "23812              0                                 0   \n",
       "23813              0                                 0   \n",
       "\n",
       "       lipid_peroxidase_inhibitor  lipoprotein_lipase_activator  \\\n",
       "0                               0                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             0   \n",
       "...                           ...                           ...   \n",
       "23809                           0                             0   \n",
       "23810                           0                             0   \n",
       "23811                           0                             0   \n",
       "23812                           0                             0   \n",
       "23813                           0                             0   \n",
       "\n",
       "       lrkk2_inhibitor  lymphocyte_inhibitor  \\\n",
       "0                    0                     0   \n",
       "1                    0                     0   \n",
       "2                    0                     0   \n",
       "3                    0                     0   \n",
       "4                    0                     0   \n",
       "...                ...                   ...   \n",
       "23809                0                     0   \n",
       "23810                0                     0   \n",
       "23811                0                     0   \n",
       "23812                0                     0   \n",
       "23813                0                     0   \n",
       "\n",
       "       lysophosphatidic_acid_receptor_antagonist  macrophage_inhibitor  \\\n",
       "0                                              0                     0   \n",
       "1                                              0                     0   \n",
       "2                                              0                     0   \n",
       "3                                              0                     0   \n",
       "4                                              0                     0   \n",
       "...                                          ...                   ...   \n",
       "23809                                          0                     0   \n",
       "23810                                          0                     0   \n",
       "23811                                          0                     0   \n",
       "23812                                          0                     0   \n",
       "23813                                          0                     0   \n",
       "\n",
       "       macrophage_migration_inhibiting_factor_inhibitor  map_k  \\\n",
       "0                                                     0      0   \n",
       "1                                                     0      0   \n",
       "2                                                     0      0   \n",
       "3                                                     0      0   \n",
       "4                                                     0      0   \n",
       "...                                                 ...    ...   \n",
       "23809                                                 0      0   \n",
       "23810                                                 0      0   \n",
       "23811                                                 0      0   \n",
       "23812                                                 0      0   \n",
       "23813                                                 0      0   \n",
       "\n",
       "       map_kinase_inhibitor  matrix_metalloprotease_inhibitor  mcl1_inhibitor  \\\n",
       "0                         0                                 0               0   \n",
       "1                         0                                 0               0   \n",
       "2                         0                                 0               0   \n",
       "3                         0                                 0               0   \n",
       "4                         0                                 0               0   \n",
       "...                     ...                               ...             ...   \n",
       "23809                     0                                 0               0   \n",
       "23810                     0                                 0               0   \n",
       "23811                     0                                 0               0   \n",
       "23812                     0                                 0               0   \n",
       "23813                     0                                 0               0   \n",
       "\n",
       "       melanin_inhibitor  melanocortin_receptor_agonist  \\\n",
       "0                      0                              0   \n",
       "1                      0                              0   \n",
       "2                      0                              0   \n",
       "3                      0                              0   \n",
       "4                      0                              0   \n",
       "...                  ...                            ...   \n",
       "23809                  0                              0   \n",
       "23810                  0                              0   \n",
       "23811                  0                              0   \n",
       "23812                  0                              0   \n",
       "23813                  0                              0   \n",
       "\n",
       "       melatonin_receptor_agonist  membrane_permeability_enhancer  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "2                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "...                           ...                             ...   \n",
       "23809                           0                               0   \n",
       "23810                           0                               0   \n",
       "23811                           0                               0   \n",
       "23812                           0                               0   \n",
       "23813                           0                               0   \n",
       "\n",
       "       membrane_permeability_inhibitor  mer_tyrosine_kinase_inhibitor  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "...                                ...                            ...   \n",
       "23809                                0                              0   \n",
       "23810                                0                              0   \n",
       "23811                                0                              0   \n",
       "23812                                0                              0   \n",
       "23813                                0                              0   \n",
       "\n",
       "       met_inhibitor  metalloproteinase_inhibitor  \\\n",
       "0                  0                            0   \n",
       "1                  0                            0   \n",
       "2                  0                            0   \n",
       "3                  0                            0   \n",
       "4                  0                            0   \n",
       "...              ...                          ...   \n",
       "23809              0                            0   \n",
       "23810              0                            0   \n",
       "23811              0                            0   \n",
       "23812              0                            0   \n",
       "23813              0                            0   \n",
       "\n",
       "       mineralocorticoid_receptor_agonist  mitochondrial_inhibitor  \\\n",
       "0                                       0                        0   \n",
       "1                                       0                        0   \n",
       "2                                       0                        0   \n",
       "3                                       0                        0   \n",
       "4                                       0                        0   \n",
       "...                                   ...                      ...   \n",
       "23809                                   0                        0   \n",
       "23810                                   0                        0   \n",
       "23811                                   0                        0   \n",
       "23812                                   0                        0   \n",
       "23813                                   0                        0   \n",
       "\n",
       "       mitochondrial_na+_ca2+_exchanger_antagonist  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "23809                                            0   \n",
       "23810                                            0   \n",
       "23811                                            0   \n",
       "23812                                            0   \n",
       "23813                                            0   \n",
       "\n",
       "       monocarboxylate_transporter_inhibitor  motilin_receptor_agonist  \\\n",
       "0                                          0                         0   \n",
       "1                                          0                         0   \n",
       "2                                          0                         0   \n",
       "3                                          0                         0   \n",
       "4                                          0                         0   \n",
       "...                                      ...                       ...   \n",
       "23809                                      0                         0   \n",
       "23810                                      0                         0   \n",
       "23811                                      0                         0   \n",
       "23812                                      0                         0   \n",
       "23813                                      0                         0   \n",
       "\n",
       "       mrp_inhibitor  mth1_inhibitor  mucolytic  mucus_protecting_agent  \\\n",
       "0                  0               0          0                       0   \n",
       "1                  0               0          0                       0   \n",
       "2                  0               0          0                       0   \n",
       "3                  0               0          0                       0   \n",
       "4                  0               0          0                       0   \n",
       "...              ...             ...        ...                     ...   \n",
       "23809              0               0          0                       0   \n",
       "23810              0               0          0                       0   \n",
       "23811              0               0          0                       0   \n",
       "23812              0               0          0                       0   \n",
       "23813              0               0          0                       0   \n",
       "\n",
       "       muscle_relaxant  na_k-atpase_inhibitor  nadph_inhibitor  \\\n",
       "0                    0                      0                0   \n",
       "1                    0                      0                0   \n",
       "2                    0                      0                0   \n",
       "3                    0                      0                0   \n",
       "4                    0                      0                0   \n",
       "...                ...                    ...              ...   \n",
       "23809                0                      0                0   \n",
       "23810                0                      0                0   \n",
       "23811                0                      0                0   \n",
       "23812                0                      0                0   \n",
       "23813                0                      0                0   \n",
       "\n",
       "       nampt_inhibitor  neprilysin_inhibitor  neural_stem_cell_inducer  \\\n",
       "0                    0                     0                         0   \n",
       "1                    0                     0                         0   \n",
       "2                    0                     0                         0   \n",
       "3                    0                     0                         0   \n",
       "4                    0                     0                         0   \n",
       "...                ...                   ...                       ...   \n",
       "23809                0                     0                         0   \n",
       "23810                0                     0                         0   \n",
       "23811                0                     0                         0   \n",
       "23812                0                     0                         0   \n",
       "23813                0                     0                         0   \n",
       "\n",
       "       neuraminidase_inhibitor  neurokinin_receptor_antagonist  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "...                        ...                             ...   \n",
       "23809                        0                               0   \n",
       "23810                        0                               0   \n",
       "23811                        0                               0   \n",
       "23812                        0                               0   \n",
       "23813                        0                               0   \n",
       "\n",
       "       neurotensin_receptor_agonist  neurotensin_receptor_antagonist  \\\n",
       "0                                 0                                0   \n",
       "1                                 0                                0   \n",
       "2                                 0                                0   \n",
       "3                                 0                                0   \n",
       "4                                 0                                0   \n",
       "...                             ...                              ...   \n",
       "23809                             0                                0   \n",
       "23810                             0                                0   \n",
       "23811                             0                                0   \n",
       "23812                             0                                0   \n",
       "23813                             0                                0   \n",
       "\n",
       "       neurotransmitter  neurotrophic_agent  nfkb_activator  \\\n",
       "0                     0                   0               0   \n",
       "1                     0                   0               0   \n",
       "2                     0                   0               0   \n",
       "3                     0                   0               0   \n",
       "4                     0                   0               0   \n",
       "...                 ...                 ...             ...   \n",
       "23809                 0                   0               0   \n",
       "23810                 0                   0               0   \n",
       "23811                 0                   0               0   \n",
       "23812                 0                   0               0   \n",
       "23813                 0                   0               0   \n",
       "\n",
       "       niemann-pick_c1-like_1_protein_antagonist  nitric_oxide_scavenger  \\\n",
       "0                                              0                       0   \n",
       "1                                              0                       0   \n",
       "2                                              0                       0   \n",
       "3                                              0                       0   \n",
       "4                                              0                       0   \n",
       "...                                          ...                     ...   \n",
       "23809                                          0                       0   \n",
       "23810                                          0                       0   \n",
       "23811                                          0                       0   \n",
       "23812                                          0                       0   \n",
       "23813                                          0                       0   \n",
       "\n",
       "       nitric_oxide_stimulant  \\\n",
       "0                           0   \n",
       "1                           0   \n",
       "2                           0   \n",
       "3                           0   \n",
       "4                           0   \n",
       "...                       ...   \n",
       "23809                       0   \n",
       "23810                       0   \n",
       "23811                       0   \n",
       "23812                       0   \n",
       "23813                       0   \n",
       "\n",
       "       nociceptin_orphanin_fq_(nop)_receptor_antagonist  \\\n",
       "0                                                     0   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "23809                                                 0   \n",
       "23810                                                 0   \n",
       "23811                                                 0   \n",
       "23812                                                 0   \n",
       "23813                                                 0   \n",
       "\n",
       "       non-nucleoside_reverse_transcriptase_inhibitor  nootropic_agent  \\\n",
       "0                                                   0                0   \n",
       "1                                                   0                0   \n",
       "2                                                   0                0   \n",
       "3                                                   0                0   \n",
       "4                                                   0                0   \n",
       "...                                               ...              ...   \n",
       "23809                                               0                0   \n",
       "23810                                               0                0   \n",
       "23811                                               0                0   \n",
       "23812                                               0                0   \n",
       "23813                                               0                0   \n",
       "\n",
       "       nop_receptor_agonist  noradrenaline_uptake_inhibitor  \\\n",
       "0                         0                               0   \n",
       "1                         0                               0   \n",
       "2                         0                               0   \n",
       "3                         0                               0   \n",
       "4                         0                               0   \n",
       "...                     ...                             ...   \n",
       "23809                     0                               0   \n",
       "23810                     0                               0   \n",
       "23811                     0                               0   \n",
       "23812                     0                               0   \n",
       "23813                     0                               0   \n",
       "\n",
       "       norepinephrine_inhibitor  notch_signaling_inhibitor  ntpdase_inhibitor  \\\n",
       "0                             0                          0                  0   \n",
       "1                             0                          0                  0   \n",
       "2                             0                          0                  0   \n",
       "3                             0                          0                  0   \n",
       "4                             0                          0                  0   \n",
       "...                         ...                        ...                ...   \n",
       "23809                         0                          0                  0   \n",
       "23810                         0                          0                  0   \n",
       "23811                         0                          0                  0   \n",
       "23812                         0                          0                  0   \n",
       "23813                         0                          0                  0   \n",
       "\n",
       "       nucleoside_reverse_transcriptase_inhibitor  oct_activator  \\\n",
       "0                                               0              0   \n",
       "1                                               0              0   \n",
       "2                                               0              0   \n",
       "3                                               0              0   \n",
       "4                                               0              0   \n",
       "...                                           ...            ...   \n",
       "23809                                           0              0   \n",
       "23810                                           0              0   \n",
       "23811                                           0              0   \n",
       "23812                                           0              0   \n",
       "23813                                           0              0   \n",
       "\n",
       "       omega_3_fatty_acid_stimulant  osteoclast_inhibitor  oxidizing_agent  \\\n",
       "0                                 0                     0                0   \n",
       "1                                 0                     0                0   \n",
       "2                                 0                     0                0   \n",
       "3                                 0                     0                0   \n",
       "4                                 0                     0                0   \n",
       "...                             ...                   ...              ...   \n",
       "23809                             0                     0                0   \n",
       "23810                             0                     0                0   \n",
       "23811                             0                     0                0   \n",
       "23812                             0                     0                0   \n",
       "23813                             0                     0                0   \n",
       "\n",
       "       oxidosqualene_cyclase_inhibitor  oxytocin_receptor_agonist  \\\n",
       "0                                    0                          0   \n",
       "1                                    0                          0   \n",
       "2                                    0                          0   \n",
       "3                                    0                          0   \n",
       "4                                    0                          0   \n",
       "...                                ...                        ...   \n",
       "23809                                0                          0   \n",
       "23810                                0                          0   \n",
       "23811                                0                          0   \n",
       "23812                                0                          0   \n",
       "23813                                0                          0   \n",
       "\n",
       "       oxytocin_receptor_antagonist  p21_activated_kinase_inhibitor  \\\n",
       "0                                 0                               0   \n",
       "1                                 0                               0   \n",
       "2                                 0                               0   \n",
       "3                                 0                               0   \n",
       "4                                 0                               0   \n",
       "...                             ...                             ...   \n",
       "23809                             0                               0   \n",
       "23810                             0                               0   \n",
       "23811                             0                               0   \n",
       "23812                             0                               0   \n",
       "23813                             0                               0   \n",
       "\n",
       "       p53_activator  p53_inhibitor  paba_antagonist  pdk1_inhibitor  \\\n",
       "0                  0              0                0               0   \n",
       "1                  0              0                0               0   \n",
       "2                  0              0                0               0   \n",
       "3                  0              0                0               0   \n",
       "4                  0              0                0               0   \n",
       "...              ...            ...              ...             ...   \n",
       "23809              0              0                0               0   \n",
       "23810              0              0                0               0   \n",
       "23811              0              0                0               0   \n",
       "23812              0              0                0               0   \n",
       "23813              0              0                0               0   \n",
       "\n",
       "       penicillin_binding_protein_inhibitor  peptidase_inhibitor  \\\n",
       "0                                         0                    0   \n",
       "1                                         0                    0   \n",
       "2                                         0                    0   \n",
       "3                                         0                    0   \n",
       "4                                         0                    0   \n",
       "...                                     ...                  ...   \n",
       "23809                                     0                    0   \n",
       "23810                                     0                    0   \n",
       "23811                                     0                    0   \n",
       "23812                                     0                    0   \n",
       "23813                                     0                    0   \n",
       "\n",
       "       perk_inhibitor  phosphatase_inhibitor  phosphofructokinase_inhibitor  \\\n",
       "0                   0                      0                              0   \n",
       "1                   0                      0                              0   \n",
       "2                   0                      0                              0   \n",
       "3                   0                      0                              0   \n",
       "4                   0                      0                              0   \n",
       "...               ...                    ...                            ...   \n",
       "23809               0                      0                              0   \n",
       "23810               0                      0                              0   \n",
       "23811               0                      0                              0   \n",
       "23812               0                      0                              0   \n",
       "23813               0                      0                              0   \n",
       "\n",
       "       phospholipase_activator  pim_inhibitor  pka_activator  pka_inhibitor  \\\n",
       "0                            0              0              0              0   \n",
       "1                            0              0              0              0   \n",
       "2                            0              0              0              0   \n",
       "3                            0              0              0              0   \n",
       "4                            0              0              0              0   \n",
       "...                        ...            ...            ...            ...   \n",
       "23809                        0              0              0              0   \n",
       "23810                        0              0              0              0   \n",
       "23811                        0              0              0              0   \n",
       "23812                        0              0              0              0   \n",
       "23813                        0              0              0              0   \n",
       "\n",
       "       plasminogen_activator_inhibitor  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "...                                ...   \n",
       "23809                                0   \n",
       "23810                                0   \n",
       "23811                                0   \n",
       "23812                                0   \n",
       "23813                                0   \n",
       "\n",
       "       platelet_activating_factor_receptor_antagonist  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "...                                               ...   \n",
       "23809                                               0   \n",
       "23810                                               0   \n",
       "23811                                               0   \n",
       "23812                                               0   \n",
       "23813                                               0   \n",
       "\n",
       "       platelet_aggregation_inhibitor  plk_inhibitor  porcupine_inhibitor  \\\n",
       "0                                   0              0                    0   \n",
       "1                                   0              0                    0   \n",
       "2                                   0              0                    0   \n",
       "3                                   0              0                    0   \n",
       "4                                   0              0                    0   \n",
       "...                               ...            ...                  ...   \n",
       "23809                               0              0                    0   \n",
       "23810                               0              0                    0   \n",
       "23811                               0              0                    0   \n",
       "23812                               0              0                    0   \n",
       "23813                               0              0                    0   \n",
       "\n",
       "       potassium_channel_agonist  potassium_channel_blocker  prmt_inhibitor  \\\n",
       "0                              0                          0               0   \n",
       "1                              0                          0               0   \n",
       "2                              0                          0               0   \n",
       "3                              0                          0               0   \n",
       "4                              0                          0               0   \n",
       "...                          ...                        ...             ...   \n",
       "23809                          0                          0               0   \n",
       "23810                          0                          0               0   \n",
       "23811                          0                          0               0   \n",
       "23812                          0                          0               0   \n",
       "23813                          0                          0               0   \n",
       "\n",
       "       progestogen_hormone  prolactin_inhibitor  prostacyclin_analog  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    0                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "23809                    0                    0                    0   \n",
       "23810                    0                    0                    0   \n",
       "23811                    0                    0                    0   \n",
       "23812                    0                    0                    0   \n",
       "23813                    0                    0                    0   \n",
       "\n",
       "       prostanoid_receptor_agonist  prostanoid_receptor_inhibitor  \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "...                            ...                            ...   \n",
       "23809                            0                              0   \n",
       "23810                            0                              0   \n",
       "23811                            0                              0   \n",
       "23812                            0                              0   \n",
       "23813                            0                              0   \n",
       "\n",
       "       protease_inhibitor  protein_kinase_activator  \\\n",
       "0                       0                         0   \n",
       "1                       0                         0   \n",
       "2                       0                         0   \n",
       "3                       0                         0   \n",
       "4                       0                         0   \n",
       "...                   ...                       ...   \n",
       "23809                   0                         0   \n",
       "23810                   0                         0   \n",
       "23811                   0                         0   \n",
       "23812                   0                         0   \n",
       "23813                   0                         0   \n",
       "\n",
       "       protein_synthesis_stimulant  psychoactive_drug  purine_antagonist  \\\n",
       "0                                0                  0                  0   \n",
       "1                                0                  0                  0   \n",
       "2                                0                  0                  0   \n",
       "3                                0                  0                  0   \n",
       "4                                0                  0                  0   \n",
       "...                            ...                ...                ...   \n",
       "23809                            0                  0                  0   \n",
       "23810                            0                  0                  0   \n",
       "23811                            0                  0                  0   \n",
       "23812                            0                  0                  0   \n",
       "23813                            0                  0                  0   \n",
       "\n",
       "       purinergic_receptor_antagonist  pxr_ligand  \\\n",
       "0                                   0           0   \n",
       "1                                   0           0   \n",
       "2                                   0           0   \n",
       "3                                   0           0   \n",
       "4                                   0           0   \n",
       "...                               ...         ...   \n",
       "23809                               0           0   \n",
       "23810                               0           0   \n",
       "23811                               0           0   \n",
       "23812                               0           0   \n",
       "23813                               0           0   \n",
       "\n",
       "       pyruvate_dehydrogenase_inhibitor  pyruvate_kinase_isozyme_activator  \\\n",
       "0                                     0                                  0   \n",
       "1                                     0                                  0   \n",
       "2                                     0                                  0   \n",
       "3                                     0                                  0   \n",
       "4                                     0                                  0   \n",
       "...                                 ...                                ...   \n",
       "23809                                 0                                  0   \n",
       "23810                                 0                                  0   \n",
       "23811                                 0                                  0   \n",
       "23812                                 0                                  0   \n",
       "23813                                 0                                  0   \n",
       "\n",
       "       quorum_sensing_signaling_modulator  rad51_inhibitor  \\\n",
       "0                                       0                0   \n",
       "1                                       0                0   \n",
       "2                                       0                0   \n",
       "3                                       0                0   \n",
       "4                                       0                0   \n",
       "...                                   ...              ...   \n",
       "23809                                   0                0   \n",
       "23810                                   0                0   \n",
       "23811                                   0                0   \n",
       "23812                                   0                0   \n",
       "23813                                   0                0   \n",
       "\n",
       "       rage_receptor_antagonist  receptor_tyrosine_protein_kinase_inhibitor  \\\n",
       "0                             0                                           0   \n",
       "1                             0                                           0   \n",
       "2                             0                                           0   \n",
       "3                             0                                           0   \n",
       "4                             0                                           0   \n",
       "...                         ...                                         ...   \n",
       "23809                         0                                           0   \n",
       "23810                         0                                           0   \n",
       "23811                         0                                           0   \n",
       "23812                         0                                           0   \n",
       "23813                         0                                           0   \n",
       "\n",
       "       reducing_agent  ret_inhibitor  ret_tyrosine_kinase_inhibitor  \\\n",
       "0                   0              0                              0   \n",
       "1                   0              0                              0   \n",
       "2                   0              0                              0   \n",
       "3                   0              0                              0   \n",
       "4                   0              0                              0   \n",
       "...               ...            ...                            ...   \n",
       "23809               0              0                              0   \n",
       "23810               0              0                              0   \n",
       "23811               0              0                              0   \n",
       "23812               0              0                              0   \n",
       "23813               0              0                              0   \n",
       "\n",
       "       reverse_transcriptase_inhibitor  ribosomal_protein_inhibitor  \\\n",
       "0                                    0                            0   \n",
       "1                                    0                            0   \n",
       "2                                    0                            0   \n",
       "3                                    0                            0   \n",
       "4                                    0                            0   \n",
       "...                                ...                          ...   \n",
       "23809                                0                            0   \n",
       "23810                                0                            0   \n",
       "23811                                0                            0   \n",
       "23812                                0                            0   \n",
       "23813                                0                            0   \n",
       "\n",
       "       ripk_inhibitor  rna_synthesis_inhibitor  ror_inverse_agonist  \\\n",
       "0                   0                        0                    0   \n",
       "1                   0                        0                    0   \n",
       "2                   0                        0                    0   \n",
       "3                   0                        0                    0   \n",
       "4                   0                        0                    0   \n",
       "...               ...                      ...                  ...   \n",
       "23809               0                        0                    0   \n",
       "23810               0                        0                    0   \n",
       "23811               0                        0                    0   \n",
       "23812               0                        0                    0   \n",
       "23813               0                        0                    0   \n",
       "\n",
       "       rsv_fusion_inhibitor  s100a9_inhibitor  \\\n",
       "0                         0                 0   \n",
       "1                         0                 0   \n",
       "2                         0                 0   \n",
       "3                         0                 0   \n",
       "4                         0                 0   \n",
       "...                     ...               ...   \n",
       "23809                     0                 0   \n",
       "23810                     0                 0   \n",
       "23811                     0                 0   \n",
       "23812                     0                 0   \n",
       "23813                     0                 0   \n",
       "\n",
       "       sars_coronavirus_3c-like_protease_inhibitor  sedative  \\\n",
       "0                                                0         0   \n",
       "1                                                0         0   \n",
       "2                                                0         0   \n",
       "3                                                0         0   \n",
       "4                                                0         0   \n",
       "...                                            ...       ...   \n",
       "23809                                            0         0   \n",
       "23810                                            0         0   \n",
       "23811                                            0         0   \n",
       "23812                                            0         0   \n",
       "23813                                            0         0   \n",
       "\n",
       "       selective_estrogen_receptor_modulator_(serm)  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "...                                             ...   \n",
       "23809                                             0   \n",
       "23810                                             0   \n",
       "23811                                             0   \n",
       "23812                                             0   \n",
       "23813                                             0   \n",
       "\n",
       "       selective_serotonin_reuptake_inhibitor_(ssri)  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "...                                              ...   \n",
       "23809                                              0   \n",
       "23810                                              0   \n",
       "23811                                              0   \n",
       "23812                                              0   \n",
       "23813                                              0   \n",
       "\n",
       "       serine_protease_inhibitor  serine_threonine_kinase_inhibitor  \\\n",
       "0                              0                                  0   \n",
       "1                              0                                  0   \n",
       "2                              0                                  0   \n",
       "3                              0                                  0   \n",
       "4                              0                                  0   \n",
       "...                          ...                                ...   \n",
       "23809                          0                                  0   \n",
       "23810                          0                                  0   \n",
       "23811                          0                                  0   \n",
       "23812                          0                                  0   \n",
       "23813                          0                                  0   \n",
       "\n",
       "       serine_threonine_protein_phosphatase_activator  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "...                                               ...   \n",
       "23809                                               0   \n",
       "23810                                               0   \n",
       "23811                                               0   \n",
       "23812                                               0   \n",
       "23813                                               0   \n",
       "\n",
       "       serotonin_release_inhibitor  sirt_activator  sirt_inhibitor  \\\n",
       "0                                0               0               0   \n",
       "1                                0               0               0   \n",
       "2                                0               0               0   \n",
       "3                                0               0               0   \n",
       "4                                0               0               0   \n",
       "...                            ...             ...             ...   \n",
       "23809                            0               0               0   \n",
       "23810                            0               0               0   \n",
       "23811                            0               0               0   \n",
       "23812                            0               0               0   \n",
       "23813                            0               0               0   \n",
       "\n",
       "       smoothened_receptor_agonist  sodium_calcium_exchange_inhibitor  \\\n",
       "0                                0                                  0   \n",
       "1                                0                                  0   \n",
       "2                                0                                  0   \n",
       "3                                0                                  0   \n",
       "4                                0                                  0   \n",
       "...                            ...                                ...   \n",
       "23809                            0                                  0   \n",
       "23810                            0                                  0   \n",
       "23811                            0                                  0   \n",
       "23812                            0                                  0   \n",
       "23813                            0                                  0   \n",
       "\n",
       "       sodium_channel_activator  sodium_channel_blocker  \\\n",
       "0                             0                       0   \n",
       "1                             0                       0   \n",
       "2                             0                       0   \n",
       "3                             0                       0   \n",
       "4                             0                       0   \n",
       "...                         ...                     ...   \n",
       "23809                         0                       0   \n",
       "23810                         0                       0   \n",
       "23811                         0                       0   \n",
       "23812                         0                       0   \n",
       "23813                         0                       0   \n",
       "\n",
       "       somatostatin_receptor_agonist  \\\n",
       "0                                  0   \n",
       "1                                  0   \n",
       "2                                  0   \n",
       "3                                  0   \n",
       "4                                  0   \n",
       "...                              ...   \n",
       "23809                              0   \n",
       "23810                              0   \n",
       "23811                              0   \n",
       "23812                              0   \n",
       "23813                              0   \n",
       "\n",
       "       sphingosine_1_phosphate_receptor_agonist  sphingosine_kinase_inhibitor  \\\n",
       "0                                             0                             0   \n",
       "1                                             0                             0   \n",
       "2                                             0                             0   \n",
       "3                                             0                             0   \n",
       "4                                             0                             0   \n",
       "...                                         ...                           ...   \n",
       "23809                                         0                             0   \n",
       "23810                                         0                             0   \n",
       "23811                                         0                             0   \n",
       "23812                                         0                             0   \n",
       "23813                                         0                             0   \n",
       "\n",
       "       src_activator  srebp_inhibitor  stat_inhibitor  \\\n",
       "0                  0                0               0   \n",
       "1                  0                0               0   \n",
       "2                  0                0               0   \n",
       "3                  0                0               0   \n",
       "4                  0                0               0   \n",
       "...              ...              ...             ...   \n",
       "23809              0                0               0   \n",
       "23810              0                0               0   \n",
       "23811              0                0               0   \n",
       "23812              0                0               0   \n",
       "23813              0                0               0   \n",
       "\n",
       "       stearoyl-coa_desaturase_inhibitor  steroid_sulfatase_inhibitor  \\\n",
       "0                                      0                            0   \n",
       "1                                      0                            0   \n",
       "2                                      0                            0   \n",
       "3                                      0                            0   \n",
       "4                                      0                            0   \n",
       "...                                  ...                          ...   \n",
       "23809                                  0                            0   \n",
       "23810                                  0                            0   \n",
       "23811                                  0                            0   \n",
       "23812                                  0                            0   \n",
       "23813                                  0                            0   \n",
       "\n",
       "       steroidal_progestin  sterol_demethylase_inhibitor  \\\n",
       "0                        0                             0   \n",
       "1                        0                             0   \n",
       "2                        0                             0   \n",
       "3                        0                             0   \n",
       "4                        0                             0   \n",
       "...                    ...                           ...   \n",
       "23809                    0                             0   \n",
       "23810                    0                             0   \n",
       "23811                    0                             0   \n",
       "23812                    0                             0   \n",
       "23813                    0                             0   \n",
       "\n",
       "       sterol_regulatory_element_binding_protein_(srebp)_inhibitor  \\\n",
       "0                                                      0             \n",
       "1                                                      0             \n",
       "2                                                      0             \n",
       "3                                                      0             \n",
       "4                                                      0             \n",
       "...                                                  ...             \n",
       "23809                                                  0             \n",
       "23810                                                  0             \n",
       "23811                                                  0             \n",
       "23812                                                  0             \n",
       "23813                                                  0             \n",
       "\n",
       "       steryl_sulfatase_inhibitor  structural_glycoprotein_antagonist  \\\n",
       "0                               0                                   0   \n",
       "1                               0                                   0   \n",
       "2                               0                                   0   \n",
       "3                               0                                   0   \n",
       "4                               0                                   0   \n",
       "...                           ...                                 ...   \n",
       "23809                           0                                   0   \n",
       "23810                           0                                   0   \n",
       "23811                           0                                   0   \n",
       "23812                           0                                   0   \n",
       "23813                           0                                   0   \n",
       "\n",
       "       succinimide_antiepileptic  sulfonylurea  synthetic_estrogen  \\\n",
       "0                              0             0                   0   \n",
       "1                              0             0                   0   \n",
       "2                              0             0                   0   \n",
       "3                              0             0                   0   \n",
       "4                              0             0                   0   \n",
       "...                          ...           ...                 ...   \n",
       "23809                          0             0                   0   \n",
       "23810                          0             0                   0   \n",
       "23811                          0             0                   0   \n",
       "23812                          0             0                   0   \n",
       "23813                          0             0                   0   \n",
       "\n",
       "       t_cell_inhibitor  tankyrase_inhibitor  telomerase_inhibitor  \\\n",
       "0                     0                    0                     0   \n",
       "1                     0                    0                     0   \n",
       "2                     0                    0                     0   \n",
       "3                     0                    0                     0   \n",
       "4                     0                    0                     0   \n",
       "...                 ...                  ...                   ...   \n",
       "23809                 0                    0                     0   \n",
       "23810                 0                    0                     0   \n",
       "23811                 0                    0                     0   \n",
       "23812                 0                    0                     0   \n",
       "23813                 0                    0                     0   \n",
       "\n",
       "       testosterone_receptor_antagonist  thiazide_diuretic  \\\n",
       "0                                     0                  0   \n",
       "1                                     0                  0   \n",
       "2                                     0                  0   \n",
       "3                                     0                  0   \n",
       "4                                     0                  0   \n",
       "...                                 ...                ...   \n",
       "23809                                 0                  0   \n",
       "23810                                 0                  0   \n",
       "23811                                 0                  0   \n",
       "23812                                 0                  0   \n",
       "23813                                 0                  0   \n",
       "\n",
       "       thioredoxin_inhibitor  thrombopoietin_receptor_agonist  \\\n",
       "0                          0                                0   \n",
       "1                          0                                0   \n",
       "2                          0                                0   \n",
       "3                          0                                0   \n",
       "4                          0                                0   \n",
       "...                      ...                              ...   \n",
       "23809                      0                                0   \n",
       "23810                      0                                0   \n",
       "23811                      0                                0   \n",
       "23812                      0                                0   \n",
       "23813                      0                                0   \n",
       "\n",
       "       thromboxane_receptor_antagonist  thromboxane_synthase_inhibitor  \\\n",
       "0                                    0                               0   \n",
       "1                                    0                               0   \n",
       "2                                    0                               0   \n",
       "3                                    0                               0   \n",
       "4                                    0                               0   \n",
       "...                                ...                             ...   \n",
       "23809                                0                               0   \n",
       "23810                                0                               0   \n",
       "23811                                0                               0   \n",
       "23812                                0                               0   \n",
       "23813                                0                               0   \n",
       "\n",
       "       thyroid_hormone_inhibitor  thyroid_hormone_stimulant  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "...                          ...                        ...   \n",
       "23809                          0                          0   \n",
       "23810                          0                          0   \n",
       "23811                          0                          0   \n",
       "23812                          0                          0   \n",
       "23813                          0                          0   \n",
       "\n",
       "       thyrotropin_releasing_hormone_receptor_agonist  tie_inhibitor  \\\n",
       "0                                                   0              0   \n",
       "1                                                   0              0   \n",
       "2                                                   0              0   \n",
       "3                                                   0              0   \n",
       "4                                                   0              0   \n",
       "...                                               ...            ...   \n",
       "23809                                               0              0   \n",
       "23810                                               0              0   \n",
       "23811                                               0              0   \n",
       "23812                                               0              0   \n",
       "23813                                               0              0   \n",
       "\n",
       "       tissue_transglutaminase_inhibitor  topical_anesthetic  \\\n",
       "0                                      0                   0   \n",
       "1                                      0                   0   \n",
       "2                                      0                   0   \n",
       "3                                      0                   0   \n",
       "4                                      0                   0   \n",
       "...                                  ...                 ...   \n",
       "23809                                  0                   0   \n",
       "23810                                  0                   0   \n",
       "23811                                  0                   0   \n",
       "23812                                  0                   0   \n",
       "23813                                  0                   0   \n",
       "\n",
       "       topical_sunscreen_agent  trace_amine_associated_receptor_agonist  \\\n",
       "0                            0                                        0   \n",
       "1                            0                                        0   \n",
       "2                            0                                        0   \n",
       "3                            0                                        0   \n",
       "4                            0                                        0   \n",
       "...                        ...                                      ...   \n",
       "23809                        0                                        0   \n",
       "23810                        0                                        0   \n",
       "23811                        0                                        0   \n",
       "23812                        0                                        0   \n",
       "23813                        0                                        0   \n",
       "\n",
       "       trace_amine_associated_receptor_antagonist  trail_modulator  \\\n",
       "0                                               0                0   \n",
       "1                                               0                0   \n",
       "2                                               0                0   \n",
       "3                                               0                0   \n",
       "4                                               0                0   \n",
       "...                                           ...              ...   \n",
       "23809                                           0                0   \n",
       "23810                                           0                0   \n",
       "23811                                           0                0   \n",
       "23812                                           0                0   \n",
       "23813                                           0                0   \n",
       "\n",
       "       transient_receptor_potential_channel_agonist  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "...                                             ...   \n",
       "23809                                             0   \n",
       "23810                                             0   \n",
       "23811                                             0   \n",
       "23812                                             0   \n",
       "23813                                             0   \n",
       "\n",
       "       triacylglycerol_lipase_inhibitor  tricyclic_antidepressant  \\\n",
       "0                                     0                         0   \n",
       "1                                     0                         0   \n",
       "2                                     0                         0   \n",
       "3                                     0                         0   \n",
       "4                                     0                         0   \n",
       "...                                 ...                       ...   \n",
       "23809                                 0                         0   \n",
       "23810                                 0                         0   \n",
       "23811                                 0                         0   \n",
       "23812                                 0                         0   \n",
       "23813                                 0                         0   \n",
       "\n",
       "       tryptophan_hydroxylase_inhibitor  tyrosinase_inhibitor  \\\n",
       "0                                     0                     0   \n",
       "1                                     0                     0   \n",
       "2                                     0                     0   \n",
       "3                                     0                     0   \n",
       "4                                     0                     0   \n",
       "...                                 ...                   ...   \n",
       "23809                                 0                     0   \n",
       "23810                                 0                     0   \n",
       "23811                                 0                     0   \n",
       "23812                                 0                     0   \n",
       "23813                                 0                     0   \n",
       "\n",
       "       tyrosine_hydroxylase_inhibitor  tyrosine_phosphatase_inhibitor  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "...                               ...                             ...   \n",
       "23809                               0                               0   \n",
       "23810                               0                               0   \n",
       "23811                               0                               0   \n",
       "23812                               0                               0   \n",
       "23813                               0                               0   \n",
       "\n",
       "       ubiquitin-conjugating_enzyme_inhibitor  ubiquitin_ligase_inhibitor  \\\n",
       "0                                           0                           0   \n",
       "1                                           0                           0   \n",
       "2                                           0                           0   \n",
       "3                                           0                           0   \n",
       "4                                           0                           0   \n",
       "...                                       ...                         ...   \n",
       "23809                                       0                           0   \n",
       "23810                                       0                           0   \n",
       "23811                                       0                           0   \n",
       "23812                                       0                           0   \n",
       "23813                                       0                           0   \n",
       "\n",
       "       urease_inhibitor  uric_acid_diuretic  uricase_inhibitor  uricosuric  \\\n",
       "0                     0                   0                  0           0   \n",
       "1                     0                   0                  0           0   \n",
       "2                     0                   0                  0           0   \n",
       "3                     0                   0                  0           0   \n",
       "4                     0                   0                  0           0   \n",
       "...                 ...                 ...                ...         ...   \n",
       "23809                 0                   0                  0           0   \n",
       "23810                 0                   0                  0           0   \n",
       "23811                 0                   0                  0           0   \n",
       "23812                 0                   0                  0           0   \n",
       "23813                 0                   0                  0           0   \n",
       "\n",
       "       urotensin_receptor_agonist  urotensin_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       vasoconstrictor  vasodilator  vasopressin_receptor_agonist  \\\n",
       "0                    0            0                             0   \n",
       "1                    0            0                             0   \n",
       "2                    0            0                             0   \n",
       "3                    0            0                             0   \n",
       "4                    0            0                             0   \n",
       "...                ...          ...                           ...   \n",
       "23809                0            0                             0   \n",
       "23810                0            0                             0   \n",
       "23811                0            0                             0   \n",
       "23812                0            0                             0   \n",
       "23813                0            0                             0   \n",
       "\n",
       "       vasopressin_receptor_antagonist  ve-cadherin_antagonist  \\\n",
       "0                                    0                       0   \n",
       "1                                    0                       0   \n",
       "2                                    0                       0   \n",
       "3                                    0                       0   \n",
       "4                                    0                       0   \n",
       "...                                ...                     ...   \n",
       "23809                                0                       0   \n",
       "23810                                0                       0   \n",
       "23811                                0                       0   \n",
       "23812                                0                       0   \n",
       "23813                                0                       0   \n",
       "\n",
       "       vesicular_monoamine_transporter_inhibitor  vitamin_k_antagonist  \\\n",
       "0                                              0                     0   \n",
       "1                                              0                     0   \n",
       "2                                              0                     0   \n",
       "3                                              0                     0   \n",
       "4                                              0                     0   \n",
       "...                                          ...                   ...   \n",
       "23809                                          0                     0   \n",
       "23810                                          0                     0   \n",
       "23811                                          0                     0   \n",
       "23812                                          0                     0   \n",
       "23813                                          0                     0   \n",
       "\n",
       "       voltage-gated_calcium_channel_ligand  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "23809                                     0   \n",
       "23810                                     0   \n",
       "23811                                     0   \n",
       "23812                                     0   \n",
       "23813                                     0   \n",
       "\n",
       "       voltage-gated_potassium_channel_activator  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "23809                                          0   \n",
       "23810                                          0   \n",
       "23811                                          0   \n",
       "23812                                          0   \n",
       "23813                                          0   \n",
       "\n",
       "       voltage-gated_sodium_channel_blocker  wdr5_mll_interaction_inhibitor  \\\n",
       "0                                         0                               0   \n",
       "1                                         0                               0   \n",
       "2                                         0                               0   \n",
       "3                                         0                               0   \n",
       "4                                         0                               0   \n",
       "...                                     ...                             ...   \n",
       "23809                                     0                               0   \n",
       "23810                                     0                               0   \n",
       "23811                                     0                               0   \n",
       "23812                                     0                               0   \n",
       "23813                                     0                               0   \n",
       "\n",
       "       wnt_agonist  xanthine_oxidase_inhibitor  xiap_inhibitor  \n",
       "0                0                           0               0  \n",
       "1                0                           0               0  \n",
       "2                0                           0               0  \n",
       "3                0                           0               0  \n",
       "4                0                           0               0  \n",
       "...            ...                         ...             ...  \n",
       "23809            0                           0               0  \n",
       "23810            0                           0               0  \n",
       "23811            0                           0               0  \n",
       "23812            0                           0               0  \n",
       "23813            0                           0               0  \n",
       "\n",
       "[23814 rows x 402 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_nonscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:57.635400Z",
     "start_time": "2020-11-06T01:11:57.513726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cp_time', 'cp_dose', 'g-0', 'g-1', 'g-2', 'g-3', 'g-4', 'g-5', 'g-6',\n",
       "       'g-7',\n",
       "       ...\n",
       "       'c-90', 'c-91', 'c-92', 'c-93', 'c-94', 'c-95', 'c-96', 'c-97', 'c-98',\n",
       "       'c-99'],\n",
       "      dtype='object', length=874)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:57.766051Z",
     "start_time": "2020-11-06T01:11:57.635400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 10:11:57] - ### HONBAN: FOLDS:5, EPOCHS:80 ###\n"
     ]
    }
   ],
   "source": [
    "logger = util.Logger(\"./\")\n",
    "# デバッグ用にデータ減らすか\n",
    "DEBUG = False\n",
    "#DEBUG = True\n",
    "if DEBUG:\n",
    "    mlp_tf.FOLDS = 2  # cvの数\n",
    "    mlp_tf.EPOCHS = 2\n",
    "    logger.info(f\"### DEBUG: FOLDS:{mlp_tf.FOLDS}, EPOCHS:{mlp_tf.EPOCHS} ###\")\n",
    "else:\n",
    "    logger.info(f\"### HONBAN: FOLDS:{mlp_tf.FOLDS}, EPOCHS:{mlp_tf.EPOCHS} ###\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T13:57:27.407786Z",
     "start_time": "2020-11-05T13:55:14.661365Z"
    },
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01676109207541012\n",
      "Our out of folds log loss for our seed blend model is 0.01676109207541012\n",
      "Using model rs with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01676109207541012\n",
      "Our out of folds log loss for our seed blend model is 0.01676109207541012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00169588, 0.00301255, 0.00215034, ..., 0.00222579, 0.00925308,\n",
       "         0.00209847],\n",
       "        [0.0005218 , 0.00137913, 0.00165742, ..., 0.00175286, 0.00656317,\n",
       "         0.00177591],\n",
       "        [0.00077693, 0.0006134 , 0.00176651, ..., 0.0020643 , 0.00273696,\n",
       "         0.00478974],\n",
       "        ...,\n",
       "        [0.00195807, 0.00146734, 0.00178714, ..., 0.00204957, 0.00109019,\n",
       "         0.00175179],\n",
       "        [0.00252073, 0.00152682, 0.00280283, ..., 0.0023976 , 0.00094649,\n",
       "         0.00412406],\n",
       "        [0.00153159, 0.00166212, 0.00198604, ..., 0.00209821, 0.00152105,\n",
       "         0.00184435]]),\n",
       " array([[1.25059416e-03, 2.20698258e-03, 1.21258327e-03, ...,\n",
       "         9.98972915e-04, 7.55606510e-04, 4.94353892e-03],\n",
       "        [6.50121691e-03, 3.05776577e-03, 2.63947388e-03, ...,\n",
       "         2.59770895e-03, 9.03046783e-03, 5.95065486e-03],\n",
       "        [3.74499732e-03, 2.58676708e-03, 1.75386970e-03, ...,\n",
       "         2.30530417e-03, 1.51384482e-03, 1.12211134e-03],\n",
       "        ...,\n",
       "        [1.22588500e-03, 1.47365592e-03, 1.10387499e-03, ...,\n",
       "         1.09314185e-03, 1.06045359e-03, 2.04163557e-03],\n",
       "        [1.03052240e-03, 2.64294562e-04, 7.26269645e-05, ...,\n",
       "         3.98208533e-04, 1.17532210e-03, 7.62961048e-04],\n",
       "        [1.17659906e-03, 1.86436879e-03, 2.20095390e-03, ...,\n",
       "         7.03354192e-04, 2.74975249e-03, 6.56062621e-04]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1モデルだけで学習推論できるかテスト\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "\n",
    "mlp_tf.train_and_evaluate(\n",
    "    train, test, train_targets, features, train_targets_nonscored, model_type=\"rs\"\n",
    ")\n",
    "mlp_tf.inference(\n",
    "    train, test, train_targets, features, train_targets_nonscored, model_type=\"rs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T14:41:41.104119Z",
     "start_time": "2020-11-05T14:05:18.539349Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model lr with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.020149788824180583\n",
      "Our out of folds log loss for our seed blend model is 0.020149788824180583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:07:07] - model_type:lr, oof:0.0201498, train_flag:train\n",
      "lr\tno feature_eng\t0.0201498\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:19<00:00, 51.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016409830757263502\n",
      "Our out of folds log loss for our seed blend model is 0.016409830757263502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:11:39] - model_type:2l, oof:0.0164098, train_flag:train\n",
      "2l\tno feature_eng\t0.0164098\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:00<00:00, 48.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016449730541036704\n",
      "Our out of folds log loss for our seed blend model is 0.016449730541036704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:15:51] - model_type:3l, oof:0.0164497, train_flag:train\n",
      "3l\tno feature_eng\t0.0164497\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:15<00:00, 27.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01642539954049959\n",
      "Our out of folds log loss for our seed blend model is 0.01642539954049959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:18:19] - model_type:4l, oof:0.0164254, train_flag:train\n",
      "4l\tno feature_eng\t0.0164254\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:59<00:00, 59.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0164320954918053\n",
      "Our out of folds log loss for our seed blend model is 0.0164320954918053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:23:31] - model_type:5l, oof:0.0164321, train_flag:train\n",
      "5l\tno feature_eng\t0.0164321\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:38<00:00, 19.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01674007202793243\n",
      "Our out of folds log loss for our seed blend model is 0.01674007202793243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:25:21] - model_type:rs, oof:0.0167401, train_flag:train\n",
      "rs\tno feature_eng\t0.0167401\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:51<03:26, 51.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:39<02:31, 50.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:24<01:37, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:10<00:48, 48.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:01<00:00, 48.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016570669012127278\n",
      "Our out of folds log loss for our seed blend model is 0.016570669012127278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:29:35] - model_type:3l_v2, oof:0.0165707, train_flag:train\n",
      "3l_v2\tno feature_eng\t0.0165707\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3lWN with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:17<00:00, 27.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.018712745063721472\n",
      "Our out of folds log loss for our seed blend model is 0.018712745063721472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:32:04] - model_type:3lWN, oof:0.0187127, train_flag:train\n",
      "3lWN\tno feature_eng\t0.0187127\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:37<02:29, 37.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:15<01:53, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:52<01:14, 37.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:31<00:37, 37.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:08<00:00, 37.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017072668200538203\n",
      "Our out of folds log loss for our seed blend model is 0.017072668200538203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:35:25] - model_type:stack_tabnet, oof:0.0170727, train_flag:train\n",
      "stack_tabnet\tno feature_eng\t0.0170727\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:20<01:20, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:41<01:02, 20.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:05<00:42, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:28<00:22, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:51<00:00, 22.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016926636221588593\n",
      "Our out of folds log loss for our seed blend model is 0.016926636221588593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:37:28] - model_type:tabnet_class, oof:0.0169266, train_flag:train\n",
      "tabnet_class\tno feature_eng\t0.0169266\ttrain\n",
      "[2020-11-05 23:37:32] - model_type:lr-2l-3l-4l-5l-rs-3l_v2-3lWN-stack_tabnet-tabnet_class, oof:0.0207735, train_flag:train\n",
      "lr-2l-3l-4l-5l-rs-3l_v2-3lWN-stack_tabnet-tabnet_class\tno feature_eng:Mean blend\t0.0207735\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model lr with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.020149788824180583\n",
      "Our out of folds log loss for our seed blend model is 0.020149788824180583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:37:49] - model_type:lr, oof:0.0201498, train_flag:inference\n",
      "lr\tno feature_eng\t0.0201498\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 2l with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016409830757263502\n",
      "Our out of folds log loss for our seed blend model is 0.016409830757263502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:38:09] - model_type:2l, oof:0.0164098, train_flag:inference\n",
      "2l\tno feature_eng\t0.0164098\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 3l with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016449730541036704\n",
      "Our out of folds log loss for our seed blend model is 0.016449730541036704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:38:29] - model_type:3l, oof:0.0164497, train_flag:inference\n",
      "3l\tno feature_eng\t0.0164497\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 4l with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01642539954049959\n",
      "Our out of folds log loss for our seed blend model is 0.01642539954049959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:38:47] - model_type:4l, oof:0.0164254, train_flag:inference\n",
      "4l\tno feature_eng\t0.0164254\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 5l with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:05<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0164320954918053\n",
      "Our out of folds log loss for our seed blend model is 0.0164320954918053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:39:04] - model_type:5l, oof:0.0164321, train_flag:inference\n",
      "5l\tno feature_eng\t0.0164321\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model rs with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:06<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01674007202793243\n",
      "Our out of folds log loss for our seed blend model is 0.01674007202793243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:39:23] - model_type:rs, oof:0.0167401, train_flag:inference\n",
      "rs\tno feature_eng\t0.0167401\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 3l_v2 with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:01<00:06,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:03<00:05,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [00:05<00:03,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [00:06<00:01,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016570669012127278\n",
      "Our out of folds log loss for our seed blend model is 0.016570669012127278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:39:44] - model_type:3l_v2, oof:0.0165707, train_flag:inference\n",
      "3l_v2\tno feature_eng\t0.0165707\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 3lWN with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:07<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.018712745063721472\n",
      "Our out of folds log loss for our seed blend model is 0.018712745063721472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:40:04] - model_type:3lWN, oof:0.0187127, train_flag:inference\n",
      "3lWN\tno feature_eng\t0.0187127\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model stack_tabnet with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:08<00:33,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:16<00:25,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [00:25<00:16,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [00:34<00:08,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:42<00:00,  8.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017072668200538203\n",
      "Our out of folds log loss for our seed blend model is 0.017072668200538203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:40:59] - model_type:stack_tabnet, oof:0.0170727, train_flag:inference\n",
      "stack_tabnet\tno feature_eng\t0.0170727\tinference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model tabnet_class with seed 123 for inference\n",
      "Trained with 874 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:04<00:19,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:09<00:14,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [00:14<00:09,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [00:19<00:04,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:24<00:00,  4.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016926636221588593\n",
      "Our out of folds log loss for our seed blend model is 0.016926636221588593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:41:35] - model_type:tabnet_class, oof:0.0169266, train_flag:inference\n",
      "tabnet_class\tno feature_eng\t0.0169266\tinference\n",
      "[2020-11-05 23:41:39] - model_type:lr-2l-3l-4l-5l-rs-3l_v2-3lWN-stack_tabnet-tabnet_class, oof:0.0207735, train_flag:inference\n",
      "lr-2l-3l-4l-5l-rs-3l_v2-3lWN-stack_tabnet-tabnet_class\tno feature_eng:Mean blend\t0.0207735\tinference\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"no feature_eng\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "# モデルブレンドの学習実行できるかテスト\n",
    "mlp_tf.run_mlp_tf_blend_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "# モデルブレンドの推論実行できるかテスト\n",
    "mlp_tf.run_mlp_tf_blend_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    str_condition=str_condition,\n",
    "    is_train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## best FE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T15:17:41.992503Z",
     "start_time": "2020-11-05T14:41:41.105091Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model lr with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:50<00:00, 34.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.018652729418941142\n",
      "Our out of folds log loss for our seed blend model is 0.018652729418941142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:45:38] - model_type:lr, oof:0.0186527, train_flag:train\n",
      "lr\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0186527\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:08<00:00, 61.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016322946670649815\n",
      "Our out of folds log loss for our seed blend model is 0.016322946670649815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:50:58] - model_type:2l, oof:0.0163229, train_flag:train\n",
      "2l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0163229\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:04<00:00, 48.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01637299906417296\n",
      "Our out of folds log loss for our seed blend model is 0.01637299906417296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:55:16] - model_type:3l, oof:0.016373, train_flag:train\n",
      "3l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.016373\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:28<00:00, 29.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0163572504645672\n",
      "Our out of folds log loss for our seed blend model is 0.0163572504645672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:57:56] - model_type:4l, oof:0.0163573, train_flag:train\n",
      "4l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0163573\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:42<00:00, 56.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016373621840380347\n",
      "Our out of folds log loss for our seed blend model is 0.016373621840380347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:02:50] - model_type:5l, oof:0.0163736, train_flag:train\n",
      "5l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0163736\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:48<00:00, 21.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016773587421574417\n",
      "Our out of folds log loss for our seed blend model is 0.016773587421574417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:04:50] - model_type:rs, oof:0.0167736, train_flag:train\n",
      "rs\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0167736\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:52<03:29, 52.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:45<02:37, 52.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:33<01:42, 51.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:24<00:51, 51.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:14<00:00, 50.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016484104275262364\n",
      "Our out of folds log loss for our seed blend model is 0.016484104275262364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:09:17] - model_type:3l_v2, oof:0.0164841, train_flag:train\n",
      "3l_v2\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0164841\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3lWN with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:35<00:00, 31.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.018409749845942625\n",
      "Our out of folds log loss for our seed blend model is 0.018409749845942625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:12:05] - model_type:3lWN, oof:0.0184097, train_flag:train\n",
      "3lWN\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0184097\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:37<02:31, 37.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:14<01:52, 37.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:51<01:14, 37.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:29<00:37, 37.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:06<00:00, 37.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017489213993021106\n",
      "Our out of folds log loss for our seed blend model is 0.017489213993021106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:15:24] - model_type:stack_tabnet, oof:0.0174892, train_flag:train\n",
      "stack_tabnet\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0174892\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:23<01:32, 23.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:47<01:10, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:11<00:47, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:34<00:23, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:59<00:00, 23.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017277233621319964\n",
      "Our out of folds log loss for our seed blend model is 0.017277233621319964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:17:36] - model_type:tabnet_class, oof:0.0172772, train_flag:train\n",
      "tabnet_class\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0172772\ttrain\n",
      "[2020-11-06 00:17:39] - model_type:lr-2l-3l-4l-5l-rs-3l_v2-3lWN-stack_tabnet-tabnet_class, oof:0.0208002, train_flag:train\n",
      "lr-2l-3l-4l-5l-rs-3l_v2-3lWN-stack_tabnet-tabnet_class\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling:Mean blend\t0.0208002\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "mlp_tf.run_mlp_tf_blend_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T03:06:40.603395Z",
     "start_time": "2020-11-06T02:36:12.986850Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 / 99.0 % clip : -2.566718995290424 / 2.5704835731583646\n",
      "1.0 / 99.0 % clip : -6.858598915666221 / 65.34177977047811\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [06:07<00:00, 73.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016288235437457776\n",
      "Our out of folds log loss for our seed blend model is 0.016288235437457776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 11:43:31] - model_type:2l, oof:0.0162882, train_flag:train\n",
      "2l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0162882\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:54<00:00, 46.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016385334526841187\n",
      "Our out of folds log loss for our seed blend model is 0.016385334526841187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 11:47:38] - model_type:3l, oof:0.0163853, train_flag:train\n",
      "3l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0163853\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:35<00:00, 31.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016323825944515764\n",
      "Our out of folds log loss for our seed blend model is 0.016323825944515764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 11:50:26] - model_type:4l, oof:0.0163238, train_flag:train\n",
      "4l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0163238\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:49<00:00, 57.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016359862839846855\n",
      "Our out of folds log loss for our seed blend model is 0.016359862839846855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 11:55:28] - model_type:5l, oof:0.0163599, train_flag:train\n",
      "5l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0163599\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:43<00:00, 20.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0167596392836425\n",
      "Our out of folds log loss for our seed blend model is 0.0167596392836425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 11:57:23] - model_type:rs, oof:0.0167596, train_flag:train\n",
      "rs\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0167596\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:49<03:19, 49.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:37<02:27, 49.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:24<01:37, 48.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:07<00:46, 46.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:55<00:00, 47.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01646908711815762\n",
      "Our out of folds log loss for our seed blend model is 0.01646908711815762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:01:31] - model_type:3l_v2, oof:0.0164691, train_flag:train\n",
      "3l_v2\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0164691\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:36<02:26, 36.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:08<01:45, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:42<01:09, 34.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:15<00:34, 34.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:49<00:00, 33.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0175017993571376\n",
      "Our out of folds log loss for our seed blend model is 0.0175017993571376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:04:32] - model_type:stack_tabnet, oof:0.0175018, train_flag:train\n",
      "stack_tabnet\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0175018\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:21<01:25, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:44<01:05, 21.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:05<00:43, 21.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:28<00:22, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:50<00:00, 22.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017294507869808524\n",
      "Our out of folds log loss for our seed blend model is 0.017294507869808524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:06:35] - model_type:tabnet_class, oof:0.0172945, train_flag:train\n",
      "tabnet_class\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0172945\ttrain\n",
      "[2020-11-06 12:06:38] - model_type:2l-3l-4l-5l-rs-3l_v2-stack_tabnet-tabnet_class, oof:0.020213, train_flag:train\n",
      "2l-3l-4l-5l-rs-3l_v2-stack_tabnet-tabnet_class\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping:Mean blend\t0.020213\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "features_g, features_c = datasets.get_features_gc(train)\n",
    "train, test = datasets.fe_clipping(train, test, features_g=features_g, features_c=features_c)\n",
    "mlp_tf.run_mlp_tf_blend_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_types=[\n",
    "        \"2l\",\n",
    "        \"3l\",\n",
    "        \"4l\",\n",
    "        \"5l\",\n",
    "        \"rs\",\n",
    "        \"3l_v2\",\n",
    "        \"stack_tabnet\",\n",
    "        \"tabnet_class\",\n",
    "    ],\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T16:40:23.768909Z",
     "start_time": "2020-11-05T15:30:02.374880Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model rs with seed 5 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:05<00:00, 25.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016736725817493185\n",
      "Using model rs with seed 12 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:42<00:00, 20.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01672545993069803\n",
      "Using model rs with seed 67 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:43<00:00, 20.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0167651360454351\n",
      "Our out of folds log loss for our seed blend model is 0.016272242101958434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:36:51] - model_type:rs, oof:0.0162722, train_flag:train\n",
      "rs\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]\t0.0162722\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 2l with seed 5 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:44<00:00, 56.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016323429485602253\n",
      "Using model 2l with seed 12 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:11<00:00, 62.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016313735963169675\n",
      "Using model 2l with seed 67 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:25<00:00, 65.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01643209493181065\n",
      "Our out of folds log loss for our seed blend model is 0.01624385879898476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 00:52:33] - model_type:2l, oof:0.0162439, train_flag:train\n",
      "2l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]\t0.0162439\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 5 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:53<00:00, 34.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016360815471604558\n",
      "Using model 4l with seed 12 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:30<00:00, 30.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01636181805342801\n",
      "Using model 4l with seed 67 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:02<00:00, 36.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016337801391403648\n",
      "Our out of folds log loss for our seed blend model is 0.016192536342887143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 01:01:20] - model_type:4l, oof:0.0161925, train_flag:train\n",
      "4l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]\t0.0161925\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 5l with seed 5 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:38<00:00, 67.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01633600304661159\n",
      "Using model 5l with seed 12 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:32<00:00, 54.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01637809529876806\n",
      "Using model 5l with seed 67 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:50<00:00, 70.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016371188636297003\n",
      "Our out of folds log loss for our seed blend model is 0.016211144317722328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 01:17:40] - model_type:5l, oof:0.0162111, train_flag:train\n",
      "5l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]\t0.0162111\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l with seed 5 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:26<00:00, 53.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016383132333163127\n",
      "Using model 3l with seed 12 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:18<00:00, 51.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01638026946358595\n",
      "Using model 3l with seed 67 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:13<00:00, 50.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01637809514181034\n",
      "Our out of folds log loss for our seed blend model is 0.0161921806832481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 01:30:59] - model_type:3l, oof:0.0161922, train_flag:train\n",
      "3l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]\t0.0161922\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 5 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:35<02:22, 35.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:12<01:48, 36.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:49<01:12, 36.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:25<00:36, 36.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:01<00:00, 36.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01749388746333828\n",
      "Using model stack_tabnet with seed 12 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:37<02:30, 37.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:14<01:52, 37.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:51<01:14, 37.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:28<00:37, 37.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:03<00:00, 36.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01746649170210523\n",
      "Using model stack_tabnet with seed 67 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:34<02:16, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:09<01:43, 34.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:43<01:08, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:19<00:34, 34.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:55<00:00, 35.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017434247206467173\n",
      "Our out of folds log loss for our seed blend model is 0.016998437133547813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 01:40:18] - model_type:stack_tabnet, oof:0.0169984, train_flag:train\n",
      "stack_tabnet\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]\t0.0169984\ttrain\n",
      "[2020-11-06 01:40:21] - model_type:rs-2l-4l-5l-3l-stack_tabnet, oof:0.0192757, train_flag:train\n",
      "rs-2l-4l-5l-3l-stack_tabnet\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]:Mean blend\t0.0192757\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling + seeds=[5, 12, 67]\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "mlp_tf.run_mlp_tf_blend_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    seeds=[5, 12, 67],\n",
    "    str_condition=str_condition,\n",
    "    model_types=[\"rs\", \"2l\", \"4l\", \"5l\", \"3l\", \"stack_tabnet\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1モデルだけで試していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T02:25:31.600554Z",
     "start_time": "2020-11-06T02:21:25.797341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 / 99.0 % clip : -3.97 / 3.918\n",
      "1.0 / 99.0 % clip : -9.931 / 1.505\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:55<00:00, 35.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016383323505001532\n",
      "Our out of folds log loss for our seed blend model is 0.016383323505001532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 11:25:31] - model_type:4l, oof:0.0163833, train_flag:train\n",
      "4l\tfe_clipping → fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0163833\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"fe_clipping → fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_clipping(train, test)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T02:32:48.820551Z",
     "start_time": "2020-11-06T02:28:47.799584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 / 99.0 % clip : -2.566718995290424 / 2.5704835731583646\n",
      "1.0 / 99.0 % clip : -6.858598915666221 / 65.34177977047811\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1941 features. train.shape: (23814, 1943). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:48<00:00, 33.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016353718597731066\n",
      "Our out of folds log loss for our seed blend model is 0.016353718597731066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 11:32:48] - model_type:4l, oof:0.0163537, train_flag:train\n",
      "4l\tfe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\t0.0163537\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling → fe_clipping\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "features_g, features_c = datasets.get_features_gc(train)\n",
    "train, test = datasets.fe_clipping(train, test, features_g=features_g, features_c=features_c)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:11:25.027422Z",
     "start_time": "2020-11-06T00:08:39.015357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (21282, 876). train_targets.shape: (21282, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:36<00:00, 31.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0175857142120379\n",
      "Our out of folds log loss for our seed blend model is 0.0175857142120379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:11:25] - model_type:4l, oof:0.0175857, train_flag:train\n",
      "4l\tno feature_eng + is_del_ctl + is_del_noise_drug\t0.0175857\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"no feature_eng + is_del_ctl + is_del_noise_drug\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_del_ctl=True, is_del_noise_drug=True\n",
    ")\n",
    "features = datasets.get_features(train)\n",
    "\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T13:59:54.020483Z",
     "start_time": "2020-11-05T13:57:27.408784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (21948, 876). train_targets.shape: (21948, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:15<00:00, 27.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017734774967382398\n",
      "Our out of folds log loss for our seed blend model is 0.017734774967382398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 22:59:54] - model_type:4l, oof:0.0177348, train_flag:train\n",
      "4l\tis_del_ctl + scaling\t0.0177348\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"is_del_ctl + scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_del_ctl=True\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T14:05:18.538378Z",
     "start_time": "2020-11-05T14:02:35.861446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23096, 876). train_targets.shape: (23096, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:31<00:00, 30.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016999163032590504\n",
      "Our out of folds log loss for our seed blend model is 0.016999163032590504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:05:18] - model_type:4l, oof:0.0169992, train_flag:train\n",
      "4l\tis_del_noise_drug + scaling\t0.0169992\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"is_del_noise_drug + scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_del_noise_drug=True\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T14:02:35.860477Z",
     "start_time": "2020-11-05T13:59:54.021479Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:21<00:00, 28.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016740740054203725\n",
      "Our out of folds log loss for our seed blend model is 0.016740740054203725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-05 23:02:35] - model_type:4l, oof:0.0167407, train_flag:train\n",
      "4l\tis_conat_nonscore + scaling\t0.0167407\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"is_conat_nonscore + scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_conat_nonscore=True\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T18:27:04.386852Z",
     "start_time": "2020-11-05T16:40:23.769906Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:8, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [03:14<12:59, 194.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [06:26<09:41, 193.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [08:52<05:58, 179.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [12:03<03:02, 182.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [15:14<00:00, 182.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016724333959073544\n",
      "Our out of folds log loss for our seed blend model is 0.016724333959073544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 01:55:52] - model_type:tabnet_class, oof:0.0167243, train_flag:train\n",
      "tabnet_class\tno feature_eng + batch_size=8\t0.0167243\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:8, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [05:41<22:44, 341.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [11:53<17:31, 350.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [17:02<11:16, 338.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [22:56<05:42, 342.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [29:13<00:00, 350.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016692786774627655\n",
      "Our out of folds log loss for our seed blend model is 0.016692786774627655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 02:25:21] - model_type:stack_tabnet, oof:0.0166928, train_flag:train\n",
      "stack_tabnet\tno feature_eng + batch_size=8\t0.0166928\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:16, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [01:47<07:08, 107.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [03:28<05:16, 105.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [05:18<03:33, 106.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [07:00<01:45, 105.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [08:42<00:00, 104.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016720003090711102\n",
      "Our out of folds log loss for our seed blend model is 0.016720003090711102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 02:34:19] - model_type:tabnet_class, oof:0.01672, train_flag:train\n",
      "tabnet_class\tno feature_eng + batch_size=16\t0.01672\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:16, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [03:08<12:34, 188.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [06:22<09:30, 190.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [09:37<06:23, 191.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [13:03<03:15, 195.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [16:17<00:00, 195.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016672178978687877\n",
      "Our out of folds log loss for our seed blend model is 0.016672178978687877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 02:50:52] - model_type:stack_tabnet, oof:0.0166722, train_flag:train\n",
      "stack_tabnet\tno feature_eng + batch_size=16\t0.0166722\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:32, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:02<04:08, 62.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:59<03:02, 60.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [03:01<02:02, 61.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:58<01:00, 60.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:00<00:00, 60.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01683133859868338\n",
      "Our out of folds log loss for our seed blend model is 0.01683133859868338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 02:56:08] - model_type:tabnet_class, oof:0.0168313, train_flag:train\n",
      "tabnet_class\tno feature_eng + batch_size=32\t0.0168313\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:32, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [01:41<06:47, 101.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [03:24<05:06, 102.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [05:08<03:25, 102.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [07:03<01:46, 106.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [08:45<00:00, 105.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016719095119660125\n",
      "Our out of folds log loss for our seed blend model is 0.016719095119660125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:05:09] - model_type:stack_tabnet, oof:0.0167191, train_flag:train\n",
      "stack_tabnet\tno feature_eng + batch_size=32\t0.0167191\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:64, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:36<02:26, 36.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:09<01:46, 35.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:44<01:10, 35.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:19<00:35, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:55<00:00, 35.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016870970941589698\n",
      "Our out of folds log loss for our seed blend model is 0.016870970941589698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:08:20] - model_type:tabnet_class, oof:0.016871, train_flag:train\n",
      "tabnet_class\tno feature_eng + batch_size=64\t0.016871\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:64, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:04<04:18, 64.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [02:01<03:06, 62.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:54<01:59, 59.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:51<00:58, 58.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:47<00:00, 57.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016804322406520782\n",
      "Our out of folds log loss for our seed blend model is 0.016804322406520782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:13:22] - model_type:stack_tabnet, oof:0.0168043, train_flag:train\n",
      "stack_tabnet\tno feature_eng + batch_size=64\t0.0168043\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:25<01:41, 25.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:47<01:13, 24.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:10<00:48, 24.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:34<00:23, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:57<00:00, 23.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016926636221588593\n",
      "Our out of folds log loss for our seed blend model is 0.016926636221588593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:15:35] - model_type:tabnet_class, oof:0.0169266, train_flag:train\n",
      "tabnet_class\tno feature_eng + batch_size=128\t0.0169266\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:41<02:45, 41.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:19<02:01, 40.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:56<01:18, 39.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:35<00:39, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:12<00:00, 38.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017072668200538203\n",
      "Our out of folds log loss for our seed blend model is 0.017072668200538203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:19:02] - model_type:stack_tabnet, oof:0.0170727, train_flag:train\n",
      "stack_tabnet\tno feature_eng + batch_size=128\t0.0170727\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:256, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:21<01:24, 21.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:37<00:59, 19.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [00:55<00:38, 19.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:13<00:18, 18.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:30<00:00, 18.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016957212601108836\n",
      "Our out of folds log loss for our seed blend model is 0.016957212601108836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:20:47] - model_type:tabnet_class, oof:0.0169572, train_flag:train\n",
      "tabnet_class\tno feature_eng + batch_size=256\t0.0169572\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:256, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:31<02:04, 31.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:58<01:29, 29.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:26<00:58, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:54<00:28, 28.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:20<00:00, 28.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01718158394720229\n",
      "Our out of folds log loss for our seed blend model is 0.01718158394720229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:23:23] - model_type:stack_tabnet, oof:0.0171816, train_flag:train\n",
      "stack_tabnet\tno feature_eng + batch_size=256\t0.0171816\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:1024, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:18<01:15, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:34<00:53, 17.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [00:49<00:34, 17.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:05<00:16, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:19<00:00, 15.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0170571055730908\n",
      "Our out of folds log loss for our seed blend model is 0.0170571055730908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:24:58] - model_type:tabnet_class, oof:0.0170571, train_flag:train\n",
      "tabnet_class\tno feature_eng + batch_size=1024\t0.0170571\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:1024, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:26<01:46, 26.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:47<01:15, 25.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:08<00:47, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:29<00:22, 22.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:50<00:00, 22.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017493571929670482\n",
      "Our out of folds log loss for our seed blend model is 0.017493571929670482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:27:04] - model_type:stack_tabnet, oof:0.0174936, train_flag:train\n",
      "stack_tabnet\tno feature_eng + batch_size=1024\t0.0174936\ttrain\n"
     ]
    }
   ],
   "source": [
    "for bs in [8, 16, 32, 64, 128, 256, 1024]:\n",
    "    mlp_tf.BATCH_SIZE = bs\n",
    "    str_condition = f\"no feature_eng + batch_size={mlp_tf.BATCH_SIZE}\"\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"tabnet_class\",\n",
    "        str_condition=str_condition,\n",
    "    )\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"stack_tabnet\",\n",
    "        str_condition=str_condition,\n",
    "    )\n",
    "    \n",
    "mlp_tf.BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:05:14.627443Z",
     "start_time": "2020-11-05T18:27:04.387850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:20<01:22, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:37<00:58, 19.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [00:54<00:37, 18.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:10<00:17, 18.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:27<00:00, 17.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01702596097508366\n",
      "Our out of folds log loss for our seed blend model is 0.01702596097508366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:28:46] - model_type:tabnet_class, oof:0.017026, train_flag:train\n",
      "tabnet_class\tno feature_eng + learning rate=0.1\t0.017026\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:39<02:38, 39.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:17<01:57, 39.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:56<01:18, 39.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:30<00:37, 37.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:07<00:00, 37.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016903741759280274\n",
      "Our out of folds log loss for our seed blend model is 0.016903741759280274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:32:09] - model_type:stack_tabnet, oof:0.0169037, train_flag:train\n",
      "stack_tabnet\tno feature_eng + learning rate=0.1\t0.0169037\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:22<01:30, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:39<01:02, 20.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [00:57<00:40, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:16<00:19, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016821720262544828\n",
      "Our out of folds log loss for our seed blend model is 0.016821720262544828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:33:57] - model_type:tabnet_class, oof:0.0168217, train_flag:train\n",
      "tabnet_class\tno feature_eng + learning rate=0.01\t0.0168217\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:38<02:32, 38.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:12<01:50, 36.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:48<01:13, 36.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:21<00:35, 35.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:53<00:00, 34.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016852747973100345\n",
      "Our out of folds log loss for our seed blend model is 0.016852747973100345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:37:06] - model_type:stack_tabnet, oof:0.0168527, train_flag:train\n",
      "stack_tabnet\tno feature_eng + learning rate=0.01\t0.0168527\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:46<03:05, 46.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:30<02:17, 45.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:16<01:31, 45.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:00<00:45, 45.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:51<00:00, 46.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017056995106822282\n",
      "Our out of folds log loss for our seed blend model is 0.017056995106822282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:41:14] - model_type:tabnet_class, oof:0.017057, train_flag:train\n",
      "tabnet_class\tno feature_eng + learning rate=0.0001\t0.017057\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:11<04:47, 71.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [02:17<03:29, 69.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [03:22<02:16, 68.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [04:23<01:06, 66.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:28<00:00, 65.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01738961396423891\n",
      "Our out of folds log loss for our seed blend model is 0.01738961396423891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:46:57] - model_type:stack_tabnet, oof:0.0173896, train_flag:train\n",
      "stack_tabnet\tno feature_eng + learning rate=0.0001\t0.0173896\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:25<05:40, 85.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [02:44<04:10, 83.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [04:03<02:43, 81.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [05:19<01:20, 80.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [06:43<00:00, 80.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01945544118044095\n",
      "Our out of folds log loss for our seed blend model is 0.01945544118044095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 03:53:56] - model_type:tabnet_class, oof:0.0194554, train_flag:train\n",
      "tabnet_class\tno feature_eng + learning rate=1e-05\t0.0194554\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [02:08<08:35, 128.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [04:21<06:30, 130.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [06:35<04:22, 131.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [08:48<02:11, 131.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [11:03<00:00, 132.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01869354108160658\n",
      "Our out of folds log loss for our seed blend model is 0.01869354108160658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 04:05:14] - model_type:stack_tabnet, oof:0.0186935, train_flag:train\n",
      "stack_tabnet\tno feature_eng + learning rate=1e-05\t0.0186935\ttrain\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.1, 0.01, 0.0001, 0.00001]:\n",
    "    mlp_tf.LR = lr\n",
    "    str_condition = f\"no feature_eng + learning rate={mlp_tf.LR}\"\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"tabnet_class\",\n",
    "        str_condition=str_condition,\n",
    "    )\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"stack_tabnet\",\n",
    "        str_condition=str_condition,\n",
    "    )\n",
    "    \n",
    "mlp_tf.LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T21:37:15.755889Z",
     "start_time": "2020-11-05T19:05:14.628443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:25<01:41, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:47<01:13, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:10<00:48, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:33<00:23, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:56<00:00, 23.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016926636221588593\n",
      "Our out of folds log loss for our seed blend model is 0.016926636221588593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 04:07:26] - model_type:tabnet_class, oof:0.0169266, train_flag:train\n",
      "tabnet_class\tno feature_eng + num_decision_steps=1\t0.0169266\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:41<02:44, 41.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:19<02:00, 40.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:56<01:18, 39.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:34<00:38, 38.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:11<00:00, 38.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017072668200538203\n",
      "Our out of folds log loss for our seed blend model is 0.017072668200538203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 04:10:52] - model_type:stack_tabnet, oof:0.0170727, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_decision_steps=1\t0.0170727\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:02<04:10, 62.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:52<02:56, 58.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:52<01:57, 59.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:53<00:59, 59.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:43<00:00, 56.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.02039530137771991\n",
      "Our out of folds log loss for our seed blend model is 0.02039530137771991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 04:15:51] - model_type:tabnet_class, oof:0.0203953, train_flag:train\n",
      "tabnet_class\tno feature_eng + num_decision_steps=2\t0.0203953\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [02:35<10:23, 155.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [05:13<07:49, 156.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [07:20<04:55, 147.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [10:04<02:32, 152.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 2, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [11:32<00:00, 138.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.019676901891097283\n",
      "Our out of folds log loss for our seed blend model is 0.019676901891097283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 04:27:39] - model_type:stack_tabnet, oof:0.0196769, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_decision_steps=2\t0.0196769\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [01:50<07:22, 110.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [04:38<06:23, 127.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [06:23<04:02, 121.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [07:45<01:49, 109.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [09:29<00:00, 113.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.019911757908280835\n",
      "Our out of folds log loss for our seed blend model is 0.019911757908280835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 04:37:24] - model_type:tabnet_class, oof:0.0199118, train_flag:train\n",
      "tabnet_class\tno feature_eng + num_decision_steps=3\t0.0199118\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [04:14<16:58, 254.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [06:29<10:55, 218.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [09:46<07:04, 212.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [14:36<03:55, 235.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 3, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [16:40<00:00, 200.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0197523349303564\n",
      "Our out of folds log loss for our seed blend model is 0.0197523349303564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 04:54:20] - model_type:stack_tabnet, oof:0.0197523, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_decision_steps=3\t0.0197523\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [02:26<09:45, 146.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [04:41<07:09, 143.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [06:46<04:35, 137.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [08:58<02:15, 135.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [10:18<00:00, 123.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.019576487155029323\n",
      "Our out of folds log loss for our seed blend model is 0.019576487155029323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 05:04:54] - model_type:tabnet_class, oof:0.0195765, train_flag:train\n",
      "tabnet_class\tno feature_eng + num_decision_steps=4\t0.0195765\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [02:11<08:46, 131.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [07:17<09:11, 183.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [10:14<06:03, 181.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [15:21<03:39, 219.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 4, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [21:53<00:00, 262.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.019839941031525008\n",
      "Our out of folds log loss for our seed blend model is 0.019839941031525008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 05:27:05] - model_type:stack_tabnet, oof:0.0198399, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_decision_steps=4\t0.0198399\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [04:44<18:59, 284.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [10:51<15:28, 309.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [15:22<09:55, 297.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [20:06<04:53, 293.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [25:33<00:00, 306.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01972193699043687\n",
      "Our out of folds log loss for our seed blend model is 0.01972193699043687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 05:52:55] - model_type:tabnet_class, oof:0.0197219, train_flag:train\n",
      "tabnet_class\tno feature_eng + num_decision_steps=8\t0.0197219\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [07:19<29:17, 439.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [18:59<25:53, 517.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [26:00<16:17, 488.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [32:46<07:43, 463.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_layers': 2, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 8, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [44:03<00:00, 528.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.02057137782154323\n",
      "Our out of folds log loss for our seed blend model is 0.02057137782154323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 06:37:15] - model_type:stack_tabnet, oof:0.0205714, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_decision_steps=8\t0.0205714\ttrain\n"
     ]
    }
   ],
   "source": [
    "for num_decision_steps in [1, 2, 3, 4, 8]:\n",
    "    str_condition = f\"no feature_eng + num_decision_steps={num_decision_steps}\"\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    tabnet_params = dict(\n",
    "            feature_columns=None,\n",
    "            num_classes=206,\n",
    "            feature_dim=128,\n",
    "            output_dim=64,\n",
    "            num_features=len(features),\n",
    "            num_decision_steps=num_decision_steps,\n",
    "            relaxation_factor=1.5,\n",
    "            sparsity_coefficient=1e-5,\n",
    "            batch_momentum=0.98,\n",
    "            virtual_batch_size=None,\n",
    "            norm_type=\"group\",\n",
    "            num_groups=-1,\n",
    "            multi_label=True,\n",
    "        )\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"tabnet_class\",\n",
    "        str_condition=str_condition,\n",
    "        tabnet_params=tabnet_params,\n",
    "    )\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    tabnet_params = dict(\n",
    "            feature_columns=None,\n",
    "            num_layers=2,\n",
    "            num_classes=206,\n",
    "            feature_dim=128,\n",
    "            output_dim=64,\n",
    "            num_features=len(features),\n",
    "            num_decision_steps=num_decision_steps,\n",
    "            relaxation_factor=1.5,\n",
    "            sparsity_coefficient=1e-5,\n",
    "            batch_momentum=0.98,\n",
    "            virtual_batch_size=None,\n",
    "            norm_type=\"group\",\n",
    "            num_groups=-1,\n",
    "            multi_label=True,\n",
    "        )\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"stack_tabnet\",\n",
    "        str_condition=str_condition,\n",
    "        tabnet_params=tabnet_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:06:19.501621Z",
     "start_time": "2020-11-05T21:37:15.756886Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:47<03:10, 47.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:29<02:17, 45.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:13<01:30, 45.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:53<00:43, 43.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:35<00:00, 43.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017677068947706827\n",
      "Our out of folds log loss for our seed blend model is 0.017677068947706827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 06:41:06] - model_type:tabnet_class, oof:0.0176771, train_flag:train\n",
      "tabnet_class\tno feature_eng + feature_dim,output_dim=8\t0.0176771\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:13<04:52, 73.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [02:07<03:22, 67.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [03:12<02:13, 66.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [04:52<01:16, 76.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 8, 'output_dim': 8, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [06:00<00:00, 72.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01871676831275669\n",
      "Our out of folds log loss for our seed blend model is 0.01871676831275669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 06:47:22] - model_type:stack_tabnet, oof:0.0187168, train_flag:train\n",
      "stack_tabnet\tno feature_eng + feature_dim,output_dim=8\t0.0187168\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:33<02:13, 33.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:02<01:36, 32.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:32<01:02, 31.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:03<00:31, 31.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:32<00:00, 30.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01711343044954276\n",
      "Our out of folds log loss for our seed blend model is 0.01711343044954276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 06:50:10] - model_type:tabnet_class, oof:0.0171134, train_flag:train\n",
      "tabnet_class\tno feature_eng + feature_dim,output_dim=32\t0.0171134\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:55<03:40, 55.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:40<02:36, 52.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:28<01:41, 50.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:18<00:50, 50.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 32, 'output_dim': 32, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:02<00:00, 48.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017360115754471363\n",
      "Our out of folds log loss for our seed blend model is 0.017360115754471363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 06:54:27] - model_type:stack_tabnet, oof:0.0173601, train_flag:train\n",
      "stack_tabnet\tno feature_eng + feature_dim,output_dim=32\t0.0173601\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:30<02:02, 30.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:55<01:26, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:20<00:55, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:46<00:27, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:11<00:00, 26.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016929891707319237\n",
      "Our out of folds log loss for our seed blend model is 0.016929891707319237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 06:56:54] - model_type:tabnet_class, oof:0.0169299, train_flag:train\n",
      "tabnet_class\tno feature_eng + feature_dim,output_dim=64\t0.0169299\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:47<03:09, 47.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:28<02:16, 45.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:09<01:28, 44.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:50<00:43, 43.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 64, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:30<00:00, 42.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017071799563826227\n",
      "Our out of folds log loss for our seed blend model is 0.017071799563826227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:00:40] - model_type:stack_tabnet, oof:0.0170718, train_flag:train\n",
      "stack_tabnet\tno feature_eng + feature_dim,output_dim=64\t0.0170718\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:27<01:50, 27.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:49<01:18, 26.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:12<00:49, 24.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:35<00:24, 24.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:58<00:00, 23.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01690313206577805\n",
      "Our out of folds log loss for our seed blend model is 0.01690313206577805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:02:54] - model_type:tabnet_class, oof:0.0169031, train_flag:train\n",
      "tabnet_class\tno feature_eng + feature_dim,output_dim=128\t0.0169031\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:39<02:39, 39.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:16<01:56, 38.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:53<01:16, 38.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:32<00:38, 38.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 128, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:09<00:00, 37.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016969490429787654\n",
      "Our out of folds log loss for our seed blend model is 0.016969490429787654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:06:19] - model_type:stack_tabnet, oof:0.0169695, train_flag:train\n",
      "stack_tabnet\tno feature_eng + feature_dim,output_dim=128\t0.0169695\ttrain\n"
     ]
    }
   ],
   "source": [
    "for feature_dim in [8, 32, 64, 128]:\n",
    "    str_condition = f\"no feature_eng + feature_dim,output_dim={feature_dim}\"\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    tabnet_params = dict(\n",
    "            feature_columns=None,\n",
    "            num_classes=206,\n",
    "            feature_dim=feature_dim,\n",
    "            output_dim=feature_dim,\n",
    "            num_features=len(features),\n",
    "            num_decision_steps=1,\n",
    "            relaxation_factor=1.5,\n",
    "            sparsity_coefficient=1e-5,\n",
    "            batch_momentum=0.98,\n",
    "            virtual_batch_size=None,\n",
    "            norm_type=\"group\",\n",
    "            num_groups=-1,\n",
    "            multi_label=True,\n",
    "        )\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"tabnet_class\",\n",
    "        str_condition=str_condition,\n",
    "        tabnet_params=tabnet_params,\n",
    "    )\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    tabnet_params = dict(\n",
    "            feature_columns=None,\n",
    "            num_classes=206,\n",
    "            num_layers=2,\n",
    "            feature_dim=feature_dim,\n",
    "            output_dim=feature_dim,\n",
    "            num_features=len(features),\n",
    "            num_decision_steps=1,\n",
    "            relaxation_factor=1.5,\n",
    "            sparsity_coefficient=1e-5,\n",
    "            batch_momentum=0.98,\n",
    "            virtual_batch_size=None,\n",
    "            norm_type=\"group\",\n",
    "            num_groups=-1,\n",
    "            multi_label=True,\n",
    "        )\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"stack_tabnet\",\n",
    "        str_condition=str_condition,\n",
    "        tabnet_params=tabnet_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:31:27.381562Z",
     "start_time": "2020-11-05T22:06:19.502622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 1, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:25<01:42, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 1, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:47<01:13, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 1, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:11<00:48, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 1, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:34<00:23, 24.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 1, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:58<00:00, 23.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016926636221588593\n",
      "Our out of folds log loss for our seed blend model is 0.016926636221588593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:08:32] - model_type:stack_tabnet, oof:0.0169266, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_layers=1\t0.0169266\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:41<02:45, 41.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:19<02:01, 40.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:56<01:18, 39.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:34<00:38, 38.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 2, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:11<00:00, 38.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017072668200538203\n",
      "Our out of folds log loss for our seed blend model is 0.017072668200538203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:11:59] - model_type:stack_tabnet, oof:0.0170727, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_layers=2\t0.0170727\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 3, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:58<03:54, 58.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 3, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:52<02:51, 57.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 3, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:43<01:50, 55.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 3, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:38<00:55, 55.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 3, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:27<00:00, 53.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01709059305134233\n",
      "Our out of folds log loss for our seed blend model is 0.01709059305134233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:16:42] - model_type:stack_tabnet, oof:0.0170906, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_layers=3\t0.0170906\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 4, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:13<04:53, 73.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 4, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [02:19<03:33, 71.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 4, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [03:30<02:22, 71.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 4, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [04:47<01:12, 72.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 4, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:58<00:00, 71.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017029039922553994\n",
      "Our out of folds log loss for our seed blend model is 0.017029039922553994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:22:57] - model_type:stack_tabnet, oof:0.017029, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_layers=4\t0.017029\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 5, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [01:42<06:49, 102.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 5, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [03:16<05:00, 100.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 5, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [04:58<03:21, 100.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 5, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [06:32<01:38, 98.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'feature_columns': None, 'num_classes': 206, 'num_layers': 5, 'feature_dim': 128, 'output_dim': 64, 'num_features': 874, 'num_decision_steps': 1, 'relaxation_factor': 1.5, 'sparsity_coefficient': 1e-05, 'batch_momentum': 0.98, 'virtual_batch_size': None, 'norm_type': 'group', 'num_groups': -1, 'multi_label': True}\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [08:14<00:00, 98.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0170164395555092\n",
      "Our out of folds log loss for our seed blend model is 0.0170164395555092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:31:27] - model_type:stack_tabnet, oof:0.0170164, train_flag:train\n",
      "stack_tabnet\tno feature_eng + num_layers=5\t0.0170164\ttrain\n"
     ]
    }
   ],
   "source": [
    "for num_layers in [1, 2, 3, 4, 5]:\n",
    "    str_condition = f\"no feature_eng + num_layers={num_layers}\"\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    tabnet_params = dict(\n",
    "            feature_columns=None,\n",
    "            num_classes=206,\n",
    "            num_layers=num_layers,\n",
    "            feature_dim=128,\n",
    "            output_dim=64,\n",
    "            num_features=len(features),\n",
    "            num_decision_steps=1,\n",
    "            relaxation_factor=1.5,\n",
    "            sparsity_coefficient=1e-5,\n",
    "            batch_momentum=0.98,\n",
    "            virtual_batch_size=None,\n",
    "            norm_type=\"group\",\n",
    "            num_groups=-1,\n",
    "            multi_label=True,\n",
    "        )\n",
    "    _, _ = mlp_tf.run_mlp_tf_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        model_type=\"stack_tabnet\",\n",
    "        str_condition=str_condition,\n",
    "        tabnet_params=tabnet_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:34:14.555019Z",
     "start_time": "2020-11-05T22:31:27.382536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 / 99.0 % clip : -3.97 / 3.918\n",
      "1.0 / 99.0 % clip : -9.931 / 1.505\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:30<00:00, 30.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016399909472230658\n",
      "Our out of folds log loss for our seed blend model is 0.016399909472230658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:34:14] - model_type:4l, oof:0.0163999, train_flag:train\n",
      "4l\tcliping\t0.0163999\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"cliping\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_clipping(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:18:59.776544Z",
     "start_time": "2020-11-06T00:16:14.823566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 / 95.0 % clip : -1.515 / 1.57\n",
      "5.0 / 95.0 % clip : -3.9920499999999883 / 1.066\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:27<00:00, 29.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016414002814469142\n",
      "Our out of folds log loss for our seed blend model is 0.016414002814469142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:18:59] - model_type:4l, oof:0.016414, train_flag:train\n",
      "4l\tcliping min_clip=0.05, max_clip=0.95\t0.016414\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"cliping min_clip=0.05, max_clip=0.95\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_clipping(train, test, min_clip=0.05, max_clip=0.95)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:22:00.882606Z",
     "start_time": "2020-11-06T00:18:59.777541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:43<00:00, 32.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01640379155735001\n",
      "Our out of folds log loss for our seed blend model is 0.01640379155735001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:22:00] - model_type:4l, oof:0.0164038, train_flag:train\n",
      "4l\tfe_clipping_col\t0.0164038\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"fe_clipping_col\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "#display(np.max(train))\n",
    "train, test = datasets.fe_clipping_col(train, test)\n",
    "#display(np.max(train))\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:24:41.595073Z",
     "start_time": "2020-11-06T00:22:00.883576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:22<00:00, 28.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016424846292118062\n",
      "Our out of folds log loss for our seed blend model is 0.016424846292118062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:24:41] - model_type:4l, oof:0.0164248, train_flag:train\n",
      "4l\tfe_clipping_col min_clip=0.05, max_clip=0.95\t0.0164248\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"fe_clipping_col min_clip=0.05, max_clip=0.95\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "#display(np.max(train))\n",
    "train, test = datasets.fe_clipping_col(train, test, min_clip=0.05, max_clip=0.95)\n",
    "#display(np.max(train))\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:37:36.602455Z",
     "start_time": "2020-11-05T22:34:14.557014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 / 99.0 % clip : -3.97 / 3.918\n",
      "1.0 / 99.0 % clip : -9.931 / 1.505\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 889 features. train.shape: (23814, 891). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:59<00:00, 35.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016371620847609153\n",
      "Our out of folds log loss for our seed blend model is 0.016371620847609153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:37:36] - model_type:4l, oof:0.0163716, train_flag:train\n",
      "4l\tcliping → fe_stats\t0.0163716\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"cliping → fe_stats\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_clipping(train, test)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:40:38.629366Z",
     "start_time": "2020-11-05T22:37:36.603453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 / 99.0 % clip : -3.97 / 3.918\n",
      "1.0 / 99.0 % clip : -9.931 / 1.505\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:41<00:00, 32.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01639072415329617\n",
      "Our out of folds log loss for our seed blend model is 0.01639072415329617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:40:38] - model_type:4l, oof:0.0163907, train_flag:train\n",
      "4l\tcliping → scaling\t0.0163907\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"cliping → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_clipping(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:43:38.388199Z",
     "start_time": "2020-11-05T22:40:38.630337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 / 99.0 % clip : -3.97 / 3.918\n",
      "1.0 / 99.0 % clip : -9.931 / 1.505\n",
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 889 features. train.shape: (23814, 891). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:33<00:00, 30.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016394915265482254\n",
      "Our out of folds log loss for our seed blend model is 0.016394915265482254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:43:38] - model_type:4l, oof:0.0163949, train_flag:train\n",
      "4l\tcliping → fe_stats → scaling\t0.0163949\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"cliping → fe_stats → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_clipping(train, test)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:48:52.470554Z",
     "start_time": "2020-11-05T22:43:38.389169Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 5 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:28<00:00, 29.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016415164661213934\n",
      "Using model 4l with seed 12 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 206)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:26<00:00, 29.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016432959041340213\n",
      "Our out of folds log loss for our seed blend model is 0.0163158942958022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:48:52] - model_type:4l, oof:0.0163159, train_flag:train\n",
      "4l\tno feature_eng + seeds=[5, 12]\t0.0163159\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"no feature_eng + seeds=[5, 12]\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    seeds=[5, 12],\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:51:40.257703Z",
     "start_time": "2020-11-05T22:48:52.471549Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:32<00:00, 30.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016417860003448276\n",
      "Our out of folds log loss for our seed blend model is 0.016417860003448276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:51:40] - model_type:4l, oof:0.0164733, train_flag:train\n",
      "4l\tno feature_eng + p_min=0.001\t0.0164733\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"no feature_eng + p_min=0.001\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    "    p_min=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:54:44.505449Z",
     "start_time": "2020-11-05T22:51:40.258682Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:48<00:00, 33.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016418535034054025\n",
      "Our out of folds log loss for our seed blend model is 0.016418535034054025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:54:44] - model_type:4l, oof:0.0164171, train_flag:train\n",
      "4l\tno feature_eng + p_min=0.0001\t0.0164171\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"no feature_eng + p_min=0.0001\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    "    p_min=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T22:57:38.816911Z",
     "start_time": "2020-11-05T22:54:44.506446Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01642010286740012\n",
      "Our out of folds log loss for our seed blend model is 0.01642010286740012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 07:57:38] - model_type:4l, oof:0.0164193, train_flag:train\n",
      "4l\tno feature_eng + p_min=0.000012\t0.0164193\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"no feature_eng + p_min=0.000012\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    "    p_min=0.000012,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:00:19.038640Z",
     "start_time": "2020-11-05T22:57:38.817881Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:18<00:00, 27.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01651488976653086\n",
      "Our out of folds log loss for our seed blend model is 0.01651488976653086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:00:19] - model_type:4l, oof:0.0165149, train_flag:train\n",
      "4l\tfeature_eng: RankGauss\t0.0165149\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: RankGauss\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:03:35.475282Z",
     "start_time": "2020-11-05T23:00:19.039611Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 914 features. train.shape: (23814, 916). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016428480786353908\n",
      "Our out of folds log loss for our seed blend model is 0.016428480786353908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:03:35] - model_type:4l, oof:0.0164285, train_flag:train\n",
      "4l\tfeature_eng: Kmean\t0.0164285\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: Kmean\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_cluster(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:06:33.647354Z",
     "start_time": "2020-11-05T23:03:35.475282Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 974 features. train.shape: (23814, 976). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:42<00:00, 32.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016341572635491387\n",
      "Our out of folds log loss for our seed blend model is 0.016341572635491387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:06:33] - model_type:4l, oof:0.0163416, train_flag:train\n",
      "4l\tfeature_eng: c_abs\t0.0163416\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: c_abs\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:10:14.130031Z",
     "start_time": "2020-11-05T23:06:33.648327Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1646 features. train.shape: (23814, 1648). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:49<00:00, 33.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01642308050404753\n",
      "Our out of folds log loss for our seed blend model is 0.01642308050404753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:10:14] - model_type:4l, oof:0.0164231, train_flag:train\n",
      "4l\tfeature_eng: g_valid\t0.0164231\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: g_valid\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:13:05.770236Z",
     "start_time": "2020-11-05T23:10:14.131004Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1646 features. train.shape: (23814, 1648). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016526913096311505\n",
      "Our out of folds log loss for our seed blend model is 0.016526913096311505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:13:05] - model_type:4l, oof:0.0165269, train_flag:train\n",
      "4l\tfeature_eng: g_abs\t0.0165269\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: g_abs\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.g_abs(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:16:15.402374Z",
     "start_time": "2020-11-05T23:13:05.771208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1646 features. train.shape: (23814, 1648). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:49<00:00, 33.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016719939286481203\n",
      "Our out of folds log loss for our seed blend model is 0.016719939286481203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:16:15] - model_type:4l, oof:0.0167199, train_flag:train\n",
      "4l\tfeature_eng: g_binary\t0.0167199\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: g_binary\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.g_binary(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:18:49.205222Z",
     "start_time": "2020-11-05T23:16:15.403346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 974 features. train.shape: (23814, 976). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:17<00:00, 27.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016473761854097265\n",
      "Our out of folds log loss for our seed blend model is 0.016473761854097265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:18:49] - model_type:4l, oof:0.0164738, train_flag:train\n",
      "4l\tfeature_eng: c_binary\t0.0164738\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: c_binary\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.c_binary(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:22:13.869601Z",
     "start_time": "2020-11-05T23:18:49.206219Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1038 features. train.shape: (23814, 1040). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:56<00:00, 35.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01652331065609927\n",
      "Our out of folds log loss for our seed blend model is 0.01652331065609927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:22:13] - model_type:4l, oof:0.0165233, train_flag:train\n",
      "4l\tfeature_eng: RankGauss → pca → variance_threshold\t0.0165233\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: RankGauss → pca → variance_threshold\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=600, n_components_c=50, SEED=42\n",
    ")\n",
    "train, test, features = datasets.fe_variance_threshold(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:25:48.848927Z",
     "start_time": "2020-11-05T23:22:13.873587Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1078 features. train.shape: (23814, 1080). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:43<00:00, 32.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0164885426626139\n",
      "Our out of folds log loss for our seed blend model is 0.0164885426626139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:25:48] - model_type:4l, oof:0.0164885, train_flag:train\n",
      "4l\tfeature_eng: RankGauss → pca → variance_threshold → Kmean\t0.0164885\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: RankGauss → pca → variance_threshold → Kmean\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=600, n_components_c=50, SEED=42\n",
    ")\n",
    "train, test, features = datasets.fe_variance_threshold(train, test)\n",
    "train, test, features = datasets.fe_cluster(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:29:28.993444Z",
     "start_time": "2020-11-05T23:25:48.850921Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1193 features. train.shape: (23814, 1195). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:42<00:00, 32.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016528910127349562\n",
      "Our out of folds log loss for our seed blend model is 0.016528910127349562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:29:28] - model_type:4l, oof:0.0165289, train_flag:train\n",
      "4l\tfeature_eng: RankGauss → pca → variance_threshold → Kmean → fe_stats flag_add=False → c_squared\t0.0165289\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: RankGauss → pca → variance_threshold → Kmean → fe_stats flag_add=False → c_squared\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=600, n_components_c=50, SEED=42\n",
    ")\n",
    "train, test, features = datasets.fe_variance_threshold(train, test)\n",
    "train, test, features = datasets.fe_cluster(train, test)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:33:07.974137Z",
     "start_time": "2020-11-05T23:29:28.994435Z"
    },
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1193 features. train.shape: (23814, 1195). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:33<00:00, 30.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016533685746245374\n",
      "Our out of folds log loss for our seed blend model is 0.016533685746245374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:33:07] - model_type:4l, oof:0.0165337, train_flag:train\n",
      "4l\tfeature_eng: RankGauss → pca → variance_threshold → Kmean → scaling(RobustScaler)→ fe_stats flag_add=False → c_squared\t0.0165337\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: RankGauss → pca → variance_threshold → Kmean → scaling(RobustScaler)→ fe_stats flag_add=False → c_squared\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=600, n_components_c=50, SEED=42\n",
    ")\n",
    "train, test, features = datasets.fe_variance_threshold(train, test)\n",
    "train, test, features = datasets.fe_cluster(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:36:34.340716Z",
     "start_time": "2020-11-05T23:33:07.975135Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1293 features. train.shape: (23814, 1295). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016493835431063784\n",
      "Our out of folds log loss for our seed blend model is 0.016493835431063784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:36:34] - model_type:4l, oof:0.0164938, train_flag:train\n",
      "4l\tfeature_eng: RankGauss → pca → variance_threshold → Kmean → fe_stats flag_add=False → c_squared → c_abs → scaling(RobustScaler)\t0.0164938\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: RankGauss → pca → variance_threshold → Kmean → fe_stats flag_add=False → c_squared → c_abs → scaling(RobustScaler)\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=600, n_components_c=50, SEED=42\n",
    ")\n",
    "train, test, features = datasets.fe_variance_threshold(train, test)\n",
    "train, test, features = datasets.fe_cluster(train, test)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:39:26.870998Z",
     "start_time": "2020-11-05T23:36:34.341689Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:33<00:00, 30.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016413690246593705\n",
      "Our out of folds log loss for our seed blend model is 0.016413690246593705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:39:26] - model_type:4l, oof:0.0164137, train_flag:train\n",
      "4l\tfeature_eng: scaling(RobustScaler)\t0.0164137\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: scaling(RobustScaler)\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:42:04.506151Z",
     "start_time": "2020-11-05T23:39:26.871970Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016415946929797816\n",
      "Our out of folds log loss for our seed blend model is 0.016415946929797816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:42:04] - model_type:4l, oof:0.0164159, train_flag:train\n",
      "4l\tfeature_eng: scaling(StandardScaler)\t0.0164159\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: scaling(StandardScaler)\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.scaling(train, test, scaler=StandardScaler())\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:45:17.522436Z",
     "start_time": "2020-11-05T23:42:04.507124Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 898 features. train.shape: (23814, 900). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:46<00:00, 33.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01638532914324773\n",
      "Our out of folds log loss for our seed blend model is 0.01638532914324773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:45:17] - model_type:4l, oof:0.0163853, train_flag:train\n",
      "4l\tfeature_eng: fe_stats flag_add=True\t0.0163853\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: fe_stats flag_add=True\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=True)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:48:11.211745Z",
     "start_time": "2020-11-05T23:45:17.522436Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 889 features. train.shape: (23814, 891). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:31<00:00, 30.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016398407289922035\n",
      "Our out of folds log loss for our seed blend model is 0.016398407289922035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:48:11] - model_type:4l, oof:0.0163984, train_flag:train\n",
      "4l\tfeature_eng: fe_stats flag_add=False\t0.0163984\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: fe_stats flag_add=False\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:50:54.226174Z",
     "start_time": "2020-11-05T23:48:11.212718Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 879 features. train.shape: (23814, 881). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:25<00:00, 29.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016411038796386595\n",
      "Our out of folds log loss for our seed blend model is 0.016411038796386595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:50:54] - model_type:4l, oof:0.016411, train_flag:train\n",
      "4l\tfeature_eng: fe_stats g only\t0.016411\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: fe_stats g only\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, params=[\"g\"])\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:53:46.591403Z",
     "start_time": "2020-11-05T23:50:54.227171Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 879 features. train.shape: (23814, 881). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:36<00:00, 31.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016420352734854742\n",
      "Our out of folds log loss for our seed blend model is 0.016420352734854742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:53:46] - model_type:4l, oof:0.0164204, train_flag:train\n",
      "4l\tfeature_eng: fe_stats c only\t0.0164204\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: fe_stats c only\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, params=[\"c\"])\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:56:57.129539Z",
     "start_time": "2020-11-05T23:53:46.592376Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 884 features. train.shape: (23814, 886). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:51<00:00, 34.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01637087886593117\n",
      "Our out of folds log loss for our seed blend model is 0.01637087886593117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:56:57] - model_type:4l, oof:0.0163709, train_flag:train\n",
      "4l\tfeature_eng: fe_stats g,c\t0.0163709\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: fe_stats g,c\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, params=[\"g\", \"c\"])\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T23:59:49.986295Z",
     "start_time": "2020-11-05T23:56:57.130536Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 879 features. train.shape: (23814, 881). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016413121856755565\n",
      "Our out of folds log loss for our seed blend model is 0.016413121856755565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 08:59:49] - model_type:4l, oof:0.0164131, train_flag:train\n",
      "4l\tfeature_eng: fe_stats gc only\t0.0164131\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: fe_stats gc only\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, params=[\"gc\"])\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:02:53.808006Z",
     "start_time": "2020-11-05T23:59:49.987268Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 898 features. train.shape: (23814, 900). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:33<00:00, 30.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016382322838011405\n",
      "Our out of folds log loss for our seed blend model is 0.016382322838011405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:02:53] - model_type:4l, oof:0.0163823, train_flag:train\n",
      "4l\tfeature_eng: scaling → fe_stats flag_add=True\t0.0163823\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: scaling → fe_stats flag_add=True\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.scaling(\n",
    "    train, test\n",
    ")  # fe_statsの後にするとinfエラーが出て実行できない(infないんだけどなあ。。。)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=True)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.397411Z",
     "start_time": "2020-11-06T00:02:53.808978Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1646 features. train.shape: (23814, 1648). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [01:11<04:46, 71.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-39928c7a1c6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m ) = load_data()\n\u001b[0;32m     10\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_squared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m _, _ = mlp_tf.run_mlp_tf_logger(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mrun_mlp_tf_logger\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, logger, model_dir, model_type, seeds, str_condition, p_min, is_train, tabnet_params)\u001b[0m\n\u001b[0;32m   1354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m         test_pred, oof_pred = train_and_evaluate(\n\u001b[0m\u001b[0;32m   1357\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, start_predictors, seeds, model_type, model_dir, tabnet_params)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1109\u001b[1;33m                 model.fit(\n\u001b[0m\u001b[0;32m   1110\u001b[0m                     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "str_condition = \"feature_eng: g_squared\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.g_squared(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.398434Z",
     "start_time": "2020-11-05T16:33:57.991Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: g_squared → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.g_squared(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.399406Z",
     "start_time": "2020-11-05T16:33:58.817Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: c_squared\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.400403Z",
     "start_time": "2020-11-05T16:33:59.631Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: c_squared → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.401401Z",
     "start_time": "2020-11-05T16:34:00.834Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: fe_pca\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.401401Z",
     "start_time": "2020-11-05T16:34:01.579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: fe_pca is_fit_train_only=True\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123, is_fit_train_only=True,\n",
    ")\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.402425Z",
     "start_time": "2020-11-05T16:34:02.342Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pcaの値確認\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.402425Z",
     "start_time": "2020-11-05T16:34:03.076Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pcaの値確認\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123, is_fit_train_only=True,\n",
    ")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.403421Z",
     "start_time": "2020-11-05T16:34:03.787Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: fe_pca → scaling(RobustScaler)\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.404417Z",
     "start_time": "2020-11-05T16:34:04.509Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: fe_pca is_fit_train_only=True → scaling(RobustScaler)\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123, is_fit_train_only=True,\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.404417Z",
     "start_time": "2020-11-05T16:34:05.219Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: fe_pca → scaling(StandardScaler)\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test, scaler=StandardScaler())\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.405417Z",
     "start_time": "2020-11-05T16:34:05.955Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split_gc(train, test):\n",
    "    \"\"\"g-,c-で特徴量分ける\"\"\"\n",
    "    features_g = list(train.columns[2:4]) + [\n",
    "        col for col in train.columns if \"g-\" in col\n",
    "    ]\n",
    "    features_c = list(train.columns[2:4]) + [\n",
    "        col for col in train.columns if \"c-\" in col\n",
    "    ]\n",
    "    start_predictors_g = [s for s in mlp_tf.start_predictors if \"g-\" in s]\n",
    "    start_predictors_c = [s for s in mlp_tf.start_predictors if \"c-\" in s]\n",
    "    return (\n",
    "        train[features_g],\n",
    "        test[features_g],\n",
    "        train[features_c],\n",
    "        test[features_c],\n",
    "        features_g,\n",
    "        features_c,\n",
    "        start_predictors_g,\n",
    "        start_predictors_c,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.405417Z",
     "start_time": "2020-11-05T16:34:06.682Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"g- feature only\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, _, _, features, _, start_predictors_g, _ = split_gc(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.406412Z",
     "start_time": "2020-11-05T16:34:07.428Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"g- feature only → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, _, _, features, _, start_predictors_g, _ = split_gc(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.406412Z",
     "start_time": "2020-11-05T16:34:08.202Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"c- feature only\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _, train, test, _, features, _, start_predictors_c = split_gc(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.407419Z",
     "start_time": "2020-11-05T16:34:08.948Z"
    },
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"c- feature only → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _, train, test, _, features, _, start_predictors_c = split_gc(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.408382Z",
     "start_time": "2020-11-05T16:34:09.700Z"
    },
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"feature_eng: c_squared → scaling → fe_stats flag_add=True\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=True)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:30:41.443044Z",
     "start_time": "2020-11-06T00:27:16.147380Z"
    },
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1841 features. train.shape: (23814, 1843). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:50<00:00, 34.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016563169544878083\n",
      "Our out of folds log loss for our seed blend model is 0.016563169544878083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:30:41] - model_type:4l, oof:0.0165632, train_flag:train\n",
      "4l\tfe_stats flag_add=False → g_squared → c_squared → fe_pca → scaling\t0.0165632\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"fe_stats flag_add=False → g_squared → c_squared → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.g_squared(train, test)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.409378Z",
     "start_time": "2020-11-05T16:34:11.237Z"
    },
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = (\n",
    "    \"fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.409378Z",
     "start_time": "2020-11-05T16:34:11.973Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca is_fit_train_only=True → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123, is_fit_train_only=True,\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.410403Z",
     "start_time": "2020-11-05T16:34:12.746Z"
    },
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_stats flag_add=False → c_squared → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_stats flag_add=False → c_squared → c_abs → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_stats flag_add=False → c_squared → c_abs → fe_pca → RankGauss\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.c_abs(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_stats flag_add=True → c_squared → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=True)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_ctl_mean\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_ctl_mean gc_flg=g\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test, gc_flg=\"g\")\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_ctl_mean gc_flg=c\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test, gc_flg=\"c\")\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_ctl_mean is_mean=False\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test, is_mean=False)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.411374Z",
     "start_time": "2020-11-05T16:34:13.538Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_ctl_mean is_ratio=False\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test, is_ratio=False)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.411374Z",
     "start_time": "2020-11-05T16:34:14.386Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_ctl_mean → fe_variance_threshold\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test)\n",
    "train, test, features = datasets.fe_variance_threshold(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.412371Z",
     "start_time": "2020-11-05T16:34:15.181Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_ctl_mean → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test)\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.412371Z",
     "start_time": "2020-11-05T16:34:15.956Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_ctl_mean → RankGauss\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_ctl_mean(train, test)\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.413369Z",
     "start_time": "2020-11-05T16:34:16.700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"RankGauss → fe_ctl_mean → fe_variance_threshold\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test = datasets.fe_quantile_transformer(train, test)\n",
    "train, test, features = datasets.fe_ctl_mean(train, test)\n",
    "train, test, features = datasets.fe_variance_threshold(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.414366Z",
     "start_time": "2020-11-05T16:34:17.498Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_stats flag_add=False → c_squared → g_valid → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.414366Z",
     "start_time": "2020-11-05T16:34:18.242Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str_condition = \"fe_stats flag_add=False → c_squared → fe_ctl_mean → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.fe_ctl_mean(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")\n",
    "str_condition = \"fe_stats flag_add=False → c_squared → g_valid → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.g_valid(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.417358Z",
     "start_time": "2020-11-05T16:34:20.618Z"
    }
   },
   "outputs": [],
   "source": [
    "str_condition = (\n",
    "    \"targets_nonscored + fe_stats flag_add=False → c_squared  → fe_pca → scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_conat_nonscore=True\n",
    ")\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:27:16.146410Z",
     "start_time": "2020-11-06T00:24:41.596071Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 1069 features. train.shape: (23814, 1071). train_targets.shape: (23814, 538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:04<00:00, 24.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01670923842194732\n",
      "Our out of folds log loss for our seed blend model is 0.01670923842194732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:27:16] - model_type:rs, oof:0.0167092, train_flag:train\n",
      "rs\ttargets_nonscored + fe_stats flag_add=False → c_squared  → fe_pca → scaling\t0.0167092\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = (\n",
    "    \"targets_nonscored + fe_stats flag_add=False → c_squared  → fe_pca → scaling\"\n",
    ")\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_conat_nonscore=True\n",
    ")\n",
    "train, test, features = datasets.fe_stats(train, test, flag_add=False)\n",
    "train, test, features = datasets.c_squared(train, test)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train, test, n_components_g=70, n_components_c=10, SEED=123\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"rs\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T03:22:25.893101Z",
     "start_time": "2020-11-06T03:06:40.604368Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:200, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 1516 features. train.shape: (23814, 1518). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [03:03<12:14, 183.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [05:52<08:57, 179.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [08:57<06:01, 180.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [11:57<03:00, 180.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [15:02<00:00, 180.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016937076643232404\n",
      "Our out of folds log loss for our seed blend model is 0.016937076643232404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:22:25] - model_type:stack_tabnet, oof:0.0169371, train_flag:train\n",
      "stack_tabnet\tEPOCHS = 200 + start_predictors → fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0169371\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"EPOCHS = 200 + start_predictors → fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_conat_nonscore=False\n",
    ")\n",
    "\n",
    "features_g, features_c = datasets.get_features_gc(\n",
    "    train, top_feat_cols=mlp_tf.start_predictors\n",
    ")\n",
    "\n",
    "train, test, features = datasets.fe_stats(\n",
    "    train, test, flag_add=False, features_g=features_g, features_c=features_c\n",
    ")\n",
    "train, test, features = datasets.c_squared(train, test, features_c=features_c)\n",
    "train, test, features = datasets.c_abs(train, test, features_c=features_c)\n",
    "train, test, features = datasets.g_valid(train, test, features_g=features_g)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train,\n",
    "    test,\n",
    "    n_components_g=70,\n",
    "    n_components_c=10,\n",
    "    SEED=123,\n",
    "    features_g=features_g,\n",
    "    features_c=features_c,\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "\n",
    "mlp_tf.EPOCHS = 200\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"stack_tabnet\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T03:25:54.226453Z",
     "start_time": "2020-11-06T03:22:25.894074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 1516 features. train.shape: (23814, 1518). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:46<00:00, 33.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016312127472810176\n",
      "Our out of folds log loss for our seed blend model is 0.016312127472810176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:25:54] - model_type:4l, oof:0.0163121, train_flag:train\n",
      "4l\tstart_predictors → fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\t0.0163121\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"start_predictors → fe_stats flag_add=False → c_squared → c_abs → g_valid → fe_pca → scaling\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_conat_nonscore=False\n",
    ")\n",
    "\n",
    "features_g, features_c = datasets.get_features_gc(\n",
    "    train, top_feat_cols=mlp_tf.start_predictors\n",
    ")\n",
    "\n",
    "train, test, features = datasets.fe_stats(\n",
    "    train, test, flag_add=False, features_g=features_g, features_c=features_c\n",
    ")\n",
    "train, test, features = datasets.c_squared(train, test, features_c=features_c)\n",
    "train, test, features = datasets.c_abs(train, test, features_c=features_c)\n",
    "train, test, features = datasets.g_valid(train, test, features_g=features_g)\n",
    "train, test, features = datasets.fe_pca(\n",
    "    train,\n",
    "    test,\n",
    "    n_components_g=70,\n",
    "    n_components_c=10,\n",
    "    SEED=123,\n",
    "    features_g=features_g,\n",
    "    features_c=features_c,\n",
    ")\n",
    "train, test, features = datasets.scaling(train, test)\n",
    "\n",
    "mlp_tf.EPOCHS = 80\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.419353Z",
     "start_time": "2020-11-05T16:34:23.323Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.001\n",
    "mlp_tf.BATCH_SIZE = 256\n",
    "mlp_tf.EPOCHS = 80\n",
    "\n",
    "str_condition = \"no feature_eng + batch_size=256\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.419353Z",
     "start_time": "2020-11-05T16:34:24.074Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.001\n",
    "mlp_tf.BATCH_SIZE = 1024\n",
    "mlp_tf.EPOCHS = 80\n",
    "\n",
    "str_condition = \"no feature_eng + batch_size=1024\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.420350Z",
     "start_time": "2020-11-05T16:34:24.835Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.001\n",
    "mlp_tf.BATCH_SIZE = 64\n",
    "mlp_tf.EPOCHS = 80\n",
    "\n",
    "str_condition = \"no feature_eng + batch_size=64\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(b\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.420350Z",
     "start_time": "2020-11-05T16:34:25.643Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.001\n",
    "mlp_tf.BATCH_SIZE = 32\n",
    "mlp_tf.EPOCHS = 80\n",
    "\n",
    "str_condition = \"no feature_eng + batch_size=32\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.421347Z",
     "start_time": "2020-11-05T16:34:26.366Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.01\n",
    "mlp_tf.BATCH_SIZE = 128\n",
    "mlp_tf.EPOCHS = 80\n",
    "\n",
    "str_condition = \"no feature_eng + LR=0.01\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.421347Z",
     "start_time": "2020-11-05T16:34:27.094Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.01\n",
    "mlp_tf.BATCH_SIZE = 128\n",
    "mlp_tf.EPOCHS = 100\n",
    "\n",
    "str_condition = \"no feature_eng + LR=0.01 + epochs=100\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.422345Z",
     "start_time": "2020-11-05T16:34:27.815Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.1\n",
    "mlp_tf.BATCH_SIZE = 128\n",
    "mlp_tf.EPOCHS = 80\n",
    "\n",
    "str_condition = \"no feature_eng + LR=0.1\"\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    ") = load_data()\n",
    "_, _ = mlp_tf.run_mlp_tf_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_type=\"4l\",\n",
    "    str_condition=str_condition,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.422345Z",
     "start_time": "2020-11-05T16:34:28.599Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp_tf.LR = 0.001\n",
    "mlp_tf.BATCH_SIZE = 128\n",
    "mlp_tf.EPOCHS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T02:20:48.206636Z",
     "start_time": "2020-11-06T01:51:36.922192Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d8a0b3b2a08c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"sig_id\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mtrain_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sig_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mnelder_mead_weights_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_targets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0moof_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moof_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moof_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-d8a0b3b2a08c>\u001b[0m in \u001b[0;36mnelder_mead_weights_class\u001b[1;34m(y_true, oof_preds, method)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# http://www.kamishima.net/mlmpyja/lr/optimization.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mbnds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         result = minimize(\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    615\u001b[0m                                   **options)\n\u001b[0;32m    616\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    618\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    619\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0m\u001b[0;32m     92\u001b[0m                                            **finite_diff_options)\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0m\u001b[0;32m    427\u001b[0m                                      use_one_sided, method)\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'3-point'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-d8a0b3b2a08c>\u001b[0m in \u001b[0;36mopt\u001b[1;34m(ws, y_true, y_preds)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mws\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmlp_tf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_log_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0minitial_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mmean_log_loss\u001b[1;34m(y_true, y_pred, n_class, p_min)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   2204\u001b[0m                              'got {0}.'.format(lb.classes_))\n\u001b[0;32m   2205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2206\u001b[1;33m     \u001b[0mtransformed_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtransformed_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    486\u001b[0m                              \" input.\")\n\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         return label_binarize(y, classes=self.classes_,\n\u001b[0m\u001b[0;32m    489\u001b[0m                               \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m                               \u001b[0mneg_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[1;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0my_in_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[0my_seen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_in_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_seen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_in_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \"\"\"\n\u001b[1;32m-> 1341\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'searchsorted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mside\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mside\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def nelder_mead_weights_class(y_true: np.ndarray, oof_preds: list, method=\"L-BFGS-B\"):\n",
    "    \"\"\"ネルダーミードでモデルのクラスごとのブレンド重み最適化\n",
    "    ネルダーミード遅いから、L-BFGS-B をデフォルトの方法にする.重みクラス数文あるのでめちゃめちゃ時間かかる。。。\"\"\"\n",
    "    from scipy.optimize import minimize\n",
    "\n",
    "    def opt(ws, y_true, y_preds):\n",
    "        y_pred = None\n",
    "        for y_p in y_preds:\n",
    "            if y_pred is None:\n",
    "                y_pred = ws * y_p\n",
    "            else:\n",
    "                y_pred += ws * y_p\n",
    "        return mlp_tf.mean_log_loss(y_true, y_pred)\n",
    "\n",
    "    initial_weights = np.array([1.0 / y_true.shape[1]] * y_true.shape[1])\n",
    "    if method in [\"L-BFGS-B\", \"TNC\", \"COBYLA \", \"SLSQP\"]:\n",
    "        # パラメータの範囲に制約のある方法で最適化\n",
    "        # 1位の人は L-BFGS-B 使ってたので\n",
    "        # https://www.kaggle.com/gogo827jz/optimise-blending-weights-with-bonus-0\n",
    "        # パラメータの範囲は bounds に，最小値と最大値の対の系列を指定する必要あり\n",
    "        # http://www.kamishima.net/mlmpyja/lr/optimization.html\n",
    "        bnds = [(0, 1) for _ in range(y_true.shape[1])]\n",
    "        result = minimize(\n",
    "            opt,\n",
    "            x0=initial_weights,\n",
    "            args=(y_true, oof_preds),\n",
    "            method=method,\n",
    "            bounds=bnds,\n",
    "        )\n",
    "    else:\n",
    "        result = minimize(\n",
    "            opt, x0=initial_weights, args=(y_true, oof_preds), method=method\n",
    "        )\n",
    "    best_weights = result.x\n",
    "    return best_weights\n",
    "\n",
    "\n",
    "if \"sig_id\" in train_targets.columns:\n",
    "    train_targets = train_targets.drop([\"sig_id\"], axis=1)\n",
    "best_weights = nelder_mead_weights_class(train_targets.values,  [oof_pred, oof_pred * 2, oof_pred * 3])\n",
    "best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_mlp_tf_blend_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:08:53.508869Z",
     "start_time": "2020-11-06T00:44:33.545806Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:10<00:00, 38.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.020377357356507884\n",
      "Our out of folds log loss for our seed blend model is 0.020377357356507884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:47:58] - model_type:2l, oof:0.0203774, train_flag:train\n",
      "2l\tposi_ratio_class_weight\t0.0203774\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:18<00:00, 51.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.019795284234599194\n",
      "Our out of folds log loss for our seed blend model is 0.019795284234599194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:52:29] - model_type:3l, oof:0.0197953, train_flag:train\n",
      "3l\tposi_ratio_class_weight\t0.0197953\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:36<00:00, 31.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.020244723716548098\n",
      "Our out of folds log loss for our seed blend model is 0.020244723716548098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 09:55:17] - model_type:4l, oof:0.0202447, train_flag:train\n",
      "4l\tposi_ratio_class_weight\t0.0202447\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:33<00:00, 54.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.020380464968796662\n",
      "Our out of folds log loss for our seed blend model is 0.020380464968796662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 10:00:03] - model_type:5l, oof:0.0203805, train_flag:train\n",
      "5l\tposi_ratio_class_weight\t0.0203805\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:34<00:00, 18.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016729138834169623\n",
      "Our out of folds log loss for our seed blend model is 0.016729138834169623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 10:01:49] - model_type:rs, oof:0.0167291, train_flag:train\n",
      "rs\tposi_ratio_class_weight\t0.0167291\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model stack_tabnet with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:51<03:25, 51.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:43<02:34, 51.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:30<01:40, 50.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [03:17<00:49, 49.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:06<00:00, 49.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.019378261918031478\n",
      "Our out of folds log loss for our seed blend model is 0.019378261918031478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 10:06:07] - model_type:stack_tabnet, oof:0.0193783, train_flag:train\n",
      "stack_tabnet\tposi_ratio_class_weight\t0.0193783\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model tabnet_class with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:29<01:56, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [00:54<01:24, 28.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:25<00:57, 28.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [01:55<00:29, 29.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: None\n",
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:28<00:00, 29.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.019247927762780635\n",
      "Our out of folds log loss for our seed blend model is 0.019247927762780635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 10:08:48] - model_type:tabnet_class, oof:0.0192479, train_flag:train\n",
      "tabnet_class\tposi_ratio_class_weight\t0.0192479\ttrain\n",
      "[2020-11-06 10:08:51] - model_type:2l-3l-4l-5l-rs-stack_tabnet-tabnet_class, oof:0.0222129, train_flag:train\n",
      "2l-3l-4l-5l-rs-stack_tabnet-tabnet_class\tposi_ratio_class_weight:Mean blend\t0.0222129\ttrain\n"
     ]
    }
   ],
   "source": [
    "str_condition = \"posi_ratio_class_weight\"\n",
    "\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored\n",
    ")\n",
    "features = datasets.get_features(train)\n",
    "\n",
    "mlp_tf.run_mlp_tf_blend_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_types=[\n",
    "        \"2l\",\n",
    "        \"3l\",\n",
    "        \"4l\",\n",
    "        \"5l\",\n",
    "        \"rs\",\n",
    "        \"stack_tabnet\",\n",
    "        \"tabnet_class\",\n",
    "    ],\n",
    "    str_condition=str_condition,\n",
    "    class_weight = datasets.fetch_posi_ratio_class_weight(train_targets),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T01:11:21.819895Z",
     "start_time": "2020-11-06T01:08:53.509837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.001\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 538)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [02:21<03:32, 70.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3c26f3199c20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m mlp_tf.run_mlp_tf_blend_logger(\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mrun_mlp_tf_blend_logger\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, logger, model_dir, seeds, str_condition, model_types, is_train, class_weight, is_nelder)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm_t\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m         \u001b[0m_run_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_condition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m     \u001b[0mmodel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m     \u001b[0mmean_oof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moof_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36m_run_model\u001b[1;34m(_model_type, _str_condition)\u001b[0m\n\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_model_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_str_condition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         test_pred, oof_pred = run_mlp_tf_logger(\n\u001b[0m\u001b[0;32m   1430\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mrun_mlp_tf_logger\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, logger, model_dir, model_type, seeds, str_condition, p_min, is_train, tabnet_params, class_weight)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m         \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         test_pred, oof_pred = train_and_evaluate(\n\u001b[0m\u001b[0;32m   1360\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, start_predictors, seeds, model_type, model_dir, tabnet_params, class_weight)\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m                 model.fit(\n\u001b[0m\u001b[0;32m   1111\u001b[0m                     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \"\"\"\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "str_condition = \"no feature_eng + posi_ratio_class_weight + targets_nonscored\"\n",
    "\n",
    "(\n",
    "    train,\n",
    "    train_targets,\n",
    "    test,\n",
    "    sample_submission,\n",
    "    train_targets_nonscored,\n",
    "    train_drug,\n",
    ") = datasets.load_orig_data()\n",
    "train, train_targets, test, train_targets_nonscored = datasets.mapping_and_filter(\n",
    "    train, train_targets, test, train_targets_nonscored, is_conat_nonscore=True\n",
    ")\n",
    "features = datasets.get_features(train)\n",
    "\n",
    "mlp_tf.run_mlp_tf_blend_logger(\n",
    "    train,\n",
    "    test,\n",
    "    train_targets,\n",
    "    features,\n",
    "    train_targets_nonscored,\n",
    "    model_types=[\n",
    "        \"2l\",\n",
    "        \"3l\",\n",
    "        \"4l\",\n",
    "        \"5l\",\n",
    "        \"rs\",\n",
    "        \"stack_tabnet\",\n",
    "        \"tabnet_class\",\n",
    "    ],\n",
    "    str_condition=str_condition,\n",
    "    class_weight = datasets.fetch_posi_ratio_class_weight(train_targets),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:56:04.768207Z",
     "start_time": "2020-11-06T03:25:54.227450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:17<00:00, 27.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01629360464586551\n",
      "Our out of folds log loss for our seed blend model is 0.01629360464586551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:28:26] - model_type:2l, oof:0.0162936, train_flag:train\n",
      "2l\tno feature_eng + learning rate=0.1\t0.0162936\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:02<00:00, 36.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016479810097414036\n",
      "Our out of folds log loss for our seed blend model is 0.016479810097414036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:31:41] - model_type:3l, oof:0.0164798, train_flag:train\n",
      "3l\tno feature_eng + learning rate=0.1\t0.0164798\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017893354010365767\n",
      "Our out of folds log loss for our seed blend model is 0.017893354010365767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:34:13] - model_type:4l, oof:0.0178934, train_flag:train\n",
      "4l\tno feature_eng + learning rate=0.1\t0.0178934\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:06<00:00, 49.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.018318113739454897\n",
      "Our out of folds log loss for our seed blend model is 0.018318113739454897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:38:32] - model_type:5l, oof:0.0183181, train_flag:train\n",
      "5l\tno feature_eng + learning rate=0.1\t0.0183181\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:58<00:00, 23.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01668373093245185\n",
      "Our out of folds log loss for our seed blend model is 0.01668373093245185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:40:42] - model_type:rs, oof:0.0166837, train_flag:train\n",
      "rs\tno feature_eng + learning rate=0.1\t0.0166837\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.1\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:48<03:13, 48.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:26<02:15, 45.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:08<01:28, 44.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:51<00:43, 43.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:33<00:00, 42.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016559056910483802\n",
      "Our out of folds log loss for our seed blend model is 0.016559056910483802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:44:28] - model_type:3l_v2, oof:0.0165591, train_flag:train\n",
      "3l_v2\tno feature_eng + learning rate=0.1\t0.0165591\ttrain\n",
      "[2020-11-06 12:44:31] - model_type:2l-3l-4l-5l-rs-3l_v2, oof:0.0195798, train_flag:train\n",
      "2l-3l-4l-5l-rs-3l_v2\tno feature_eng + learning rate=0.1:Mean blend\t0.0195798\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:17<00:00, 27.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0163090129507107\n",
      "Our out of folds log loss for our seed blend model is 0.0163090129507107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:47:06] - model_type:2l, oof:0.016309, train_flag:train\n",
      "2l\tno feature_eng + learning rate=0.01\t0.016309\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:40<00:00, 32.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016552306380958358\n",
      "Our out of folds log loss for our seed blend model is 0.016552306380958358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:49:58] - model_type:3l, oof:0.0165523, train_flag:train\n",
      "3l\tno feature_eng + learning rate=0.01\t0.0165523\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:13<00:00, 26.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01650613488110208\n",
      "Our out of folds log loss for our seed blend model is 0.01650613488110208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:52:24] - model_type:4l, oof:0.0165061, train_flag:train\n",
      "4l\tno feature_eng + learning rate=0.01\t0.0165061\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [04:07<00:00, 49.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016467797921902057\n",
      "Our out of folds log loss for our seed blend model is 0.016467797921902057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:56:44] - model_type:5l, oof:0.0164678, train_flag:train\n",
      "5l\tno feature_eng + learning rate=0.01\t0.0164678\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:36<00:00, 19.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016764920037609522\n",
      "Our out of folds log loss for our seed blend model is 0.016764920037609522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 12:58:33] - model_type:rs, oof:0.0167649, train_flag:train\n",
      "rs\tno feature_eng + learning rate=0.01\t0.0167649\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.01\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:37<02:30, 37.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:18<01:56, 38.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [02:01<01:20, 40.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:44<00:40, 40.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:26<00:00, 41.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0165326105552723\n",
      "Our out of folds log loss for our seed blend model is 0.0165326105552723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:02:12] - model_type:3l_v2, oof:0.0165326, train_flag:train\n",
      "3l_v2\tno feature_eng + learning rate=0.01\t0.0165326\ttrain\n",
      "[2020-11-06 13:02:15] - model_type:2l-3l-4l-5l-rs-3l_v2, oof:0.0194456, train_flag:train\n",
      "2l-3l-4l-5l-rs-3l_v2\tno feature_eng + learning rate=0.01:Mean blend\t0.0194456\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.03\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:15<00:00, 27.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016309155180820326\n",
      "Our out of folds log loss for our seed blend model is 0.016309155180820326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:04:48] - model_type:2l, oof:0.0163092, train_flag:train\n",
      "2l\tno feature_eng + learning rate=0.03\t0.0163092\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.03\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:06<00:00, 37.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016441239017141604\n",
      "Our out of folds log loss for our seed blend model is 0.016441239017141604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:08:08] - model_type:3l, oof:0.0164412, train_flag:train\n",
      "3l\tno feature_eng + learning rate=0.03\t0.0164412\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.03\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [02:42<00:00, 32.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016522766828745712\n",
      "Our out of folds log loss for our seed blend model is 0.016522766828745712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:11:02] - model_type:4l, oof:0.0165228, train_flag:train\n",
      "4l\tno feature_eng + learning rate=0.03\t0.0165228\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.03\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:01<00:00, 60.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016509644760712743\n",
      "Our out of folds log loss for our seed blend model is 0.016509644760712743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:16:17] - model_type:5l, oof:0.0165096, train_flag:train\n",
      "5l\tno feature_eng + learning rate=0.03\t0.0165096\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.03\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [01:48<00:00, 21.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01661659336061307\n",
      "Our out of folds log loss for our seed blend model is 0.01661659336061307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:18:18] - model_type:rs, oof:0.0166166, train_flag:train\n",
      "rs\tno feature_eng + learning rate=0.03\t0.0166166\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.03\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [00:36<02:26, 36.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [01:10<01:47, 35.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [01:52<01:15, 37.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [02:30<00:37, 37.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:11<00:00, 38.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.0165810370858479\n",
      "Our out of folds log loss for our seed blend model is 0.0165810370858479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:21:41] - model_type:3l_v2, oof:0.016581, train_flag:train\n",
      "3l_v2\tno feature_eng + learning rate=0.03\t0.016581\ttrain\n",
      "[2020-11-06 13:21:44] - model_type:2l-3l-4l-5l-rs-3l_v2, oof:0.0194162, train_flag:train\n",
      "2l-3l-4l-5l-rs-3l_v2\tno feature_eng + learning rate=0.03:Mean blend\t0.0194162\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [07:18<00:00, 87.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017101819973575468\n",
      "Our out of folds log loss for our seed blend model is 0.017101819973575468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:29:21] - model_type:2l, oof:0.0171018, train_flag:train\n",
      "2l\tno feature_eng + learning rate=0.0001\t0.0171018\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [09:17<00:00, 111.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01668167289082721\n",
      "Our out of folds log loss for our seed blend model is 0.01668167289082721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:38:50] - model_type:3l, oof:0.0166817, train_flag:train\n",
      "3l\tno feature_eng + learning rate=0.0001\t0.0166817\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:05<00:00, 61.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016717266298590026\n",
      "Our out of folds log loss for our seed blend model is 0.016717266298590026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:44:07] - model_type:4l, oof:0.0167173, train_flag:train\n",
      "4l\tno feature_eng + learning rate=0.0001\t0.0167173\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [09:00<00:00, 108.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.01678912651831522\n",
      "Our out of folds log loss for our seed blend model is 0.01678912651831522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:53:20] - model_type:5l, oof:0.0167891, train_flag:train\n",
      "5l\tno feature_eng + learning rate=0.0001\t0.0167891\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [03:33<00:00, 42.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017214808622152595\n",
      "Our out of folds log loss for our seed blend model is 0.017214808622152595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 13:57:06] - model_type:rs, oof:0.0172148, train_flag:train\n",
      "rs\tno feature_eng + learning rate=0.0001\t0.0172148\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:0.0001\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [01:20<05:21, 80.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [02:36<03:57, 79.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [04:01<02:41, 80.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [05:27<01:22, 82.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [07:02<00:00, 84.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.016688681342558014\n",
      "Our out of folds log loss for our seed blend model is 0.016688681342558014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 14:04:20] - model_type:3l_v2, oof:0.0166887, train_flag:train\n",
      "3l_v2\tno feature_eng + learning rate=0.0001\t0.0166887\ttrain\n",
      "[2020-11-06 14:04:23] - model_type:2l-3l-4l-5l-rs-3l_v2, oof:0.0193497, train_flag:train\n",
      "2l-3l-4l-5l-rs-3l_v2\tno feature_eng + learning rate=0.0001:Mean blend\t0.0193497\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [07:21<00:00, 88.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.61891520334827\n",
      "Our out of folds log loss for our seed blend model is 0.61891520334827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 14:12:02] - model_type:2l, oof:0.6189152, train_flag:train\n",
      "2l\tno feature_eng + learning rate=1e-05\t0.6189152\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model 3l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [06:25<00:00, 77.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.5011191993271764\n",
      "Our out of folds log loss for our seed blend model is 0.5011191993271764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 14:18:39] - model_type:3l, oof:0.5011192, train_flag:train\n",
      "3l\tno feature_eng + learning rate=1e-05\t0.5011192\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model 4l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [05:55<00:00, 71.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.033350194709295886\n",
      "Our out of folds log loss for our seed blend model is 0.033350194709295886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 14:24:47] - model_type:4l, oof:0.0333502, train_flag:train\n",
      "4l\tno feature_eng + learning rate=1e-05\t0.0333502\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model 5l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [10:46<00:00, 129.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.04217435833416406\n",
      "Our out of folds log loss for our seed blend model is 0.04217435833416406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 14:35:46] - model_type:5l, oof:0.0421744, train_flag:train\n",
      "5l\tno feature_eng + learning rate=1e-05\t0.0421744\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model rs with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [06:49<00:00, 81.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.06789557334638874\n",
      "Our out of folds log loss for our seed blend model is 0.06789557334638874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 14:42:47] - model_type:rs, oof:0.0678956, train_flag:train\n",
      "rs\tno feature_eng + learning rate=1e-05\t0.0678956\ttrain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:128, LR:1e-05\n",
      "Using model 3l_v2 with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 1/5 [02:35<10:23, 155.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 2/5 [05:10<07:46, 155.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 3/5 [07:46<05:11, 155.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 4/5 [10:22<02:35, 155.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPlease check your arguments if you have upgraded adabelief-tf from version 0.0.1.\n",
      "\u001b[31mModifications to default arguments:\n",
      "\u001b[31m                           eps  weight_decouple    rectify\n",
      "-----------------------  -----  -----------------  -------------\n",
      "adabelief-tf=0.0.1       1e-08  Not supported      Not supported\n",
      "Current version (0.1.0)  1e-14  supported          default: True\n",
      "\u001b[31mFor a complete table of recommended hyperparameters, see\n",
      "\u001b[31mhttps://github.com/juntang-zhuang/Adabelief-Optimizer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [12:59<00:00, 155.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds mean log loss score is 0.017427688232432625\n",
      "Our out of folds log loss for our seed blend model is 0.017427688232432625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-11-06 14:55:59] - model_type:3l_v2, oof:0.0174277, train_flag:train\n",
      "3l_v2\tno feature_eng + learning rate=1e-05\t0.0174277\ttrain\n",
      "[2020-11-06 14:56:02] - model_type:2l-3l-4l-5l-rs-3l_v2, oof:0.0381998, train_flag:train\n",
      "2l-3l-4l-5l-rs-3l_v2\tno feature_eng + learning rate=1e-05:Mean blend\t0.0381998\ttrain\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.1, 0.01, 0.03, 0.0001, 0.00001]:\n",
    "    mlp_tf.LR = lr\n",
    "    str_condition = f\"no feature_eng + learning rate={mlp_tf.LR}\"\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    mlp_tf.run_mlp_tf_blend_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        str_condition=str_condition,\n",
    "        model_types=[\n",
    "            \"2l\",\n",
    "            \"3l\",\n",
    "            \"4l\",\n",
    "            \"5l\",\n",
    "            \"rs\",\n",
    "            \"3l_v2\",\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "mlp_tf.LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:16:46.069752Z",
     "start_time": "2020-11-06T05:56:04.769175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:5, epochs:80, batch_size:8, LR:0.001\n",
      "Using model 2l with seed 123 for train_and_evaluate\n",
      "Trained with 874 features. train.shape: (23814, 876). train_targets.shape: (23814, 207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▊                                                 | 2/5 [20:37<30:55, 618.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-522e19f667fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtrain_targets_nonscored\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     ) = load_data()\n\u001b[1;32m---> 12\u001b[1;33m     mlp_tf.run_mlp_tf_blend_logger(\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mrun_mlp_tf_blend_logger\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, logger, model_dir, seeds, str_condition, model_types, is_train, class_weight, is_nelder)\u001b[0m\n\u001b[0;32m   1547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm_t\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1549\u001b[1;33m         \u001b[0m_run_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_condition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1550\u001b[0m     \u001b[0mmodel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[0mmean_oof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moof_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36m_run_model\u001b[1;34m(_model_type, _str_condition)\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_model_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_str_condition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m         test_pred, oof_pred = run_mlp_tf_logger(\n\u001b[0m\u001b[0;32m   1532\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mrun_mlp_tf_logger\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, logger, model_dir, model_type, seeds, str_condition, p_min, is_train, tabnet_params, class_weight)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m         test_pred, oof_pred = train_and_evaluate(\n\u001b[0m\u001b[0;32m   1462\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\code\\mlp_tf.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(train, test, train_targets, features, train_targets_nonscored, start_predictors, seeds, model_type, model_dir, tabnet_params, class_weight)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m                 model.fit(\n\u001b[0m\u001b[0;32m   1159\u001b[0m                     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\81908\\appdata\\local\\pypoetry\\cache\\virtualenvs\\tfgpu-ehdmne1y-py3.8\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for bs in [8, 32, 128, 512, 1024]:\n",
    "    mlp_tf.BATCH_SIZE = bs\n",
    "    str_condition = f\"no feature_eng + mlp_tf.BATCH_SIZE={mlp_tf.BATCH_SIZE}\"\n",
    "    (\n",
    "        train,\n",
    "        train_targets,\n",
    "        test,\n",
    "        sample_submission,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "    ) = load_data()\n",
    "    mlp_tf.run_mlp_tf_blend_logger(\n",
    "        train,\n",
    "        test,\n",
    "        train_targets,\n",
    "        features,\n",
    "        train_targets_nonscored,\n",
    "        str_condition=str_condition,\n",
    "        model_types=[\n",
    "            \"2l\",\n",
    "            \"3l\",\n",
    "            \"4l\",\n",
    "            \"5l\",\n",
    "            \"rs\",\n",
    "            \"3l_v2\",\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "mlp_tf.BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T00:04:11.423341Z",
     "start_time": "2020-11-05T16:34:29.365Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<button id=\"code-show-switch-btn\">スクリプトを非表示にする</button>\n",
    "\n",
    "<script>\n",
    "var code_show = true;\n",
    "\n",
    "function switch_display_setting() {\n",
    "    var switch_btn = $(\"#code-show-switch-btn\");\n",
    "    if (code_show) {\n",
    "        $(\"div.input\").hide();\n",
    "        code_show = false;\n",
    "        switch_btn.text(\"スクリプトを表示する\");\n",
    "    }else {\n",
    "        $(\"div.input\").show();\n",
    "        code_show = true;\n",
    "        switch_btn.text(\"スクリプトを非表示にする\");\n",
    "    }\n",
    "}\n",
    "\n",
    "$(\"#code-show-switch-btn\").click(switch_display_setting);\n",
    "</script>\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
