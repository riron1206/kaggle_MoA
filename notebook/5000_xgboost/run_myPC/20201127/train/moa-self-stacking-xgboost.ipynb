{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Stacking GroupCV XGBoost\n",
    "\n",
    "In this notebook, I introduce a self-stacking XGBoost (XGB) pipeline. \n",
    "\n",
    "XGB model does not support multi-label learning so it cannot fully learn the label correlation as well as neural networks (NNs). Then I come up with an idea of self-stacking learning for XGB. The purpose is to enhance the label correlation learning by taking the first-stage predictions as additional features for the second-stage learning.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "- XGBoostでself-stacking  \n",
    "第1段階の予測値を第2段階の学習の追加特徴量とし、クラス間の関係性を学習させるのが目的  \n",
    "https://www.kaggle.com/gogo827jz/self-stacking-groupcv-xgboost\n",
    "\n",
    "<br>\n",
    "\n",
    "- ポジティブサンプル(=1)を多く含むターゲットを最初に学習させる\n",
    "oofを保存し、oofの予測値を特徴量として追加することで、ポジティブなサンプル数が少ない学習対象の特徴量を得る  \n",
    "https://www.kaggle.com/underwearfitting/partial-self-stacking-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.426707Z",
     "start_time": "2020-11-28T11:28:07.300396Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "kw1VW6DCvgSq",
    "outputId": "030d81e0-579d-463d-b2ed-6c714151a063"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import joblib\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.430696Z",
     "start_time": "2020-11-28T11:28:09.427704Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    rn.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.435683Z",
     "start_time": "2020-11-28T11:28:09.431694Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "def score(Y, Y_pred):\n",
    "    _, n_classes = Y.shape\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for j in range(n_classes):\n",
    "        loss = log_loss(Y.iloc[:, j], Y_pred.iloc[:, j], labels=[0, 1])\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.443662Z",
     "start_time": "2020-11-28T11:28:09.436681Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def auc_score(Y, Y_pred):\n",
    "    _, n_classes = Y.shape\n",
    "\n",
    "    aucs = []\n",
    "\n",
    "    for j in range(n_classes):\n",
    "        auc = roc_auc_score(Y.iloc[:, j], Y_pred.iloc[:, j])\n",
    "\n",
    "        aucs.append(auc)\n",
    "\n",
    "    return np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.449645Z",
     "start_time": "2020-11-28T11:28:09.445657Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_row_statistics(X, prefix=\"\"):\n",
    "    Xt = pd.DataFrame()\n",
    "\n",
    "    for agg_func in [\n",
    "        # \"min\",\n",
    "        # \"max\",\n",
    "        \"mean\",\n",
    "        \"std\",\n",
    "        \"kurtosis\",\n",
    "        \"skew\",\n",
    "    ]:\n",
    "        Xt[f\"{prefix}{agg_func}\"] = X.agg(agg_func, axis=1)\n",
    "\n",
    "    return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.455629Z",
     "start_time": "2020-11-28T11:28:09.450643Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class ClippedFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, copy=True, high=0.99, low=0.01):\n",
    "        self.copy = copy\n",
    "        self.high = high\n",
    "        self.low = low\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.data_max_ = X.quantile(q=self.high)\n",
    "        self.data_min_ = X.quantile(q=self.low)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.copy:\n",
    "            X = X.copy()\n",
    "\n",
    "        X.clip(self.data_min_, self.data_max_, axis=1, inplace=True)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.467597Z",
     "start_time": "2020-11-28T11:28:09.456627Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "\n",
    "import numpy as np\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "\n",
    "\n",
    "class MultilabelStratifiedGroupKFold(_BaseKFold):\n",
    "    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n",
    "        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "\n",
    "    def _iter_test_indices(self, X=None, y=None, groups=None):\n",
    "        cv = MultilabelStratifiedKFold(\n",
    "            n_splits=self.n_splits,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=self.shuffle,\n",
    "        )\n",
    "\n",
    "        value_counts = groups.value_counts()\n",
    "        regluar_indices = value_counts.loc[\n",
    "            (value_counts == 6) | (value_counts == 12) | (value_counts == 18)\n",
    "        ].index.sort_values()\n",
    "        irregluar_indices = value_counts.loc[\n",
    "            (value_counts != 6) & (value_counts != 12) & (value_counts != 18)\n",
    "        ].index.sort_values()\n",
    "\n",
    "        group_to_fold = {}\n",
    "        tmp = y.groupby(groups).mean().loc[regluar_indices]\n",
    "\n",
    "        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n",
    "            group_to_fold.update({group: fold for group in tmp.index[test]})\n",
    "\n",
    "        sample_to_fold = {}\n",
    "        tmp = y.loc[groups.isin(irregluar_indices)]\n",
    "\n",
    "        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n",
    "            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n",
    "\n",
    "        folds = groups.map(group_to_fold)\n",
    "        is_na = folds.isna()\n",
    "        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            yield np.where(folds == i)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSVuPpi2vgSv"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:09.472584Z",
     "start_time": "2020-11-28T11:28:09.469592Z"
    }
   },
   "outputs": [],
   "source": [
    "#dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\n",
    "#index_col = \"sig_id\"\n",
    "#\n",
    "#train_features = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_features.csv\", dtype=dtype, index_col=index_col\n",
    "#)\n",
    "#X = train_features.select_dtypes(\"number\")\n",
    "#Y_nonscored = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_targets_nonscored.csv\", index_col=index_col\n",
    "#)\n",
    "#Y = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\n",
    "#groups = pd.read_csv(\n",
    "#    \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n",
    "#)\n",
    "#\n",
    "#test_features = pd.read_csv(\n",
    "#    \"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n",
    "#)\n",
    "#X_test = test_features.select_dtypes(\"number\")\n",
    "#\n",
    "#columns = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:12.492629Z",
     "start_time": "2020-11-28T11:28:09.473582Z"
    }
   },
   "outputs": [],
   "source": [
    "DATADIR = (\n",
    "    r\"C:\\Users\\81908\\jupyter_notebook\\poetry_work\\tfgpu\\01_MoA_compe\\input\\lish-moa\"\n",
    ")\n",
    "\n",
    "dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\n",
    "index_col = \"sig_id\"\n",
    "\n",
    "train_features = pd.read_csv(\n",
    "    f\"{DATADIR}/train_features.csv\", dtype=dtype, index_col=index_col\n",
    ")\n",
    "X = train_features.select_dtypes(\"number\")\n",
    "Y_nonscored = pd.read_csv(\n",
    "    f\"{DATADIR}/train_targets_nonscored.csv\", index_col=index_col\n",
    ")\n",
    "Y = pd.read_csv(f\"{DATADIR}/train_targets_scored.csv\", index_col=index_col)\n",
    "groups = pd.read_csv(\n",
    "    f\"{DATADIR}/train_drug.csv\", index_col=index_col, squeeze=True\n",
    ")\n",
    "\n",
    "columns = Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:15.865853Z",
     "start_time": "2020-11-28T11:28:12.492629Z"
    }
   },
   "outputs": [],
   "source": [
    "c_prefix = \"c-\"\n",
    "g_prefix = \"g-\"\n",
    "c_columns = X.columns.str.startswith(c_prefix)\n",
    "g_columns = X.columns.str.startswith(g_prefix)\n",
    "X_c = compute_row_statistics(X.loc[:, c_columns], prefix=c_prefix)\n",
    "X_g = compute_row_statistics(X.loc[:, g_columns], prefix=g_prefix)\n",
    "\n",
    "clipped_features = ClippedFeatures()\n",
    "X = clipped_features.fit_transform(X)\n",
    "with open(\"clipped_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clipped_features, f)\n",
    "\n",
    "X = pd.concat([X, X_c, X_g], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eDJ68r-vgTA"
   },
   "source": [
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:15.871837Z",
     "start_time": "2020-11-28T11:28:15.866851Z"
    }
   },
   "outputs": [],
   "source": [
    "n_seeds = 5\n",
    "n_splits = 5\n",
    "LBS = 0.0008\n",
    "\n",
    "param = {'objective': 'binary:logistic',\n",
    "         'eval_metric': 'logloss', \n",
    "         'tree_method': 'gpu_hist', \n",
    "         'verbosity': 0, \n",
    "         'colsample_bytree': 0.1818593017814899, \n",
    "         'eta': 0.012887963193108452, \n",
    "         'gamma': 6.576022976359221, \n",
    "         'max_depth': 8, \n",
    "         'min_child_weight': 8.876744371188476, \n",
    "         'subsample': 0.7813380253086911, \n",
    "        }\n",
    "n_estimators = 1000\n",
    "early_stopping_rounds = 25\n",
    "\n",
    "# pick top features that have more postive samples\n",
    "top_k = 75\n",
    "\n",
    "\n",
    "#DEBUG = True\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    n_seeds = 2\n",
    "    n_splits = 2\n",
    "    \n",
    "    n_estimators = 5\n",
    "    early_stopping_rounds = 2\n",
    "    \n",
    "    columns = [\n",
    "        \"atp-sensitive_potassium_channel_antagonist\",  # 陽性ラベル1個だけ\n",
    "        \"erbb2_inhibitor\",  # 陽性ラベル1個だけ\n",
    "        \"antiarrhythmic\",  # 陽性ラベル6個だけ\n",
    "#        \"aldehyde_dehydrogenase_inhibitor\",  # 陽性ラベル7個だけ\n",
    "#        \"lipase_inhibitor\",  # 陽性ラベル12個だけ\n",
    "#        \"sphingosine_receptor_agonist\",  # 陽性ラベル25個だけ\n",
    "#        \"igf-1_inhibitor\",  # 陽性ラベル37個だけ\n",
    "#        \"potassium_channel_activator\",  # 陽性ラベル55個だけ\n",
    "#        \"potassium_channel_antagonist\",  # 陽性ラベル98個だけ\n",
    "#        \"dopamine_receptor_agonist\",  # 陽性ラベル121個だけ\n",
    "#        \"nfkb_inhibitor\",  # 陽性ラベル832個\n",
    "#        \"cyclooxygenase_inhibitor\",  # 陽性ラベル435個\n",
    "#        \"dna_inhibitor\",  # 陽性ラベル402個\n",
    "#        \"glutamate_receptor_antagonist\",  # 陽性ラベル367個\n",
    "#        \"tubulin_inhibitor\",  # 陽性ラベル316個\n",
    "#        \"pdgfr_inhibitor\",  # 陽性ラベル297個\n",
    "#        \"calcium_channel_blocker\",  # 陽性ラベル281個\n",
    "        \"flt3_inhibitor\",  # 陽性ラベル279個\n",
    "        \"progesterone_receptor_agonist\",  # 陽性ラベル119個\n",
    "        \"hdac_inhibitor\",  # 陽性ラベル106個\n",
    "    ]\n",
    "    Y = Y[columns]\n",
    "    \n",
    "    top_k = Y.shape[1] // 2\n",
    "\n",
    "    print(f\"DEBUG: {DEBUG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:15.881318Z",
     "start_time": "2020-11-28T11:28:15.872340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes: 206\n"
     ]
    }
   ],
   "source": [
    "train_size, n_features = X.shape\n",
    "_, n_classes = Y.shape\n",
    "print(\"n_classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:15.889297Z",
     "start_time": "2020-11-28T11:28:15.882315Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_xgb(y, outdir):\n",
    "    \n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    \n",
    "    y_pred = np.zeros((train_size, y.shape[1]))\n",
    "    y_pred = pd.DataFrame(y_pred, columns=y.columns, index=y.index)\n",
    "\n",
    "    for i in tqdm(range(n_seeds)):\n",
    "        set_seed(seed=i)\n",
    "\n",
    "        cv = MultilabelStratifiedGroupKFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "        cv_split = cv.split(X, y, groups)\n",
    "\n",
    "        for j, (trn_idx, val_idx) in enumerate(cv_split):\n",
    "            print(f\"------------ fold:{j} ------------\")\n",
    "\n",
    "            X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
    "            y_train_targets, y_val_targets = y.iloc[trn_idx], y.iloc[val_idx]\n",
    "\n",
    "            # Label Smoothing\n",
    "            y_train_targets = y_train_targets * (1 - LBS) + 0.5 * LBS\n",
    "            \n",
    "            for tar, tar_col in enumerate(y.columns):\n",
    "                y_train, y_val = y_train_targets.values[:, tar], y_val_targets.values[:, tar]\n",
    "\n",
    "                xgb_tr  = xgb.DMatrix(X_train, label=y_train, nthread=-1)\n",
    "                xgb_val = xgb.DMatrix(X_val, label=y_val, nthread=-1)\n",
    "                \n",
    "                model = xgb.train(\n",
    "                    param, \n",
    "                    xgb_tr, \n",
    "                    n_estimators, \n",
    "                    [(xgb_val, 'eval')],\n",
    "                    early_stopping_rounds=early_stopping_rounds,\n",
    "                    verbose_eval=0,\n",
    "                )\n",
    "\n",
    "                y_pred[tar_col][val_idx] += (\n",
    "                    model.predict(xgb_val, ntree_limit=model.best_ntree_limit) / n_seeds\n",
    "                )\n",
    "\n",
    "                joblib.dump(\n",
    "                    model, f\"{outdir}/model_seed_{i}_fold_{j}_{y.columns[tar]}.jlb\", compress=True\n",
    "                )\n",
    "\n",
    "    y_pred[train_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:28:15.903265Z",
     "start_time": "2020-11-28T11:28:15.890294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(easy_tar): 75\n",
      "len(hard_tar): 131\n"
     ]
    }
   ],
   "source": [
    "easy_tar = Y.sum(axis=0).sort_values(ascending=False)[:top_k].index.values\n",
    "hard_tar = Y.sum(axis=0).sort_values(ascending=False)[top_k:].index.values\n",
    "assert len(easy_tar) + len(hard_tar) == n_classes\n",
    "\n",
    "print(\"len(easy_tar):\", len(easy_tar))\n",
    "print(\"len(hard_tar):\", len(hard_tar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Training 'Easy' Target, more positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T11:28:07.320Z"
    },
    "incorrectly_encoded_metadata": "_kg_hide-output=true",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef8f1dfaa814bb6b87d87543409960a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "------------ fold:2 ------------\n",
      "------------ fold:3 ------------\n",
      "------------ fold:4 ------------\n",
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "------------ fold:2 ------------\n",
      "------------ fold:3 ------------\n",
      "------------ fold:4 ------------\n",
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n",
      "------------ fold:2 ------------\n",
      "------------ fold:3 ------------\n",
      "------------ fold:4 ------------\n",
      "------------ fold:0 ------------\n",
      "------------ fold:1 ------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_pred_easy = run_xgb(Y[easy_tar], outdir=\"first\")\n",
    "display(Y_pred_easy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2(Self-Stacking): Training 'hard' targets, less postive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T11:28:07.322Z"
    }
   },
   "outputs": [],
   "source": [
    "#update train and test for stage 2, append the oofs as features\n",
    "X = pd.concat([X, Y_pred_easy[easy_tar]], axis=1)\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T11:28:07.323Z"
    },
    "incorrectly_encoded_metadata": "_kg_hide-output=true",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "Y_pred_hard = run_xgb(Y[hard_tar], outdir=\"second\")\n",
    "display(Y_pred_hard.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T11:28:07.326Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = Y_pred_hard.join(Y_pred_easy)\n",
    "Y_pred = Y_pred[columns]\n",
    "\n",
    "with open(f\"Y_pred.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Y_pred, f)\n",
    "    \n",
    "print(Y_pred.shape)\n",
    "display(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T11:28:07.328Z"
    }
   },
   "outputs": [],
   "source": [
    "oof_logloss = score(Y[columns], Y_pred[columns])\n",
    "oof_auc = auc_score(Y[columns], Y_pred[columns])\n",
    "print(f\"oof_logloss:\", oof_logloss)\n",
    "print(f\"oof_auc:\", oof_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T11:28:07.331Z"
    },
    "incorrectly_encoded_metadata": "_kg_hide-output=true"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_features = pd.read_csv(\n",
    "    #\"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n",
    "    f\"{DATADIR}/test_features.csv\", dtype=dtype, index_col=index_col\n",
    ")\n",
    "X_test = test_features.select_dtypes(\"number\")\n",
    "X_c = compute_row_statistics(X_test.loc[:, c_columns], prefix=c_prefix)\n",
    "X_g = compute_row_statistics(X_test.loc[:, g_columns], prefix=g_prefix)\n",
    "\n",
    "with open(\"./clipped_features.pkl\", \"rb\") as f:\n",
    "    clipped_features = pickle.load(f)\n",
    "X_test = clipped_features.transform(X_test)\n",
    "\n",
    "X_test = pd.concat([X_test, X_c, X_g], axis=1)\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "\n",
    "xgb_tt = xgb.DMatrix(X_test, nthread=-1)\n",
    "\n",
    "Y_test_pred = np.zeros((X_test.shape[0], len(columns)))\n",
    "Y_test_pred = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\n",
    "\n",
    "for i in range(n_seeds):\n",
    "    for j in range(n_splits):\n",
    "        for tar, tar_col in enumerate(easy_tar):\n",
    "\n",
    "            m_path = f\"first/model_seed_{i}_fold_{j}_{tar_col}.jlb\"\n",
    "\n",
    "            if os.path.exists(m_path):\n",
    "                print(m_path)\n",
    "                model = joblib.load(m_path)\n",
    "                Y_test_pred.loc[:, tar_col] += model.predict(xgb_tt, ntree_limit=model.best_ntree_limit) / (n_seeds * n_splits)\n",
    "            else:\n",
    "                Y_test_pred.loc[:, tar_col] += np.array([Y_pred.iloc[:,tar].mean()] * X_test.shape[0]) / (n_seeds * n_splits)\n",
    "\n",
    "X_test = pd.concat([X_test, Y_test_pred[easy_tar]], axis=1)\n",
    "xgb_tt = xgb.DMatrix(X_test, nthread=-1)\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "                \n",
    "for i in range(n_seeds):\n",
    "    for j in range(n_splits):\n",
    "        for tar, tar_col in enumerate(hard_tar):\n",
    "\n",
    "            m_path = f\"second/model_seed_{i}_fold_{j}_{tar_col}.jlb\"\n",
    "\n",
    "            if os.path.exists(m_path):\n",
    "                print(m_path)\n",
    "                model = joblib.load(m_path)\n",
    "                Y_test_pred.loc[:, tar_col] += model.predict(xgb_tt, ntree_limit=model.best_ntree_limit) / (n_seeds * n_splits)\n",
    "            else:\n",
    "                Y_test_pred.loc[:, tar_col] += np.array([Y_pred.iloc[:,tar].mean()] * X_test.shape[0]) / (n_seeds * n_splits)\n",
    "\n",
    "\n",
    "Y_test_pred[test_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n",
    "\n",
    "Y_test_pred.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-28T11:28:07.333Z"
    }
   },
   "outputs": [],
   "source": [
    "print(Y_test_pred.shape)\n",
    "display(Y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
